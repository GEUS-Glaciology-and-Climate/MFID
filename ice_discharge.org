#+PROPERTY: header-args: :comments both
#+PROPERTY: header-args:bash :eval no-export :noweb yes :session CCI
#+PROPERTY: header-args:python :eval no-export :noweb yes :session CCI :kernel ice_discharge
#+PROPERTY: header-args: :session CCI

* README                                                :noexport:

This document is an Emacs Org Mode plain-text file with code and text embedded. If you are viewing:

+ A DOC or PDF file, then it was generated by exporting from Org. Not all of the Org parts (code, results, comments, etc.) were exported. The Org source file is available upon request, and may be embedded in the PDF. Most non-Apple PDF viewers provide easy access to embedded or attached files.
 
+ A file with a =org= extension in something other than Emacs, then you are seeing the canonical version and the full source, but without any syntax highlighting, document structure, or the ability to execute the code blocks.

+ An =Org= file within Emacs, then this is the canonical version. You should be able to fully interact and reproduce the contents of this document, although it may require 3rd-party applications (Python, etc.) and a similar Emacs configuration. This is available upon request.

** Workflow

To recreate this work

+ check that you have the necessary software dependencies installed. See section: [[*Code][Code]].
+ Download and set up the necessary data files used throughout the [[*Input data][Input data]] section.
+ Open this file in Emacs Org Mode.
+ Tangle the embedded code blocks.
+ Execute =make= to run the contents of the [[#sec:makefile][Makefile]].

* Code                                                  :noexport:
:PROPERTIES:
:header-args:bash+: :comments both
:header-args:bash+: :tangle-mode (identity #o744)
:header-args:bash+: :shebang #!/usr/bin/env bash
:END:
** Makefile
:PROPERTIES:
:CUSTOM_ID: sec:makefile
:END:

This code, and all code files in this project, are derived products tangled from the ice_discharge.org source file.

#+BEGIN_SRC makefile :tangle Makefile
all: G GRASS PYTHON dist

G:
	grass -e -c EPSG:3413 ./G

GRASS: FORCE
	grass ./G/PERMANENT --exec ./import.sh
	grass ./G/PERMANENT --exec ./gate_IO_runner.sh
	grass ./G/PERMANENT --exec ./vel_eff.sh
	grass ./G/PERMANENT --exec ./export.sh


PYTHON: FORCE
	python ./errors.py
	python ./raw2discharge.py
	grass ./G/PERMANENT --exec ./gate_export.sh
	mkdir -p figs
	python ./figures.py

dist:
	ln -s out CCI
	zip -r CCI.zip CCI
	rm CCI

FORCE: # dummy target

clean:
	rm -fR G tmp out figs CCI.zip
#+END_SRC
#+RESULTS:
: 
: 81-Ubuntu SMP Tue Nov 26 12:20:02 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux



** Misc Helper
*** Support pretty messages
#+NAME: MSGS_pretty_print
#+BEGIN_SRC bash :results verbatim :tangle no
# Convenience functions for pretty printing messages
RED='\033[0;31m'; ORANGE='\033[0;33m'; GREEN='\033[0;32m'; NC='\033[0m' # No Color
MSG_OK() { echo -e "${GREEN}${@}${NC}"; }
MSG_WARN() { echo -e "${ORANGE}WARNING: ${@}${NC}"; }
MSG_ERR() { echo -e "${RED}ERROR: ${@}${NC}" >&2; }
#+END_SRC
#+RESULTS:

*** GRASS config
https://grass.osgeo.org/grass74/manuals/variables.html
#+BEGIN_SRC sh
#sudo mount -o uid=shl@geus.dk,gid=1260400513 /dev/sda1 /media/shl@geus.dk/datadrive
sudo mount -t ntfs-3g -o uid=1260406986,gid=1260400513 /dev/sda1 /media/shl@geus.dk/datadrive
conda activate py38

grass --text ./G/PERMANENT 



#+END_SRC

#+BEGIN_QUOTE
GRASS_VERBOSE
[all modules]
toggles verbosity level
-1 - complete silence (also errors and warnings are discarded)
0 - only errors and warnings are printed
1 - progress and important messages are printed (percent complete)
2 - all module messages are printed
3 - additional verbose messages are printed
#+END_QUOTE

#+NAME: GRASS_config
#+BEGIN_SRC bash :results verbatim :tangle no
export GRASS_VERBOSE=3
# export GRASS_MESSAGE_FORMAT=silent
export PROJ_LIB=/usr/share/proj
export DATADIR="/media/shl@geus.dk/datadrive/data/ESA_GIS_CCI"
if [ -z ${DATADIR+x} ]; then
    echo "DATADIR environment varible is unset."
    echo "Fix with: \"export DATADIR=/path/to/data\""
    exit 255
fi

set -x # print commands to STDOUT before running them
#+END_SRC
#+RESULTS:





** Import Data
:PROPERTIES:
:header-args:bash+: :tangle import.sh
:END:

#+BEGIN_SRC bash :results verbatim
<<MSGS_pretty_print>>
<<GRASS_config>>
#+END_SRC
#+RESULTS:

*** Bed and Surface
**** BedMachine v3
+ from [[textcite:Morlighem:2017BedMachine][Morlighem /et al./ (2017)]]
#+BEGIN_SRC bash :results verbatim
MSG_OK "BedMachine"
g.mapset -c BedMachine

#for var in $(echo mask surface thickness bed errbed); do
#  echo $var
#  r.external source=netCDF:${DATADIR}/Morlighem_2017/BedMachineGreenland-v5.nc:${var} output=${var}
#done

for var in surface thickness bed errbed; do
  echo $var
  r.external source="${DATADIR}"/Morlighem_2022/BMv5_3413/${var}.tif output=${var} --o
done
echo $var
r.external source="${DATADIR}"/Morlighem_2022/BMv5_3413/mask_float.tif output=mask -o --o

r.colors -a map=errbed color=haxby

g.mapset PERMANENT
g.region raster=surface@BedMachine res=200 -a -p
g.region -s
g.mapset BedMachine
g.region -dp

r.colors map=mask color=haxby

r.mapcalc "mask_ice = if(mask == 2, 1, null())"
#+END_SRC
#+RESULTS:
**** COMMENT GIMP 0715
#+BEGIN_SRC bash :results verbatim
MSG_OK "GIMP 0715"
g.mapset -c GIMP.0715
ROOT=${DATADIR}/GIMP/0715

# reset
# g.remove -f type=raster name=$(g.list type=raster mapset=. separator=",")

# read in DEM, DAY, and ERR
# for f in $(ls ${ROOT}/reg/tile_?_?_reg_30m_???.tif); do
#   name=$(basename ${f})
#   r.external input=${f} output=${name}
# done
ls ${ROOT}/reg/tile_?_?_reg_30m_???.tif | parallel --verbose --bar r.external input={} output={/.}
ls ${ROOT}/fit/tile_?_?_fit_30m_???.tif | parallel --verbose --bar r.external input={} output={/.}

r.patch -s input=$(g.list type=raster pattern=tile_?_?_reg_30m_dem separator=,),$(g.list type=raster pattern=tile_?_?_fit_30m_dem separator=,) output=dem

# no fit day data to patch holes. We'll assign elevation pixels with DEM data but not DAY data to some day, TBD
r.patch -s input=$(g.list type=raster pattern=tile_?_?_reg_30m_day separator=,) output=day

r.patch -s input=$(g.list type=raster pattern=tile_?_?_reg_30m_err separator=,),$(g.list type=raster pattern=tile_?_?_fit_30m_err separator=,) output=err

r.null map=day null=0
#+END_SRC
#+RESULTS:

*** Sectors
**** Mouginot
+ From citet:mouginot_2019_glacier
***** Import & Clean
#+BEGIN_SRC bash :results verbatim
MSG_OK "Mouginot 2019 sectors"

g.mapset -c Mouginot_2019
v.in.ogr input=${DATADIR}/Mouginot_2019 output=sectors_all
v.extract input=sectors_all where="NAME NOT LIKE '%ICE_CAP%'" output=sectors

db.select table=sectors | head
v.db.addcolumn map=sectors columns="region_name varchar(100)"
db.execute sql="UPDATE sectors SET region_name=SUBREGION1 || \"___\" || NAME"

# v.db.addcolumn map=sectors columns="area DOUBLE PRECISION"
v.to.db map=sectors option=area columns=area units=meters

mkdir -p ./tmp/
# db.select table=sectors > ./tmp/Mouginot_2019.txt

v.to.rast input=sectors output=sectors use=cat label_column=region_name
r.mapcalc "mask_GIC = if(sectors)"

# # regions map
v.to.rast input=sectors output=regions_tmp use=cat label_column=SUBREGION1
# which categories exist?
# r.category regions separator=comma | cut -d, -f2 | sort | uniq
# Convert categories to numbers
r.category regions_tmp separator=comma | sed s/NO/1/ | sed s/NE/2/ | sed s/CE/3/ | sed s/SE/4/ | sed s/SW/5/ | sed s/CW/6/ | sed s/NW/7/ > ./tmp/mouginot.cat
r.category regions_tmp separator=comma rules=./tmp/mouginot.cat
# r.category regions_tmp
r.mapcalc "regions = @regions_tmp"

# # region vector 
# r.to.vect input=regions output=regions type=area
# v.db.addcolumn map=regions column="REGION varchar(2)"
# v.what.vect map=regions column=REGION query_map=sectors query_column=SUBREGION1

# # mask
#+END_SRC
#+RESULTS:
***** Test
#+BEGIN_SRC bash :results verbatim :tangle no
grass74 ./G/Mouginot_2019
d.mon start=wx0
d.rast regions
d.rast sectors
d.vect sectors_all fill_color=none color=red
d.vect sectors fill_color=none
#+END_SRC
#+RESULTS:
**** Zwally (expanded)
***** Import & Clean
#+BEGIN_SRC bash :results verbatim
MSG_OK "Zwally 2012 expanded sectors"

g.mapset -c Zwally_2012
v.in.ogr input=${DATADIR}/Zwally_2012/sectors_enlarged output=sectors

db.select table=sectors | head
v.to.rast input=sectors output=sectors use=cat label_column=cat_
r.mapcalc "mask_GIC = if(sectors)"
#+END_SRC

#+RESULTS:
*** 2D Area Error
+ EPSG:3413 has projection errors of \(\pm\) ~8% in Greenland
+ Method
  + Email: [[mu4e:msgid:m2tvxmd2xr.fsf@gmail.com][Re: {GRASS-user} scale error for each pixel]]
  + Webmail: https://www.mail-archive.com/grass-user@lists.osgeo.org/msg35005.html
#+BEGIN_SRC bash :results verbatim
MSG_OK "2D Area Error"
g.mapset PERMANENT

if [[ "" == $(g.list type=raster pattern=err_2D) ]]; then
    r.mask -r
    g.region -d

    g.region res=1000 -ap # do things faster
    r.mapcalc "x = x()"
    r.mapcalc "y = y()"
    r.latlong input=x output=lat_low
    r.latlong -l input=x output=lon_low

    r.out.xyz input=lon_low,lat_low separator=space > ./tmp/llxy.txt
    PROJSTR=$(g.proj -j)
    echo $PROJSTR

    paste -d" " <(cut -d" " -f1,2 ./tmp/llxy.txt) <(cut -d" " -f3,4 ./tmp/llxy.txt | proj -VS ${PROJSTR} | grep Areal | column -t | sed s/\ \ /,/g | cut -d, -f4) > ./tmp/xy_err.txt

    r.in.xyz input=./tmp/xy_err.txt  output=err_2D_inv separator=space
    r.mapcalc "err_2D = 1/(err_2D_inv^0.5)" # convert area error to linear multiplier error
    g.region -d

    r.latlong input=x output=lat # for exporting at full res
    r.latlong -l input=x output=lon
fi

# sayav done
g.region -d
#+END_SRC
#+RESULTS:

*** ENVEO IV
**** Data Intro
:PROPERTIES:
:header-args:bash+: :session ENVEO_provenance
:END:

#+BEGIN_SRC bash :results verbatim :tangle no
export DATADIR="/media/shl@geus.dk/datadrive/data/ESA_GIS_CCI"
DIR=${DATADIR}/ENVEO/monthly
(cd ${DIR}; ls -FGhol --color *nc)
#+END_SRC

#+RESULTS:
#+begin_example
-rwxrwxrwx 1 shl@geus.dk  50M May 15  2023 [0m[01;32mgreenland_iv_250m_s1_s20141001_e20141031_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk  50M May 15  2023 [01;32mgreenland_iv_250m_s1_s20141101_e20141130_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk  61M May 15  2023 [01;32mgreenland_iv_250m_s1_s20141201_e20141231_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 462M May 15  2023 [01;32mgreenland_iv_250m_s1_s20150101_e20150131_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 512M May 15  2023 [01;32mgreenland_iv_250m_s1_s20150201_e20150228_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 145M May 15  2023 [01;32mgreenland_iv_250m_s1_s20150301_e20150331_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk  55M May 15  2023 [01;32mgreenland_iv_250m_s1_s20150401_e20150430_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 196M May 15  2023 [01;32mgreenland_iv_250m_s1_s20150501_e20150531_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 273M May 15  2023 [01;32mgreenland_iv_250m_s1_s20150601_e20150630_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 271M May 15  2023 [01;32mgreenland_iv_250m_s1_s20150701_e20150731_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 334M May 15  2023 [01;32mgreenland_iv_250m_s1_s20150801_e20150831_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 290M May 15  2023 [01;32mgreenland_iv_250m_s1_s20150901_e20150930_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 271M May 15  2023 [01;32mgreenland_iv_250m_s1_s20151001_e20151031_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 322M May 15  2023 [01;32mgreenland_iv_250m_s1_s20151101_e20151130_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 494M May 15  2023 [01;32mgreenland_iv_250m_s1_s20151201_e20151231_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 559M May 15  2023 [01;32mgreenland_iv_250m_s1_s20160101_e20160131_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 580M May 15  2023 [01;32mgreenland_iv_250m_s1_s20160201_e20160229_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 527M May 15  2023 [01;32mgreenland_iv_250m_s1_s20160301_e20160331_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 451M May 15  2023 [01;32mgreenland_iv_250m_s1_s20160401_e20160430_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 438M May 15  2023 [01;32mgreenland_iv_250m_s1_s20160501_e20160531_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 358M May 15  2023 [01;32mgreenland_iv_250m_s1_s20160601_e20160630_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 333M May 15  2023 [01;32mgreenland_iv_250m_s1_s20160701_e20160731_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 363M May 15  2023 [01;32mgreenland_iv_250m_s1_s20160801_e20160831_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 412M May 15  2023 [01;32mgreenland_iv_250m_s1_s20160901_e20160930_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 411M May 15  2023 [01;32mgreenland_iv_250m_s1_s20161001_e20161031_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 411M May 15  2023 [01;32mgreenland_iv_250m_s1_s20161101_e20161130_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 531M May 15  2023 [01;32mgreenland_iv_250m_s1_s20161201_e20161231_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 593M May 15  2023 [01;32mgreenland_iv_250m_s1_s20170101_e20170131_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 527M May 15  2023 [01;32mgreenland_iv_250m_s1_s20170201_e20170228_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 460M May 15  2023 [01;32mgreenland_iv_250m_s1_s20170301_e20170331_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 449M May 15  2023 [01;32mgreenland_iv_250m_s1_s20170401_e20170430_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 449M May 15  2023 [01;32mgreenland_iv_250m_s1_s20170501_e20170531_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 439M May 15  2023 [01;32mgreenland_iv_250m_s1_s20170601_e20170630_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 429M May 15  2023 [01;32mgreenland_iv_250m_s1_s20170701_e20170731_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 427M May 15  2023 [01;32mgreenland_iv_250m_s1_s20170801_e20170831_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 433M May 15  2023 [01;32mgreenland_iv_250m_s1_s20170901_e20170930_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 437M May 15  2023 [01;32mgreenland_iv_250m_s1_s20171001_e20171031_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 436M May 15  2023 [01;32mgreenland_iv_250m_s1_s20171101_e20171130_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 546M May 15  2023 [01;32mgreenland_iv_250m_s1_s20171201_e20171231_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 564M May 15  2023 [01;32mgreenland_iv_250m_s1_s20180101_e20180131_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 562M May 15  2023 [01;32mgreenland_iv_250m_s1_s20180201_e20180228_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 525M May 15  2023 [01;32mgreenland_iv_250m_s1_s20180301_e20180331_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 511M May 15  2023 [01;32mgreenland_iv_250m_s1_s20180401_e20180430_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 445M May 15  2023 [01;32mgreenland_iv_250m_s1_s20180501_e20180531_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 432M May 15  2023 [01;32mgreenland_iv_250m_s1_s20180601_e20180630_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 415M May 15  2023 [01;32mgreenland_iv_250m_s1_s20180701_e20180731_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 418M May 15  2023 [01;32mgreenland_iv_250m_s1_s20180801_e20180831_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 422M May 15  2023 [01;32mgreenland_iv_250m_s1_s20180901_e20180930_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 431M May 15  2023 [01;32mgreenland_iv_250m_s1_s20181001_e20181031_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 435M May 15  2023 [01;32mgreenland_iv_250m_s1_s20181101_e20181130_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 567M May 15  2023 [01;32mgreenland_iv_250m_s1_s20181201_e20181231_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 571M May 15  2023 [01;32mgreenland_iv_250m_s1_s20190101_e20190131_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 541M May 15  2023 [01;32mgreenland_iv_250m_s1_s20190201_e20190228_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 499M May 15  2023 [01;32mgreenland_iv_250m_s1_s20190301_e20190331_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 532M May 15  2023 [01;32mgreenland_iv_250m_s1_s20190401_e20190430_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 541M May 15  2023 [01;32mgreenland_iv_250m_s1_s20190501_e20190531_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 453M May 15  2023 [01;32mgreenland_iv_250m_s1_s20190601_e20190630_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 408M May 15  2023 [01;32mgreenland_iv_250m_s1_s20190701_e20190731_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 462M May 15  2023 [01;32mgreenland_iv_250m_s1_s20190801_e20190831_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 469M May 15  2023 [01;32mgreenland_iv_250m_s1_s20190901_e20190930_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 467M May 15  2023 [01;32mgreenland_iv_250m_s1_s20191001_e20191031_v1_2.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 478M May 15  2023 [01;32mgreenland_iv_250m_s1_s20191101_e20191130_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 564M May 15  2023 [01;32mgreenland_iv_250m_s1_s20191201_e20191231_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 580M May 15  2023 [01;32mgreenland_iv_250m_s1_s20200101_e20200131_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 515M May 15  2023 [01;32mgreenland_iv_250m_s1_s20200201_e20200229_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 512M May 15  2023 [01;32mgreenland_iv_250m_s1_s20200301_e20200331_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 448M May 15  2023 [01;32mgreenland_iv_250m_s1_s20200401_e20200430_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 452M May 15  2023 [01;32mgreenland_iv_250m_s1_s20200501_e20200531_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 445M May 15  2023 [01;32mgreenland_iv_250m_s1_s20200601_e20200630_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 410M May 15  2023 [01;32mgreenland_iv_250m_s1_s20200701_e20200731_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 429M May 15  2023 [01;32mgreenland_iv_250m_s1_s20200801_e20200831_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 544M May 15  2023 [01;32mgreenland_iv_250m_s1_s20200901_e20200930_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 520M May 15  2023 [01;32mgreenland_iv_250m_s1_s20201001_e20201031_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 585M May 15  2023 [01;32mgreenland_iv_250m_s1_s20201101_e20201130_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 644M May 15  2023 [01;32mgreenland_iv_250m_s1_s20201201_e20201231_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 645M May 15  2023 [01;32mgreenland_iv_250m_s1_s20210101_e20210131_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 568M May 15  2023 [01;32mgreenland_iv_250m_s1_s20210201_e20210228_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 499M May 15  2023 [01;32mgreenland_iv_250m_s1_s20210301_e20210331_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 529M May 15  2023 [01;32mgreenland_iv_250m_s1_s20210401_e20210430_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 501M May 15  2023 [01;32mgreenland_iv_250m_s1_s20210501_e20210531_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 487M May 15  2023 [01;32mgreenland_iv_250m_s1_s20210601_e20210630_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 425M May 15  2023 [01;32mgreenland_iv_250m_s1_s20210701_e20210731_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 460M May 15  2023 [01;32mgreenland_iv_250m_s1_s20210801_e20210831_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 493M May 15  2023 [01;32mgreenland_iv_250m_s1_s20210901_e20210930_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 506M May 15  2023 [01;32mgreenland_iv_250m_s1_s20211001_e20211031_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 541M May 15  2023 [01;32mgreenland_iv_250m_s1_s20211101_e20211130_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 631M May 15  2023 [01;32mgreenland_iv_250m_s1_s20211201_e20211231_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 626M May 15  2023 [01;32mgreenland_iv_250m_s1_s20220101_e20220131_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 561M May 15  2023 [01;32mgreenland_iv_250m_s1_s20220201_e20220228_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 553M May 15  2023 [01;32mgreenland_iv_250m_s1_s20220301_e20220331_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 476M May 15  2023 [01;32mgreenland_iv_250m_s1_s20220401_e20220430_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 471M May 15  2023 [01;32mgreenland_iv_250m_s1_s20220501_e20220531_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 429M May 15  2023 [01;32mgreenland_iv_250m_s1_s20220601_e20220630_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 417M May 15  2023 [01;32mgreenland_iv_250m_s1_s20220701_e20220731_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 418M May 15  2023 [01;32mgreenland_iv_250m_s1_s20220801_e20220831_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 385M May 15  2023 [01;32mgreenland_iv_250m_s1_s20220901_e20220930_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 405M May 15  2023 [01;32mgreenland_iv_250m_s1_s20221001_e20221031_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 428M May 15  2023 [01;32mgreenland_iv_250m_s1_s20221101_e20221130_v1_3.nc[0m*
-rwxrwxrwx 1 shl@geus.dk 463M May 15  2023 [01;32mgreenland_iv_250m_s1_s20221201_e20221231_v1_3.nc[0m*
#+end_example
 
#+BEGIN_SRC bash :results verbatim :tangle no
(cd ${DIR}; ncdump -h $(ls *.nc | head -n1))
#+END_SRC
#+RESULTS:
#+begin_example
netcdf greenland_iv_250m_s1_s20141001_e20141031_v1_2 {
dimensions:
	y = 10801 ;
	x = 5984 ;
variables:
	int crs ;
		crs:grid_mapping_name = "polar_stereographic" ;
		crs:standard_parallel = 70. ;
		crs:straight_vertical_longitude_from_pole = -45. ;
		crs:false_easting = 0. ;
		crs:false_northing = 0. ;
		crs:unit = "metre" ;
		crs:spatial_ref = "PROJCS[\"WGS 84 / NSIDC Sea Ice Polar Stereographic North\",\n    GEOGCS[\"WGS 84\",\n        DATUM[\"WGS_1984\",\n            SPHEROID[\"WGS 84\",6378137,298.257223563,\n                AUTHORITY[\"EPSG\",\"7030\"]],\n            AUTHORITY[\"EPSG\",\"6326\"]],\n        PRIMEM[\"Greenwich\",0,\n            AUTHORITY[\"EPSG\",\"8901\"]],\n        UNIT[\"degree\",0.0174532925199433,\n            AUTHORITY[\"EPSG\",\"9122\"]],\n        AUTHORITY[\"EPSG\",\"4326\"]],\n    PROJECTION[\"Polar_Stereographic\"],\n    PARAMETER[\"latitude_of_origin\",70],\n    PARAMETER[\"central_meridian\",-45],\n    PARAMETER[\"scale_factor\",1],\n    PARAMETER[\"false_easting\",0],\n    PARAMETER[\"false_northing\",0],\n    UNIT[\"metre\",1,\n        AUTHORITY[\"EPSG\",\"9001\"]],\n    AXIS[\"X\",EAST],\n    AXIS[\"Y\",NORTH],\n    AUTHORITY[\"EPSG\",\"3413\"]]" ;
		crs:latitude_of_projection_origin = 90. ;
	double y(y) ;
		y:units = "m" ;
		y:axis = "Y" ;
		y:long_name = "y coordinate of projection" ;
		y:standard_name = "projection_y_coordinate" ;
	double x(x) ;
		x:units = "m" ;
		x:axis = "X" ;
		x:long_name = "x coordinate of projection" ;
		x:standard_name = "projection_x_coordinate" ;
	float land_ice_surface_easting_velocity(y, x) ;
		land_ice_surface_easting_velocity:_FillValue = 3.402823e+38f ;
		land_ice_surface_easting_velocity:units = "m/day" ;
		land_ice_surface_easting_velocity:description = "easting ice velocity" ;
		land_ice_surface_easting_velocity:grid_mapping = "crs" ;
		land_ice_surface_easting_velocity:coordinates = "y x" ;
	float land_ice_surface_northing_velocity(y, x) ;
		land_ice_surface_northing_velocity:_FillValue = 3.402823e+38f ;
		land_ice_surface_northing_velocity:units = "m/day" ;
		land_ice_surface_northing_velocity:description = "northing ice velocity" ;
		land_ice_surface_northing_velocity:grid_mapping = "crs" ;
		land_ice_surface_northing_velocity:coordinates = "y x" ;
	float land_ice_surface_vertical_velocity(y, x) ;
		land_ice_surface_vertical_velocity:_FillValue = 3.402823e+38f ;
		land_ice_surface_vertical_velocity:units = "m/day" ;
		land_ice_surface_vertical_velocity:description = "vertical ice velocity" ;
		land_ice_surface_vertical_velocity:grid_mapping = "crs" ;
		land_ice_surface_vertical_velocity:coordinates = "y x" ;
	float land_ice_surface_velocity_magnitude(y, x) ;
		land_ice_surface_velocity_magnitude:_FillValue = 3.402823e+38f ;
		land_ice_surface_velocity_magnitude:units = "m/day" ;
		land_ice_surface_velocity_magnitude:description = "magnitude of horizontal ice velocity" ;
		land_ice_surface_velocity_magnitude:grid_mapping = "crs" ;
		land_ice_surface_velocity_magnitude:coordinates = "y x" ;
	int land_ice_surface_measurement_count(y, x) ;
		land_ice_surface_measurement_count:_FillValue = -1 ;
		land_ice_surface_measurement_count:units = "m/day" ;
		land_ice_surface_measurement_count:description = "count of measurements" ;
		land_ice_surface_measurement_count:grid_mapping = "crs" ;
		land_ice_surface_measurement_count:coordinates = "y x" ;
	float land_ice_surface_velocity_stddev(y, x) ;
		land_ice_surface_velocity_stddev:_FillValue = 3.402823e+38f ;
		land_ice_surface_velocity_stddev:units = "m/day" ;
		land_ice_surface_velocity_stddev:description = "standard deviation of ice velocity" ;
		land_ice_surface_velocity_stddev:grid_mapping = "crs" ;
		land_ice_surface_velocity_stddev:coordinates = "y x" ;

// global attributes:
		:comment = "Ice velocity map of Greenland derived from Sentinel-1 SAR data acquired from 2014-10-01 to 2014-10-31. The surface velocity is derived applying feature tracking techniques. The ice velocity map is provided at 250m grid spacing in North Polar Stereographic projection (EPSG: 3413). The horizontal velocity is provided in true meters per day, towards EASTING(vx) and NORTHING(vy) direction of the grid, and the vertical displacement (vz), is derived from a digital elevation model. Provided is a NetCDF file with the velocity components: vx, vy, vz and vv (magnitude of the horizontal components), along with maps showing valid pixel count and uncertainty (std.). The product was generated by ENVEO." ;
		:contact = "http://www.enveo.at/" ;
		:Conventions = "CF-1.7" ;
		:creation_date = "2020-02-04" ;
		:history = "Initial product version 1.2" ;
		:institution = "ENVEO" ;
		:keywords = "EARTH SCIENCE CLIMATE INDICATORS CRYOSPHERIC INDICATORS GLACIAL MEASUREMENTS ICE SHEET VELOCITY CRYOSPHERE GLACIERS/ICE SHEETS" ;
		:license = "general license" ;
		:project = "ESA Greenland Ice Sheet CCI+" ;
		:reference = "Main: Nagler, T.; Rott, H.; Hetzenecker, M.; Wuite, J.; Potin, P. The Sentinel-1 Mission: New Opportunities for Ice Sheet Observations. Remote Sens. 2015, 7, 9371-9389." ;
		:source = "Copernicus Sentinel-1A and Sentinel-1B" ;
		:summary = "Ice velocity derived for Greenland Ice Sheet gridded at sm averaged from 2014-10-01 to 2014-10-31." ;
		:title = "Ice Velocity of the Greenland Ice Sheet" ;
}
#+end_example

#+BEGIN_SRC bash :results table :tangle no
(cd ${DIR}; parallel "md5sum {}" ::: $(ls *.nc|head -n8))
#+END_SRC

#+RESULTS:
| 40d53f823e1a01e393fca2565eff5c1d | greenland_iv_250m_s1_s20141001_e20141031_v1_2.nc |
| ff0b16030be15cff201e5a540ef52848 | greenland_iv_250m_s1_s20141101_e20141130_v1_2.nc |
| 385e0a91654d3db8519ceb615b636436 | greenland_iv_250m_s1_s20150401_e20150430_v1_2.nc |
| e2af090c797fcc4bba8d62cf1933f49c | greenland_iv_250m_s1_s20141201_e20141231_v1_2.nc |
| 420a6f7617e2faefbb24f8afb3d456af | greenland_iv_250m_s1_s20150301_e20150331_v1_2.nc |
| 404ab716763f17524d318614b33bef2b | greenland_iv_250m_s1_s20150501_e20150531_v1_2.nc |
| 2bf634332b30fb6400cb3609fdd8972d | greenland_iv_250m_s1_s20150101_e20150131_v1_2.nc |
| d54cb3333feb08bfaac216f20371ae89 | greenland_iv_250m_s1_s20150201_e20150228_v1_2.nc |

**** Import data
+ Read in all the data
+ Convert from [m day-1] to [m year-1]
#+BEGIN_SRC bash :results verbatim
MSG_OK "ENVEO"
g.mapset -c ENVEO
ROOT=${DATADIR}/ENVEO/monthly

find ${ROOT} -name "*.nc"
# FILE=$(find ${ROOT} -name "*.nc"|head -n1) # testing

FILE=$(find ${ROOT} -name "*.nc" | head -n1) # DEBUG
for FILE in $(find ${ROOT} -name "*.nc" | LC_ALL=C sort); do
  T=$(echo ${FILE}|grep -o _s........_| tr -dc [0-9])
  DATE_STR=${T:0:4}_${T:4:2}_${T:6:2}
  echo $DATE_STR

  r.external -o source="NetCDF:${FILE}:land_ice_surface_easting_velocity" output=vx_${DATE_STR}
  r.external -o source="NetCDF:${FILE}:land_ice_surface_northing_velocity" output=vy_${DATE_STR}

  r.external -o source="NetCDF:${FILE}:land_ice_surface_velocity_stddev" output=err_${DATE_STR}
  r.external -o source="NetCDF:${FILE}:land_ice_surface_easting_stddev" output=ex_${DATE_STR}
  r.external -o source="NetCDF:${FILE}:land_ice_surface_northing_stddev" output=ey_${DATE_STR}
  r.mapcalc "err_${DATE_STR} = (ex_${DATE_STR}^2 + ey_${DATE_STR}^2)^0.5"
done
#+END_SRC
#+RESULTS:

**** Find baseline
#+BEGIN_SRC bash :results verbatim
r.series input=$(g.list type=raster pattern=vx_2018_* separator=",") output=vx_baseline method=average --o
r.series input=$(g.list type=raster pattern=vy_2018_* separator=",") output=vy_baseline method=average --o
r.mapcalc "vel_baseline = 365 * sqrt(vx_baseline^2 + vy_baseline^2) * mask_ice@BedMachine" --o

r.series input=$(g.list type=raster pattern=err_2018_* separator=",") output=err_baseline method=average --o
r.mapcalc "vel_err_baseline = 365 * err_baseline * mask_ice@BedMachine" --o
#+END_SRC
#+RESULTS:

***** Fill in holes
+ There are holes in the velocity data which will create false gates. Fill them in.
+ Clump based on yes/no velocity
  + Largest clump is GIS
  + 2nd largest is ocean
+ Mask by ocean (so velocity w/ holes remains)
+ Fill holes
#+BEGIN_SRC bash :results verbatim
r.mask -r
r.mapcalc "no_vel = if(isnull(vel_baseline), 1, null())"
r.mask no_vel
r.clump input=no_vel output=no_vel_clump --o
ocean_clump=$(r.stats -c -n no_vel_clump sort=desc | head -n1 | cut -d" " -f1)
r.mask -i raster=no_vel_clump maskcats=${ocean_clump} --o
r.fillnulls input=vel_baseline out=vel_baseline_filled method=bilinear
r.mask -r
g.rename raster=vel_baseline_filled,vel_baseline --o
r.colors map=vel_baseline -e color=viridis
#+END_SRC
#+RESULTS:
****** Display
#+BEGIN_SRC bash :results verbatim :tangle no
d.mon start=wx0
d.erase
d.rast vel
d.rast vel_filled
#+END_SRC
#+RESULTS:

*** COMMENT Sentinel IV
**** Data Intro
:PROPERTIES:
:header-args:bash+: :session Sentinel_provenance
:END:

#+BEGIN_SRC bash :results verbatim :tangle no
DIR=${DATADIR}/Sentinel1/Sentinel1_IV_maps
(cd ${DIR}; nth *.nc)
#+END_SRC

#+RESULTS:
#+begin_example

-rw------- 1 kdm  96M Nov 16  2017 IV_20160913_20161006.nc
-rw------- 1 kdm  97M Nov 16  2017 IV_20160925_20161018.nc
-rw------- 1 kdm  88M Nov 16  2017 IV_20161007_20161030.nc
-rw------- 1 kdm  88M Nov 16  2017 IV_20161013_20161105.nc
-rw------- 1 kdm  71M Nov 16  2017 IV_20161019_20161111.nc
-rw------- 1 kdm  83M Nov 16  2017 IV_20161031_20161123.nc
-rw------- 1 kdm  80M Nov 16  2017 IV_20161106_20161129.nc
-rw------- 1 kdm  87K Nov 16  2017 IV_20161118_20161211.nc
-rw------- 1 kdm  87K Nov 16  2017 IV_20161124_20161217.nc
-rw------- 1 kdm 100M Nov 16  2017 IV_20161130_20161223.nc
-rw------- 1 kdm  99M Nov 16  2017 IV_20161206_20161229.nc
-rw------- 1 kdm 101M Nov 16  2017 IV_20161212_20170104.nc
-rw------- 1 kdm 126M Nov 16  2017 IV_20161218_20170110.nc
-rw------- 1 kdm 133M Nov 16  2017 IV_20161224_20170116.nc
-rw------- 1 kdm 140M Nov 16  2017 IV_20161230_20170122.nc
-rw------- 1 kdm 141M Nov 16  2017 IV_20170105_20170128.nc
-rw------- 1 kdm 118M Nov 16  2017 IV_20170111_20170203.nc
-rw------- 1 kdm 112M Nov 16  2017 IV_20170117_20170209.nc
-rw------- 1 kdm 124M Nov 16  2017 IV_20170123_20170215.nc
-rw------- 1 kdm 123M Nov 16  2017 IV_20170129_20170221.nc
-rw------- 1 kdm 125M Nov 16  2017 IV_20170204_20170227.nc
-rw------- 1 kdm 125M Nov 16  2017 IV_20170210_20170305.nc
-rw------- 1 kdm 104M Nov 16  2017 IV_20170216_20170311.nc
-rw------- 1 kdm 105M Nov 16  2017 IV_20170222_20170317.nc
-rw------- 1 kdm 106M Nov 16  2017 IV_20170228_20170323.nc
-rw------- 1 kdm 104M Nov 16  2017 IV_20170306_20170329.nc
-rw------- 1 kdm 105M Nov 16  2017 IV_20170312_20170404.nc
-rw------- 1 kdm 105M Nov 16  2017 IV_20170318_20170410.nc
-rw------- 1 kdm 109M Nov 16  2017 IV_20170324_20170416.nc
-rw------- 1 kdm 106M Nov 16  2017 IV_20170330_20170422.nc
-rw------- 1 kdm 106M Nov 16  2017 IV_20170405_20170428.nc
-rw------- 1 kdm  99M Nov 16  2017 IV_20170411_20170504.nc
-rw------- 1 kdm  99M Nov 16  2017 IV_20170417_20170510.nc
-rw------- 1 kdm  96M Nov 16  2017 IV_20170423_20170516.nc
-rw------- 1 kdm 101M Nov 16  2017 IV_20170429_20170522.nc
-rw------- 1 kdm 104M Nov 16  2017 IV_20170505_20170528.nc
-rw------- 1 kdm 107M Nov 16  2017 IV_20170511_20170603.nc
-rw------- 1 kdm 108M Nov 16  2017 IV_20170517_20170609.nc
-rw------- 1 kdm 108M Nov 16  2017 IV_20170523_20170615.nc
-rw------- 1 kdm 106M Nov 16  2017 IV_20170529_20170621.nc
-rw------- 1 kdm 105M Nov 16  2017 IV_20170604_20170627.nc
-rw------- 1 kdm 106M Nov 16  2017 IV_20170610_20170703.nc
-rw------- 1 kdm 103M Nov 16  2017 IV_20170616_20170709.nc
-rw------- 1 kdm 101M Nov 16  2017 IV_20170622_20170715.nc
-rw------- 1 kdm 100M Nov 16  2017 IV_20170628_20170721.nc
-rw------- 1 kdm 102M Nov 16  2017 IV_20170704_20170727.nc
-rw------- 1 kdm 100M Nov 16  2017 IV_20170710_20170802.nc
-rw------- 1 kdm  99M Nov 16  2017 IV_20170716_20170808.nc
-rw------- 1 kdm 102M Nov 16  2017 IV_20170722_20170814.nc
-rw------- 1 kdm 106M Nov 16  2017 IV_20170728_20170820.nc
-rw-r--r-- 1 kdm 100M Nov 16  2017 IV_20170803_20170826.nc
-rw-r--r-- 1 kdm 102M Jan 12  2018 IV_20170809_20170901.nc
-rw-r--r-- 1 kdm 102M Jan 12  2018 IV_20170815_20170907.nc
-rw-r--r-- 1 kdm 100M Jan 12  2018 IV_20170821_20170913.nc
-rw-r--r-- 1 kdm  99M Jan 12  2018 IV_20170902_20170925.nc
-rw-r--r-- 1 kdm  99M Jan 12  2018 IV_20170908_20171001.nc
-rw-r--r-- 1 kdm  90M Jan 12  2018 IV_20170914_20171007.nc
-rw-r--r-- 1 kdm 107M Apr  6  2018 IV_20170920_20171013.nc
-rw-r--r-- 1 kdm 109M Apr  6  2018 IV_20170926_20171019.nc
-rw-r--r-- 1 kdm 108M Apr  6  2018 IV_20171002_20171025.nc
-rw-r--r-- 1 kdm 107M Apr 11  2018 IV_20171008_20171031.nc
-rw-r--r-- 1 kdm  97M Apr 11  2018 IV_20171014_20171106.nc
-rw-r--r-- 1 kdm  95M Apr 11  2018 IV_20171020_20171112.nc
-rw-r--r-- 1 kdm 102M Apr 11  2018 IV_20171026_20171118.nc
-rw-r--r-- 1 kdm 104M Apr 11  2018 IV_20171101_20171124.nc
-rw-r--r-- 1 kdm 107M Apr  6  2018 IV_20171106_20171130.nc
-rw-rw-r-- 1 kdm 104M Apr  6  2018 IV_20171118_20171212.nc
-rw-r--r-- 1 kdm 106M Apr  9  2018 IV_20171130_20171224.nc
-rw-r--r-- 1 kdm 113M Apr  9  2018 IV_20171212_20180105.nc
-rw-r--r-- 1 kdm 146M Apr  9  2018 IV_20171224_20180117.nc
-rw-rw-r-- 1 kdm 142M Apr 11  2018 IV_20180105_20180129.nc
-rw-rw-r-- 1 kdm 150M Apr 30  2018 IV_20180117_20180210.nc
-rw-rw-r-- 1 kdm 123M Apr 30  2018 IV_20180129_20180222.nc
-rw-rw-r-- 1 kdm 121M May  3  2018 IV_20180210_20180306.nc
-rw-rw-r-- 1 kdm 132M Aug 24  2018 IV_20180222_20180318.nc
-rw-rw-r-- 1 kdm 125M Aug 24  2018 IV_20180306_20180330.nc
-rw-rw-r-- 1 kdm 120M Aug 24  2018 IV_20180318_20180411.nc
-rw-rw-r-- 1 kdm  87M Aug 24  2018 IV_20180330_20180423.nc
-rw-rw-r-- 1 kdm  69M Aug 24  2018 IV_20180411_20180505.nc
-rw-rw-r-- 1 kdm  88M Aug 24  2018 IV_20180423_20180517.nc
-rw-rw-r-- 1 kdm 103M Aug 28  2018 IV_20180505_20180529.nc
-rw-rw-r-- 1 kdm 100M Sep  3  2018 IV_20180517_20180610.nc
-rw-rw-r-- 1 kdm 108M Nov 22  2018 IV_20180529_20180622.nc
-rw-rw-r-- 1 kdm 108M Nov 22  2018 IV_20180610_20180704.nc
-rw-rw-r-- 1 kdm 101M Nov 22  2018 IV_20180622_20180716.nc
-rw-rw-r-- 1 kdm  85M Nov 22  2018 IV_20180704_20180728.nc
-rw-rw-r-- 1 kdm  90M Nov 23  2018 IV_20180716_20180809.nc
-rw-rw-r-- 1 kdm  99M Nov 23  2018 IV_20180728_20180821.nc
-rw-rw-r-- 1 kdm 106M Nov 23  2018 IV_20180809_20180902.nc
-rw-rw-r-- 1 kdm 100M Nov 23  2018 IV_20180821_20180914.nc
-rw-rw-r-- 1 kdm 110M Nov 23  2018 IV_20180902_20180926.nc
-rw-rw-r-- 1 kdm  89M Nov 23  2018 IV_20180914_20181008.nc
-rw-rw-r-- 1 kdm 106M Feb  8  2019 IV_20180926_20181020.nc
-rw-rw-r-- 1 kdm 109M Feb  8  2019 IV_20181008_20181101.nc
-rw-rw-r-- 1 kdm 110M Feb  8  2019 IV_20181020_20181113.nc
-rw-rw-r-- 1 kdm 111M Feb  8  2019 IV_20181101_20181125.nc
-rw-rw-r-- 1 kdm 110M Feb  8  2019 IV_20181113_20181207.nc
-rw-rw-r-- 1 kdm 109M Feb  8  2019 IV_20181126_20181219.nc
-rw-rw-r-- 1 kdm 130M Feb  8  2019 IV_20181207_20181231.nc
-rw-rw-r-- 1 kdm 142M Apr  5  2019 IV_20181219_20190112.nc
-rw-rw-r-- 1 kdm 143M Apr  5  2019 IV_20181231_20190124.nc
-rw-rw-r-- 1 kdm 148M Apr  5  2019 IV_20190112_20190205.nc
-rw-rw-r-- 1 kdm 116M Apr  5  2019 IV_20190124_20190217.nc
-rw-rw-r-- 1 kdm 133M Apr  8  2019 IV_20190205_20190301.nc
-rw-rw-r-- 1 kdm 126M Apr  8  2019 IV_20190217_20190313.nc
-rw-rw-r-- 1 kdm 113M Apr 11  2019 IV_20190301_20190325.nc
-rw-rw-r-- 1 kdm 110M Apr 23  2019 IV_20190313_20190406.nc
-rw-rw-r-- 1 kdm 127M Apr 30  2019 IV_20190325_20190417.nc
-rw-rw-r-- 1 kdm 134M May  6  2019 IV_20190406_20190430.nc
-rw-rw-r-- 1 kdm 146M May 23  2019 IV_20190418_20190512.nc
-rw-rw-r-- 1 kdm 134M Jun  3  2019 IV_20190430_20190524.nc
-rw-rw-r-- 1 kdm 120M Jun 12  2019 IV_20190512_20190605.nc
-rw-rw-r-- 1 kdm 120M Jun 25  2019 IV_20190524_20190617.nc
-rw-rw-r-- 1 kdm  98M Jul 10  2019 IV_20190605_20190629.nc
-rw-rw-r-- 1 kdm 109M Aug 13  2019 IV_20190617_20190711.nc
-rw-rw-r-- 1 kdm 112M Aug 13  2019 IV_20190629_20190723.nc
-rw-rw-r-- 1 kdm 101M Aug 21  2019 IV_20190711_20190804.nc
-rw-rw-r-- 1 kdm 108M Aug 29  2019 IV_20190723_20190816.nc
-rw-rw-r-- 1 kdm 127M Sep  4 09:46 IV_20190804_20190828.nc
-rw-r--r-- 1 kdm 129M Sep 17 07:59 IV_20190816_20190909.nc
-rw-r--r-- 1 kdm 129M Sep 30 10:46 IV_20190828_20190921.nc
-rw-rw-r-- 1 kdm 116M Oct 11 06:30 IV_20190909_20191003.nc
-rw-rw-r-- 1 kdm 116M Nov  1 07:07 IV_20190921_20191015.nc
-rw-rw-r-- 1 kdm 129M Nov 11 11:53 IV_20191003_20191027.nc
-rw-rw-r-- 1 kdm 125M Nov 18 04:35 IV_20191015_20191108.nc
-rw-rw-r-- 1 kdm 129M Nov 26 11:40 IV_20191027_20191120.nc
-rw-rw-r-- 1 kdm 156M Dec 11 04:01 IV_20191108_20191202.nc
-rw-rw-r-- 1 kdm 159M Dec 20 07:30 IV_20191120_20191214.nc
-rw-rw-r-- 1 kdm 179M Jan  2 20:02 IV_20191202_20191226.nc
-rw-rw-r-- 1 kdm 188M Jan 22 05:30 IV_20191214_20200107.nc
-rw-rw-r-- 1 kdm 187M Jan 31 22:52 IV_20191226_20200119.nc
-rw-rw-r-- 1 kdm 187M Feb 17 14:03 IV_20200107_20200131.nc
-rw-rw-r-- 1 kdm 177M Feb 20 12:46 IV_20200119_20200212.nc
#+end_example
 
#+BEGIN_SRC bash :results verbatim :tangle no
(cd ${DIR}; ncdump -h $(ls *.nc | head -n1))
#+END_SRC
#+RESULTS:
#+begin_example
netcdf greenland_iv_250m_s1_s20141001_e20141031_v1_2 {
dimensions:
	y = 10801 ;
	x = 5984 ;
variables:
	int crs ;
		crs:grid_mapping_name = "polar_stereographic" ;
		crs:standard_parallel = 70. ;
		crs:straight_vertical_longitude_from_pole = -45. ;
		crs:false_easting = 0. ;
		crs:false_northing = 0. ;
		crs:unit = "metre" ;
		crs:spatial_ref = "PROJCS[\"WGS 84 / NSIDC Sea Ice Polar Stereographic North\",\n    GEOGCS[\"WGS 84\",\n        DATUM[\"WGS_1984\",\n            SPHEROID[\"WGS 84\",6378137,298.257223563,\n                AUTHORITY[\"EPSG\",\"7030\"]],\n            AUTHORITY[\"EPSG\",\"6326\"]],\n        PRIMEM[\"Greenwich\",0,\n            AUTHORITY[\"EPSG\",\"8901\"]],\n        UNIT[\"degree\",0.0174532925199433,\n            AUTHORITY[\"EPSG\",\"9122\"]],\n        AUTHORITY[\"EPSG\",\"4326\"]],\n    PROJECTION[\"Polar_Stereographic\"],\n    PARAMETER[\"latitude_of_origin\",70],\n    PARAMETER[\"central_meridian\",-45],\n    PARAMETER[\"scale_factor\",1],\n    PARAMETER[\"false_easting\",0],\n    PARAMETER[\"false_northing\",0],\n    UNIT[\"metre\",1,\n        AUTHORITY[\"EPSG\",\"9001\"]],\n    AXIS[\"X\",EAST],\n    AXIS[\"Y\",NORTH],\n    AUTHORITY[\"EPSG\",\"3413\"]]" ;
		crs:latitude_of_projection_origin = 90. ;
	double y(y) ;
		y:units = "m" ;
		y:axis = "Y" ;
		y:long_name = "y coordinate of projection" ;
		y:standard_name = "projection_y_coordinate" ;
	double x(x) ;
		x:units = "m" ;
		x:axis = "X" ;
		x:long_name = "x coordinate of projection" ;
		x:standard_name = "projection_x_coordinate" ;
	float land_ice_surface_easting_velocity(y, x) ;
		land_ice_surface_easting_velocity:_FillValue = 3.402823e+38f ;
		land_ice_surface_easting_velocity:units = "m/day" ;
		land_ice_surface_easting_velocity:description = "easting ice velocity" ;
		land_ice_surface_easting_velocity:grid_mapping = "crs" ;
		land_ice_surface_easting_velocity:coordinates = "y x" ;
	float land_ice_surface_northing_velocity(y, x) ;
		land_ice_surface_northing_velocity:_FillValue = 3.402823e+38f ;
		land_ice_surface_northing_velocity:units = "m/day" ;
		land_ice_surface_northing_velocity:description = "northing ice velocity" ;
		land_ice_surface_northing_velocity:grid_mapping = "crs" ;
		land_ice_surface_northing_velocity:coordinates = "y x" ;
	float land_ice_surface_vertical_velocity(y, x) ;
		land_ice_surface_vertical_velocity:_FillValue = 3.402823e+38f ;
		land_ice_surface_vertical_velocity:units = "m/day" ;
		land_ice_surface_vertical_velocity:description = "vertical ice velocity" ;
		land_ice_surface_vertical_velocity:grid_mapping = "crs" ;
		land_ice_surface_vertical_velocity:coordinates = "y x" ;
	float land_ice_surface_velocity_magnitude(y, x) ;
		land_ice_surface_velocity_magnitude:_FillValue = 3.402823e+38f ;
		land_ice_surface_velocity_magnitude:units = "m/day" ;
		land_ice_surface_velocity_magnitude:description = "magnitude of horizontal ice velocity" ;
		land_ice_surface_velocity_magnitude:grid_mapping = "crs" ;
		land_ice_surface_velocity_magnitude:coordinates = "y x" ;
	int land_ice_surface_measurement_count(y, x) ;
		land_ice_surface_measurement_count:_FillValue = -1 ;
		land_ice_surface_measurement_count:units = "m/day" ;
		land_ice_surface_measurement_count:description = "count of measurements" ;
		land_ice_surface_measurement_count:grid_mapping = "crs" ;
		land_ice_surface_measurement_count:coordinates = "y x" ;
	float land_ice_surface_velocity_stddev(y, x) ;
		land_ice_surface_velocity_stddev:_FillValue = 3.402823e+38f ;
		land_ice_surface_velocity_stddev:units = "m/day" ;
		land_ice_surface_velocity_stddev:description = "standard deviation of ice velocity" ;
		land_ice_surface_velocity_stddev:grid_mapping = "crs" ;
		land_ice_surface_velocity_stddev:coordinates = "y x" ;

// global attributes:
		:comment = "Ice velocity map of Greenland derived from Sentinel-1 SAR data acquired from 2014-10-01 to 2014-10-31. The surface velocity is derived applying feature tracking techniques. The ice velocity map is provided at 250m grid spacing in North Polar Stereographic projection (EPSG: 3413). The horizontal velocity is provided in true meters per day, towards EASTING(vx) and NORTHING(vy) direction of the grid, and the vertical displacement (vz), is derived from a digital elevation model. Provided is a NetCDF file with the velocity components: vx, vy, vz and vv (magnitude of the horizontal components), along with maps showing valid pixel count and uncertainty (std.). The product was generated by Sentinel." ;
		:contact = "http://www.enveo.at/" ;
		:Conventions = "CF-1.7" ;
		:creation_date = "2020-02-04" ;
		:history = "Initial product version 1.2" ;
		:institution = "Sentinel" ;
		:keywords = "EARTH SCIENCE CLIMATE INDICATORS CRYOSPHERIC INDICATORS GLACIAL MEASUREMENTS ICE SHEET VELOCITY CRYOSPHERE GLACIERS/ICE SHEETS" ;
		:license = "general license" ;
		:project = "ESA Greenland Ice Sheet CCI+" ;
		:reference = "Main: Nagler, T.; Rott, H.; Hetzenecker, M.; Wuite, J.; Potin, P. The Sentinel-1 Mission: New Opportunities for Ice Sheet Observations. Remote Sens. 2015, 7, 9371-9389." ;
		:source = "Copernicus Sentinel-1A and Sentinel-1B" ;
		:summary = "Ice velocity derived for Greenland Ice Sheet gridded at sm averaged from 2014-10-01 to 2014-10-31." ;
		:title = "Ice Velocity of the Greenland Ice Sheet" ;
}
#+end_example

#+BEGIN_SRC bash :results table :tangle no
(cd ${DIR}; parallel "md5sum {}" ::: $(ls *.nc|head -n8))
#+END_SRC

#+RESULTS:
| ff0b16030be15cff201e5a540ef52848 | greenland_iv_250m_s1_s20141101_e20141130_v1_2.nc |
| e2af090c797fcc4bba8d62cf1933f49c | greenland_iv_250m_s1_s20141201_e20141231_v1_2.nc |
| 40d53f823e1a01e393fca2565eff5c1d | greenland_iv_250m_s1_s20141001_e20141031_v1_2.nc |
| 385e0a91654d3db8519ceb615b636436 | greenland_iv_250m_s1_s20150401_e20150430_v1_2.nc |
| 420a6f7617e2faefbb24f8afb3d456af | greenland_iv_250m_s1_s20150301_e20150331_v1_2.nc |
| 404ab716763f17524d318614b33bef2b | greenland_iv_250m_s1_s20150501_e20150531_v1_2.nc |
| 2bf634332b30fb6400cb3609fdd8972d | greenland_iv_250m_s1_s20150101_e20150131_v1_2.nc |
| d54cb3333feb08bfaac216f20371ae89 | greenland_iv_250m_s1_s20150201_e20150228_v1_2.nc |

**** Import data
+ Read in all the data
+ Convert from [m day-1] to [m year-1]
#+BEGIN_SRC bash :results verbatim
MSG_OK "Sentinel 1"
g.mapset -c Sentinel1
ROOT=${DATADIR}/Sentinel1/Sentinel1_IV_maps

find ${ROOT} -name "*.nc"
# FILE=$(find ${ROOT} -name "*.nc"|head -n1) # testing

FILE=$(find ${ROOT} -name "*.nc" | head -n1) # DEBUG
for FILE in $(find ${ROOT} -name "*.nc"); do
  T=$(ncdump -v time $FILE | tail -n2 | tr -dc '[0-9]')
  DATE=$(date --date="1990-01-01 +${T} days" --iso-8601)
  DATE_STR=$(echo ${DATE} | sed s/-/_/g)
  echo $DATE

  r.external -o source="NetCDF:${FILE}:land_ice_surface_easting_velocity" output=vx_${DATE_STR}
  r.external -o source="NetCDF:${FILE}:land_ice_surface_northing_velocity" output=vy_${DATE_STR}
  r.external -o source="NetCDF:${FILE}:land_ice_surface_easting_velocity_std" output=ex_${DATE_STR}
  r.external -o source="NetCDF:${FILE}:land_ice_surface_northing_velocity_std" output=ey_${DATE_STR}
done
#+END_SRC
#+RESULTS:


*** Glacier Names
+ From [[textcite:Bjork:2015Brief][Bjørk /et al./ (2015)]].
+ Also use citet:mouginot_2019_glacier
**** Bjørk 2015
+ Write out x,y,name. Can use x,y and mean gate location to find closest name for each gate.
#+BEGIN_SRC bash :results verbatim
MSG_OK "Bjørk 2015"
g.mapset -c Bjork_2015

ROOT=${DATADIR}/Bjork_2015/

cat ${ROOT}/GreenlandGlacierNames_GGNv01.csv |  iconv -c -f utf-8 -t ascii | grep GrIS | awk -F';' '{print $3"|"$2"|"$7}' | sed s/,/./g | m.proj -i input=- | sed s/0.00\ //g | v.in.ascii input=- output=names columns="x double precision, y double precision, name varchar(99)"

# db.select table=names | tr '|' ',' > ./tmp/Bjork_2015_names.csv
#+END_SRC
#+RESULTS:
**** Mouginot 2019
#+BEGIN_SRC bash :results verbatim
g.mapset Mouginot_2019
db.select table=sectors | head
# v.out.ascii -c input=sectors output=./tmp/Mouginot_2019_names.csv columns=NAME,SUBREGION1
#+END_SRC
#+RESULTS:


*** SEC

Using CCI SEC data from citet:simonsen_2017_implications,sørensen_2015_envisat,khvorostovsky_2012_merging,CCI_SEC.

+ This NetCDF file is malformed and needs some dimensions swapped before GDAL can read it.
+ Thanks: https://stackoverflow.com/questions/47642695/how-can-i-swap-the-dimensions-of-a-netcdf-file

#+BEGIN_SRC bash :results verbatim
g.mapset -c SEC

ls ${DATADIR}/SEC/Release/CCI_GrIS_RA_SEC_5km_Vers3.0_2021-08-09.nc
INFILE=${DATADIR}/SEC/Release/CCI_GrIS_RA_SEC_5km_Vers3.0_2021-08-09.nc
ncdump -chs ${INFILE}
ncdump -v x ${INFILE}
ncdump -v y ${INFILE}

g.region w=-739301.625 e=880698.375 s=-3478140.75 n=-413140.75 res=5000 -p
g.region w=w-2500 e=e+2500 n=n+2500 s=s-2500 -pa

ncap2 --overwrite -s 'SEC2=SEC.permute($t,$y,$x)' ${INFILE} ./tmp/SEC.nc
INFILE=./tmp/SEC.nc

# ncdump -p 9,5 ./tmp/SEC.nc |less
for i in $(seq 24); do
  d0=$(( ${i}+1991 ))-01-01
  d1=$(( ${i}+1996 ))-01-01
  n0=$(echo $d0 | sed s/-//g)
  n1=$(echo $d1 | sed s/-//g)
  OUTFILE=SEC_${n0}_${n1}
  echo $OUTFILE
  r.external -o source=NetCDF:${INFILE}:SEC2 band=${i} output=${OUTFILE}
  r.region -c map=${OUTFILE}
done
#+END_SRC
#+RESULTS:

**** Define annual values
#+BEGIN_SRC bash :results verbatim
r.mapcalc "dh_1992 = SEC_19920101_19970101"
r.mapcalc "dh_1993 = SEC_19920101_19970101"
r.mapcalc "dh_1994 = SEC_19920101_19970101"
r.mapcalc "dh_1995 = SEC_19930101_19980101"
r.mapcalc "dh_1996 = SEC_19940101_19990101"
r.mapcalc "dh_1997 = SEC_19950101_20000101"
r.mapcalc "dh_1998 = SEC_19960101_20010101"
r.mapcalc "dh_1999 = SEC_19970101_20020101"
r.mapcalc "dh_2000 = SEC_19980101_20030101"
r.mapcalc "dh_2001 = SEC_19990101_20040101"
r.mapcalc "dh_2002 = SEC_20000101_20050101"
r.mapcalc "dh_2003 = SEC_20010101_20060101"
r.mapcalc "dh_2004 = SEC_20020101_20070101"
r.mapcalc "dh_2005 = SEC_20030101_20080101"
r.mapcalc "dh_2006 = SEC_20040101_20090101"
r.mapcalc "dh_2007 = SEC_20050101_20100101"
r.mapcalc "dh_2008 = SEC_20060101_20110101"
r.mapcalc "dh_2009 = SEC_20070101_20120101"
r.mapcalc "dh_2010 = SEC_20080101_20130101"
r.mapcalc "dh_2011 = SEC_20090101_20140101"
r.mapcalc "dh_2012 = SEC_20100101_20150101"
r.mapcalc "dh_2013 = SEC_20110101_20160101"
r.mapcalc "dh_2014 = SEC_20120101_20170101"
r.mapcalc "dh_2015 = SEC_20130101_20180101"
r.mapcalc "dh_2016 = SEC_20140101_20190101"
r.mapcalc "dh_2017 = SEC_20150101_20200101"
r.mapcalc "dh_2018 = SEC_20150101_20200101"
r.mapcalc "dh_2019 = SEC_20150101_20200101"
r.mapcalc "dh_2020 = SEC_20150101_20200101"
r.mapcalc "dh_2021 = SEC_20150101_20200101"

seq 1992 2021 | parallel --bar --progress "r.null map=dh_{} null=0" --quiet
#+END_SRC
**** COMMENT Coverage Percent?
#+BEGIN_SRC bash :results verbatim

r.univar -r mask_ice@BedMachine # 44351066 cells
g.region -up raster=mask_ice@BedMachine # res = 200
frink "44351066 * (200 m) * (200 m) -> \"km^2\"" # 1.774 million km^2

g.region -up # res = 5000
r.univar -r SEC_20150101_20170101 # 64062 non-null cells
frink "64062 * (5000 m) * (5000 m) -> \"km^2\"" # 1.601 million km^2
frink "1.601/1.774*100" # 10 % missing

r.univar -r SEC_19970101_20020101 # 60600
frink "60600 * (5000 m) * (5000 m) -> \"km^2\"" # 1.515 million km^2
frink "1.515/1.774*100" # 15 % missing
#+END_SRC
#+RESULTS:

** Find Gates
:PROPERTIES:
:header-args:bash+: :tangle gate_IO.sh
:END:

*** Algorithm
+ [X] Find all fast-moving ice (>X m yr^{-1})
  + Results not very sensitive to velocity limit (10 to 100 m yr^{-1} examined)
+ [X] Find grounding line by finding edge cells where fast-moving ice borders water or ice shelf based (loosely) on BedMachine mask
+ [X] Move grounding line cells inland by X km, again limiting to regions of fast ice.
  + Results not very sensitive to gate position (1 - 5 km range examined)

+ [X] Discard gates if group size \in [1,2]
+ [X] Manually clean a few areas (e.g. land-terminating glaciers, gates due to invalid masks, etc.) by manually selecting invalid regions in Google Earth, then remove gates in these regions

Note that "fast ice" refers to flow velocity, not the sea ice term of "stuck to the land".

INSTRUCTIONS: Set VELOCITY_CUTOFF and BUFFER_DIST to 50 and 2500 respectively and run the code. Then repeat for a range of other velocity cutoffs and buffer distances to get a range of sensitivities.

OR: Tangle via ((org-babel-tangle) the code below (C-c C-v C-t or ) to [[./gate_IO.sh]] and then run this in a GRASS session:1

#+BEGIN_SRC bash :results verbatim :tangle gate_IO_runner.sh
<<MSGS_pretty_print>>
<<GRASS_config>>

# 1000: clean results, but too few
# 500: clean results, still too few
# 250: looks good, but 15 Gt < Mankoff 2019. Maybe missing some outlets?
# 150:
VELOCITY_CUTOFF=150
BUFFER_DIST=10000
. ./gate_IO.sh
#+END_SRC
#+RESULTS:

Create a new mapset for this specific velocity cutoff and buffer distance

#+BEGIN_SRC bash :results verbatim
g.mapset -c gates_${VELOCITY_CUTOFF}_${BUFFER_DIST}
g.region -d
#+END_SRC

From above:

+ [X] Find grounding line by finding edge cells where fast-moving ice borders water or ice shelf based (loosely) on BedMachine mask

The "loosely" is because the BedMachine mask doesn't always reach into each fjord all the way. I buffer the BedMachine mask by 2 km here so that it extends to the edge of the velocity data.

#+BEGIN_SRC bash :results verbatim
g.copy raster=mask_ice@BedMachine,mask_ice --o
# Grow by 2 km (10 cells @ 200 m/cell)
r.grow input=mask_ice output=mask_ice_grow radius=10 new=1 --o
r.mask mask_ice_grow
#+END_SRC

The fast ice edge is where there is fast-flowing ice overlapping with not-ice.

#+BEGIN_SRC bash :results verbatim
r.mapcalc "fast_ice = if(vel_baseline@ENVEO > ${VELOCITY_CUTOFF}, 1, null())" --o
r.mapcalc "fast_ice_100 = if(vel_baseline@ENVEO > 100, 1, null())" --o
r.mask -r

# no velocity data, or is flagged as ice shelf or land in BedMachine
r.mapcalc "not_ice = if(isnull(vel_baseline@ENVEO) ||| (mask@BedMachine == 0) ||| (mask@BedMachine == 3), 1, null())" --o

r.grow input=not_ice output=not_ice_grow radius=1.5 new=99 --o
r.mapcalc "fast_ice_edge = if(((not_ice_grow == 99) && (fast_ice == 1)), 1, null())" --o
#+END_SRC

The gates are set ${BUFFER_DIST} inland from the fast ice edge. This is done by buffering the fast ice edge (which fills the space between the fast ice edge and buffer extent) and then growing the buffer by 1. This last step defines the gate locations.

However, in order to properly estimate discharge, the gate location is not enough. Ice must flow from outside the gates, through the gates, to inside the gates, and not flow from one gate pixel to another gate pixel (or it would be counted 2x). 

#+BEGIN_SRC bash :results verbatim
r.buffer input=fast_ice_edge output=fast_ice_buffer distances=${BUFFER_DIST} --o
r.grow input=fast_ice_buffer output=fast_ice_buffer_grow radius=1.5 new=99 --o
r.mask -i not_ice --o
r.mapcalc "gates_inside = if(((fast_ice_buffer_grow == 99) && (fast_ice_100 == 1)), 1, null())" --o
r.mask -r

r.grow input=gates_inside output=gates_inside_grow radius=1.1 new=99 --o
r.mask -i not_ice --o
r.mapcalc "gates_maybe = if(((gates_inside_grow == 99) && (fast_ice_100 == 1) && isnull(fast_ice_buffer)), 1, null())" --o
r.mask -r

r.grow input=gates_maybe output=gates_maybe_grow radius=1.1 new=99 --o
r.mask -i not_ice --o
r.mapcalc "gates_outside = if(((gates_maybe_grow == 99) && (fast_ice_100 == 1) && isnull(fast_ice_buffer) && isnull(gates_inside)), 1, null())" --o
r.mask -r

r.mapcalc "gates_IO = 0" --o
r.mapcalc "gates_IO = if(isnull(gates_inside), gates_IO, 1)" --o
r.mapcalc "gates_IO = if(isnull(gates_outside), gates_IO, -1)" --o

r.colors map=gates_inside color=red
r.colors map=gates_maybe color=grey
r.colors map=gates_outside color=blue
r.colors map=gates_IO color=viridis
#+END_SRC
#+RESULTS:

+ For each gate, split into two for the vector components of the velocity, then...
+ If flow is from gate to INSIDE, it is discharged
+ If flow is from gate to GATE, it is ignored
+ If flow is from gate to NOT(GATE || INSIDE) it is ignored
  + If gates are a closed loop, such as the 1700 m flight-line, then
    this scenario would be NEGATIVE discharge, not ignored. This was
    tested with the 1700 m flight-line and compared against both the
    vector calculations and WIC estimates.

#+NAME: tbl_velocity
| var            | value  | meaning           |
|----------------+--------+-------------------|
| vx             | > 0    | east / right      |
| vx             | < 0    | west / left       |
| vy             | > 0    | north / up        |
| vy             | < 0    | south / down      |
|----------------+--------+-------------------|
| GRASS indexing | [0,1]  | cell to the right |
|                | [0,-1] | left              |
|                | [-1,0] | above             |
|                | [1,0]  | below             |

#+BEGIN_SRC bash :results verbatim
# g.mapset -c gates_50_2500

r.mask -r

r.mapcalc "gates_x = 0" --o
r.mapcalc "gates_x = if((gates_maybe == 1) && (vx_baseline@ENVEO > 0), gates_IO[0,1], gates_x)" --o
r.mapcalc "gates_x = if((gates_maybe != 0) && (vx_baseline@ENVEO < 0), gates_IO[0,-1], gates_x)" --o

r.mapcalc "gates_y = 0" --o
r.mapcalc "gates_y = if((gates_maybe != 0) && (vy_baseline@ENVEO > 0), gates_IO[-1,0], gates_y)" --o
r.mapcalc "gates_y = if((gates_maybe != 0) && (vy_baseline@ENVEO < 0), gates_IO[1,0], gates_y)" --o

r.mapcalc "gates_x = if(gates_x == 1, 1, 0)" --o
r.mapcalc "gates_y = if(gates_y == 1, 1, 0)" --o

r.null map=gates_x null=0 # OR r.null map=gates_x setnull=0
r.null map=gates_y null=0 # OR r.null map=gates_y setnull=0
#+END_SRC
*** Clean Gates                                                    :noexport:
**** Subset to where there is known discharge
#+BEGIN_SRC bash :results verbatim
r.mapcalc "gates_xy_clean0 = if((gates_x == 1) || (gates_y == 1), 1, null())" --o
r.colors map=gates_xy_clean0 color=haxby
#+END_SRC
#+RESULTS:

**** Remove small areas (clusters <X cells)
#+BEGIN_SRC bash :results verbatim
# Remove clusters of 2 or less. How many hectares in X pixels?
# frink "(200 m)^2 * 2 -> hectares" # ans: 8.0

r.clump -d input=gates_xy_clean0 output=gates_gateID --o
r.reclass.area -d input=gates_gateID output=gates_area value=9 mode=lesser method=reclass --o

r.mapcalc "gates_xy_clean1 = if(isnull(gates_area), gates_xy_clean0, null())" --o
#+END_SRC
#+RESULTS:


**** Limit to Mouginot 2019 mask
+ Actually, limit to approximate Mouginot 2019 mask - its a bit narrow in some places
#+BEGIN_SRC bash :results verbatim
# r.mask mask_GIC@Mouginot_2019 --o
r.grow input=mask_GIC@Mouginot_2019 output=mask_GIC_Mouginot_2019_grow radius=4.5 # three cells
r.mask mask_GIC_Mouginot_2019_grow --o
r.mapcalc "gates_xy_clean2 = gates_xy_clean1" --o
r.mask -r

# r.univar map=gates_xy_clean1
# r.univar map=gates_xy_clean2
#+END_SRC

**** COMMENT Remove areas from manually-drawn KML mask
+ See [[./dat/remove_manual.kml]]
#+BEGIN_SRC bash :results verbatim
v.import input=./dat/remove_manual.kml output=remove_manual --o
r.mask -i vector=remove_manual --o
r.mapcalc "gates_xy_clean3 = gates_xy_clean2" --o
r.mask -r

r.univar map=gates_xy_clean2
r.univar map=gates_xy_clean3
#+END_SRC
#+RESULTS:

*** Final Gates
#+BEGIN_SRC bash :results verbatim
MSG_ERR "No manual removal -> No clean3 -> expecting ERROR"
g.copy "gates_xy_clean3,gates_final" --o
# MSG_WARN "Using clean2"
g.copy "gates_xy_clean2,gates_final" --o
#+end_src
#+RESULTS:

*** Add meta-data to gates
Add:
+ Gate ID
+ Calculate the average x,y of the gate, and then from that ONE point, determine the following. Do this from the average point rather than for each gate pixel because some gates span multiple sectors, or different ends of the gate are nearer different names, etc.
  + Average lon,lat of gate
  + Nearest citet:mouginot_2019_glacier region, sector, and name
  + Nearest citet:bjork_2015_brief name

Do this for both the area vector and the point vector so that we can export
+ KML and GeoPackage with gates and metadata
+ simple CSV w/ gates and metadata.

**** Gate ID
#+BEGIN_SRC bash :results verbatim

# db.droptable -f table=gates_final
# db.droptable -f table=gates_final_pts

# areas (clusters of gate pixels, but diagonals are separate)
r.to.vect input=gates_final output=gates_final type=area --o
v.db.dropcolumn map=gates_final column=label
v.db.dropcolumn map=gates_final column=value
v.db.addcolumn map=gates_final columns="gate INT"
v.what.rast map=gates_final raster=gates_gateID column=gate type=centroid

# # points (each individual gate pixel)
# r.to.vect input=gates_final output=gates_final_pts type=point --o
# v.db.dropcolumn map=gates_final_pts column=label
# v.db.dropcolumn map=gates_final_pts column=value
# v.db.addcolumn map=gates_final_pts columns="gate INT"
# v.what.rast map=gates_final_pts raster=gates_gateID column=gate type=point
#+END_SRC
#+RESULTS:
**** Mean x,y
#+BEGIN_SRC bash :results verbatim
# v.db.addcolumn map=gates_final columns="x INT, y INT, mean_x INT, mean_y INT, area INT"
v.db.addcolumn map=gates_final columns="mean_x INT, mean_y INT"
v.to.db map=gates_final option=coor columns=x,y units=meters
v.to.db map=gates_final option=area columns=area units=meters

for G in $(db.select -c sql="select gate from gates_final"|sort -n|uniq); do
  db.execute sql="UPDATE gates_final SET mean_x=(SELECT AVG(x) FROM gates_final WHERE gate == ${G}) where gate == ${G}"
  db.execute sql="UPDATE gates_final SET mean_y=(SELECT AVG(y) FROM gates_final WHERE gate == ${G}) where gate == ${G}"
done

v.out.ascii -c input=gates_final columns=gate,mean_x,mean_y | cut -d"|" -f4- | sort -n|uniq | v.in.ascii input=- output=gates_final_pts skip=1 cat=1 x=2 y=3 --o
v.db.addtable gates_final_pts
v.db.addcolumn map=gates_final_pts columns="gate INT"
v.db.update map=gates_final_pts column=gate query_column=cat

# v.db.addcolumn map=gates_final_pts columns="mean_x INT, mean_y INT"
v.to.db map=gates_final_pts option=coor columns=mean_x,mean_y units=meters
#+END_SRC
#+RESULTS:

Here we have:
#+BEGIN_SRC bash :results verbatim :tangle no
db.select table=gates_final|head -n10 # cat|gate|x|y|mean_x|mean_y
db.select table=gates_final_pts|head # cat|gate|mean_x|mean_y
#+END_SRC
#+RESULTS:

**** Mean lon,lat
#+BEGIN_SRC bash :results verbatim
v.what.rast map=gates_final_pts raster=lon@PERMANENT column=lon
v.what.rast map=gates_final_pts raster=lat@PERMANENT column=lat

v.db.addcolumn map=gates_final columns="mean_lon DOUBLE PRECISION, mean_lat DOUBLE PRECISION"
for G in $(db.select -c sql="select gate from gates_final"|sort -n|uniq); do
    db.execute sql="UPDATE gates_final SET mean_lon=(SELECT lon FROM gates_final_pts WHERE gate = ${G}) where gate = ${G}"
    db.execute sql="UPDATE gates_final SET mean_lat=(SELECT lat FROM gates_final_pts WHERE gate = ${G}) where gate = ${G}"
done
#+END_SRC
#+RESULTS:

**** Sector, Region, Names, etc.
+ Sector Number
+ Region Code
+ Nearest Sector or Glacier Name
#+BEGIN_SRC bash :results verbatim
v.db.addcolumn map=gates_final columns="sector INT"
v.db.addcolumn map=gates_final_pts columns="sector INT"
v.distance from=gates_final to=sectors@Mouginot_2019 upload=to_attr column=sector to_column=cat
v.distance from=gates_final_pts to=sectors@Mouginot_2019 upload=to_attr column=sector to_column=cat

v.db.addcolumn map=gates_final columns="region VARCHAR(2)"
v.db.addcolumn map=gates_final_pts columns="region VARCHAR(2)"
v.distance from=gates_final to=sectors@Mouginot_2019 upload=to_attr column=region to_column=SUBREGION1
v.distance from=gates_final_pts to=sectors@Mouginot_2019 upload=to_attr column=region to_column=SUBREGION1

v.db.addcolumn map=gates_final columns="Mouginot_2019 VARCHAR(99)"
v.db.addcolumn map=gates_final_pts columns="Mouginot_2019 VARCHAR(99)"
v.distance from=gates_final to=sectors@Mouginot_2019 upload=to_attr column=Mouginot_2019 to_column=NAME
v.distance from=gates_final_pts to=sectors@Mouginot_2019 upload=to_attr column=Mouginot_2019 to_column=NAME

v.db.addcolumn map=gates_final columns="Bjork_2015 VARCHAR(99)"
v.db.addcolumn map=gates_final_pts columns="Bjork_2015 VARCHAR(99)"
v.distance from=gates_final to=names@Bjork_2015 upload=to_attr column=Bjork_2015 to_column=name
v.distance from=gates_final_pts to=names@Bjork_2015 upload=to_attr column=Bjork_2015 to_column=name


v.db.addcolumn map=gates_final columns="n_pixels INT"
v.db.addcolumn map=gates_final_pts columns="n_pixels INT"
for G in $(db.select -c sql="select gate from gates_final"|sort -n|uniq); do
    db.execute sql="UPDATE gates_final SET n_pixels=(SELECT SUM(area)/(200*200) FROM gates_final WHERE gate = ${G}) where gate = ${G}"
    # now copy that to the average gate location (point) table
    db.execute sql="UPDATE gates_final_pts SET n_pixels = (SELECT n_pixels FROM gates_final WHERE gate = ${G}) WHERE gate = ${G}"
done
#+END_SRC
**** Clean up
#+BEGIN_SRC bash :results verbatim
db.dropcolumn -f table=gates_final column=area
# db.dropcolumn -f table=gates_final column=cat
#+END_SRC
#+RESULTS:

**** Export as metadata CSV
#+BEGIN_SRC bash :results verbatim
mkdir -p out
db.select sql="SELECT gate,mean_x,mean_y,lon,lat,n_pixels,sector,region,Bjork_2015,Mouginot_2019 from gates_final_pts" separator=, | sort -n | uniq  > ./out/gate_meta.csv
#+END_SRC
#+RESULTS:

*** Export Gates to KML
#+BEGIN_SRC bash :results verbatim
v.out.ogr input=gates_final output=./tmp/gates_final_${VELOCITY_CUTOFF}_${BUFFER_DIST}.kml format=KML --o
#+END_SRC
#+RESULTS:


** Effective Velocity
:PROPERTIES:
:header-args:bash+: :tangle vel_eff.sh
:END:

#+BEGIN_SRC bash :results verbatim
<<MSGS_pretty_print>>
<<GRASS_config>>
#+END_SRC
#+RESULTS:


*** ENVEO
#+BEGIN_SRC bash :results verbatim
g.mapsets -l

r.mask -r

MAPSET=$(g.mapsets --q -l separator=newline| grep "gates_")

g.mapset ENVEO
g.region -d
r.mapcalc "MASK = if((gates_x@${MAPSET} == 1) | (gates_y@${MAPSET} == 1), 1, null())" --o
VX=$(g.list type=raster pattern=vx_????_??_?? | head -n1) # DEBUG
for VX in $(g.list type=raster pattern=vx_????_??_??); do
  VY=${VX/vx/vy}
  ERR=${VX/vx/err}
  DATE=$(echo $VX | cut -d"_" -f2-)
  echo $DATE
  r.mapcalc "vel_eff_${DATE} = 365 * (if(gates_x@${MAPSET} == 1, if(isnull(${VX}), 0, abs(${VX}))) + if(gates_y@${MAPSET}, if(isnull(${VY}), 0, abs(${VY}))))"
  r.mapcalc "err_eff_${DATE} = 365 * ${ERR} * (not(isnull(gates_x@${MAPSET})) || not(isnull(gates_y@${MAPSET})))"
  r.null map=vel_eff_${DATE} null=0
  r.null map=err_eff_${DATE} null=0
done

# fix return code of this script so make continues
MSG_OK "vel_eff DONE" 
#+END_SRC
#+RESULTS:

*** COMMENT Sentinel 1
#+BEGIN_SRC bash :results verbatim :tangle no
g.mapsets -l

r.mask -r

MAPSET=$(g.mapsets --q -l separator=newline| grep "gates_")

g.mapset Sentinel1
g.region -d
r.mapcalc "MASK = if((gates_x@${MAPSET} == 1) | (gates_y@${MAPSET} == 1), 1, null())" --o
VX=$(g.list type=raster pattern=vx_????_??_?? | head -n1) # DEBUG
for VX in $(g.list type=raster pattern=vx_????_??_??); do
  VY=${VX/vx/vy}
  EX=${VX/vx/ex}
  EY=${VX/vx/ey}
  DATE=$(echo $VX | cut -d"_" -f2-)
  echo $DATE
  r.mapcalc "vel_eff_${DATE} = 365 * (if(gates_x@${MAPSET} == 1, if(isnull(${VX}), 0, abs(${VX}))) + if(gates_y@${MAPSET}, if(isnull(${VY}), 0, abs(${VY}))))"
  r.mapcalc "err_eff_${DATE} = 365 * (if(gates_x@${MAPSET} == 1, if(isnull(${EX}), 0, abs(${EX}))) + if(gates_y@${MAPSET}, if(isnull(${EY}), 0, abs(${EY}))))"
  r.null map=vel_eff_${DATE} null=0
  r.null map=err_eff_${DATE} null=0
done

# fix return code of this script so make continues
MSG_OK "vel_eff DONE" 
#+END_SRC
#+RESULTS:

** Export all data to CSV
:PROPERTIES:
:header-args:bash+: :tangle export.sh
:END:

#+BEGIN_SRC bash :results verbatim
<<MSGS_pretty_print>>
<<GRASS_config>>
#+END_SRC
#+RESULTS:

#+BEGIN_SRC bash :results output
MSG_OK "Exporting..."
g.mapset PERMANENT
g.region -dp

MAPSET=$(g.mapsets --q -l separator="\n"| grep "gates_")

VEL_baseline=vel_baseline@ENVEO,vx_baseline@ENVEO,vy_baseline@ENVEO,vel_err_baseline@ENVEO,err_baseline@ENVEO
VEL_ENVEO=$(g.list -m mapset=ENVEO type=raster pattern=vel_eff_????_??_?? separator=,)
ERR_ENVEO=$(g.list -m mapset=ENVEO type=raster pattern=err_eff_????_??_?? separator=,)
VEL_Sentinel=$(g.list -m mapset=Sentinel1 type=raster pattern=vel_eff_????_??_?? separator=,)
ERR_Sentinel=$(g.list -m mapset=Sentinel1 type=raster pattern=err_eff_????_??_?? separator=,)
THICK=$(g.list -m mapset=SEC type=raster pattern=dh_???? separator=,)
# GIMP_0715=dem@GIMP.0715,day@GIMP.0715 # ,err@GIMP.0715

LIST=lon,lat,err_2D,gates_x@${MAPSET},gates_y@${MAPSET},gates_gateID@${MAPSET},sectors@Zwally_2012,sectors@Mouginot_2019,regions@Mouginot_2019,bed@BedMachine,thickness@BedMachine,surface@BedMachine,${THICK},${VEL_baseline},${VEL_ENVEO},errbed@BedMachine,${ERR_ENVEO}

# ,${VEL_Sentinel},${ERR_Sentinel}

r.mask gates_final@${MAPSET} --o

# test
# for v in $(echo $LIST | tr ',' '\n'); do n=$(r.univar $v|grep "^n:"); echo ${v}: ${n}; done

date
MSG_WARN "Exporting: $(echo $LIST|tr ',' '\n' |wc -l) columns"
ulimit -n 2048
time (echo x,y,${LIST}; r.out.xyz input=${LIST} separator=comma) > ./tmp/dat.csv
r.mask -r
#+END_SRC
#+RESULTS:
** Compute Errors
:PROPERTIES:
:header-args:python+: :tangle errors.py
:END:

*** Results (Mouginot 2019 Sector)
#+BEGIN_SRC python :results raw drawer :session discharge :display text/org
from uncertainties import unumpy
import pandas as pd
import numpy as np

df = pd.read_csv("./tmp/dat.csv")

err_sector = pd.DataFrame(columns=['D', 'E', 'E%'])
err_sector.index.name = 'Sector'

sectors = np.unique(df['sectors@Mouginot_2019'].values)
for s in sectors:
    sub = df[df['sectors@Mouginot_2019'] == s]
    thick = sub['thickness@BedMachine']
    vel = sub['vel_baseline@ENVEO']
    D = 200  * thick * vel * 917 / 1E12
    err_thick = np.abs(sub['errbed@BedMachine'].values)
    e_th = 200 * err_thick * vel * 917 / 1E12
    err_sector.loc[s] = [np.sum(D), np.sum(e_th), np.round(np.sum(e_th),10)/np.round(np.sum(D),10)*100]

err_sector.loc['GIS'] = np.sum(err_sector, axis=0)
err_sector.loc['GIS']['E%'] = err_sector.loc['GIS']['E']/err_sector.loc['GIS']['D']*100

err_sector.to_csv('./tmp/err_sector_mouginot.csv')

err_sector.rename(columns = {'D':'D [Gt]',
                             'E':'Error [Gt]',
                             'E%':'Error [%]'}, inplace=True)

err_sector
#+END_SRC

#+RESULTS:
| Sector |      D [Gt] | Error [Gt] | Error [%] |
|--------+-------------+------------+-----------|
|      1 |     1.13636 |   0.115502 |   10.1642 |
|      2 |    0.908778 |   0.193401 |   21.2815 |
|      3 |     11.4881 |   0.824422 |    7.1763 |
|      4 |     2.91582 |   0.304107 |   10.4296 |
|      6 |     10.8265 |   0.919606 |   8.49401 |
|      7 |     0.89246 |  0.0744315 |   8.34004 |
|      8 |    0.648552 |  0.0401655 |    6.1931 |
|      9 |     11.2917 |   0.627721 |   5.55913 |
|     10 |     2.16995 |   0.123117 |   5.67372 |
|     14 |     2.48669 |   0.199724 |   8.03172 |
|     15 |     1.06562 |   0.294537 |     27.64 |
|     16 |     5.45103 |   0.440319 |   8.07772 |
|     19 |    0.270501 |   0.110674 |   40.9145 |
|     20 |    0.767355 |  0.0492437 |   6.41734 |
|     21 |     1.80726 |  0.0974649 |   5.39296 |
|     22 |     1.00093 |  0.0841373 |   8.40591 |
|     23 |    0.895347 |  0.0683989 |   7.63937 |
|     25 |    0.029346 | 0.00512194 |   17.4536 |
|     26 |     1.67654 |  0.0936123 |   5.58367 |
|     27 |     6.05449 |   0.273441 |   4.51633 |
|     28 |    0.805786 |   0.032577 |   4.04289 |
|     29 |     1.96217 |   0.116086 |   5.91621 |
|     30 |     1.83275 |   0.116705 |   6.36774 |
|     31 |    0.422771 |  0.0319242 |   7.55119 |
|     32 |     5.59584 |   0.344155 |   6.15018 |
|     33 |     6.38654 |    0.46026 |   7.20672 |
|     34 |     4.70521 |   0.364038 |   7.73692 |
|     35 |     7.01158 |   0.895814 |   12.7762 |
|     36 |     8.79645 |   0.644694 |   7.32903 |
|     37 |      8.2441 |   0.472339 |   5.72942 |
|     38 |     6.32872 |   0.440766 |   6.96455 |
|     41 |     2.23386 |   0.127442 |     5.705 |
|     42 |    0.803985 |  0.0512305 |   6.37207 |
|     43 |     3.68078 |   0.189515 |   5.14878 |
|     44 |    0.877821 |  0.0481893 |   5.48964 |
|     45 |    0.766472 |  0.0488558 |   6.37412 |
|     47 |     1.41008 |   0.135603 |   9.61666 |
|     48 |     2.50234 |   0.329722 |   13.1765 |
|     49 |    0.966754 |  0.0940565 |    9.7291 |
|     50 |     6.28814 |     0.2806 |   4.46237 |
|     53 |     3.90265 |   0.262703 |   6.73141 |
|     55 |    0.109432 |  0.0276098 |   25.2302 |
|     56 |    0.786596 |   0.154163 |   19.5988 |
|     58 |     11.4567 |   0.688932 |   6.01334 |
|     59 |      15.567 |    1.29056 |   8.29037 |
|     60 |      9.0555 |   0.608475 |   6.71939 |
|     61 |     2.24076 |   0.395304 |   17.6415 |
|     62 |    0.593675 |  0.0322815 |   5.43757 |
|     63 |     30.3913 |    2.99546 |   9.85631 |
|     64 |     5.03947 |   0.422238 |   8.37862 |
|     65 |     3.80811 |  0.0994075 |   2.61042 |
|     67 |    0.202655 |   0.703541 |   347.162 |
|     68 |     3.68474 |  0.0750308 |   2.03626 |
|     69 |     2.22766 |   0.171304 |   7.68986 |
|     70 |    0.650101 |   0.422143 |   64.9349 |
|     72 |     1.10276 |  0.0672873 |   6.10169 |
|     73 |  0.00110613 |   0.188115 |   17006.6 |
|     74 |     4.35112 |   0.399408 |   9.17943 |
|     75 |    0.145543 |    0.04469 |   30.7057 |
|     76 |     1.70487 |   0.239754 |   14.0629 |
|     78 |     2.55006 |   0.109305 |   4.28638 |
|     80 |     7.38191 |   0.550931 |   7.46325 |
|     81 |     6.02572 |   0.468044 |   7.76742 |
|     82 |     1.33453 |   0.122178 |   9.15508 |
|     83 |     4.15658 |   0.507123 |   12.2005 |
|     84 |     1.60693 |   0.176951 |   11.0117 |
|     86 |     6.56638 |     0.6114 |   9.31107 |
|     88 |   0.0161452 |  0.0435953 |    270.02 |
|     93 |     2.04422 |   0.118953 |   5.81902 |
|     94 |     1.18427 |   0.332161 |   28.0477 |
|     95 |     8.83575 |   0.289838 |   3.28029 |
|     96 |     5.06139 |   0.641972 |   12.6837 |
|     97 |  0.00532853 |  0.0315232 |   591.593 |
|     98 |     1.69358 |   0.297288 |   17.5538 |
|     99 | 6.75698e-05 | 0.00849267 |   12568.7 |
|    100 |    0.184706 |   0.121455 |   65.7562 |
|    102 |     23.1246 |    1.23201 |    5.3277 |
|    103 |    0.154002 |  0.0160936 |   10.4503 |
|    104 |     0.49088 |  0.0520854 |   10.6106 |
|    106 |     14.9256 |   0.466246 |    3.1238 |
|    107 |     3.84582 |   0.339018 |   8.81522 |
|    108 |    0.595502 |   0.165221 |   27.7449 |
|    109 |   0.0884075 |   0.042508 |    48.082 |
|    110 |    0.205879 |  0.0211271 |   10.2619 |
|    111 |  0.00582636 |   0.393715 |   6757.48 |
|    113 | 0.000794878 |   0.100536 |     12648 |
|    114 |     1.38749 |   0.120317 |   8.67155 |
|    115 |    0.897201 |    0.20931 |   23.3292 |
|    117 |     6.98255 |   0.525467 |   7.52543 |
|    118 | 0.000957382 |   0.166821 |   17424.7 |
|    120 |    0.412083 |   0.102889 |   24.9682 |
|    121 |     2.25015 |   0.512606 |   22.7809 |
|    122 |   0.0492951 |   0.488022 |   990.001 |
|    124 |  0.00105356 |   0.171178 |   16247.6 |
|    125 |     1.59346 |  0.0753527 |   4.72888 |
|    126 |     2.38866 |   0.209683 |   8.77827 |
|    127 |     9.53131 |   0.556236 |   5.83588 |
|    128 |   0.0029097 |    0.57392 |   19724.4 |
|    134 |     2.85382 |     1.4367 |   50.3433 |
|    135 |   0.0190592 |  0.0324244 |   170.125 |
|    136 |  0.00879623 |   0.102694 |   1167.48 |
|    138 |   0.0996933 |  0.0314422 |    31.539 |
|    139 |      0.2357 |  0.0701601 |   29.7666 |
|    140 |     1.04003 |   0.121997 |   11.7301 |
|    141 |    0.258956 |  0.0561728 |   21.6921 |
|    142 |    0.210307 |  0.0415359 |   19.7501 |
|    146 |    0.513598 |   0.063135 |   12.2927 |
|    147 |     2.90962 |   0.253602 |   8.71601 |
|    148 |      1.2819 |  0.0842873 |   6.57516 |
|    150 |    0.238113 |   0.133588 |   56.1028 |
|    151 |    0.215437 |  0.0542768 |   25.1938 |
|    152 |    0.171266 |  0.0699659 |   40.8523 |
|    153 |    0.280762 |  0.0780211 |   27.7891 |
|    154 |    0.716738 |    0.10592 |   14.7781 |
|    156 |  0.00128292 |    0.22432 |   17485.1 |
|    157 |  0.00904871 |  0.0105535 |    116.63 |
|    158 |    0.321452 |  0.0805232 |   25.0498 |
|    164 |    0.015171 |   0.041483 |   273.437 |
|    167 | 9.52965e-05 |  0.0136362 |   14309.2 |
|    172 | 0.000256998 |  0.0366889 |     14276 |
|    174 |  0.00019268 |  0.0113515 |   5891.37 |
|    183 |    0.179814 |   0.037001 |   20.5774 |
|    185 |    0.398766 |  0.0630249 |    15.805 |
|    189 |       6.042 |   0.308196 |    5.1009 |
|    190 |     4.15765 |     2.0767 |   49.9487 |
|    192 |      4.9286 |   0.459816 |   9.32955 |
|    193 |     1.84566 |  0.0888249 |   4.81264 |
|    195 |    0.218933 |  0.0297228 |   13.5762 |
|    197 |     0.60224 |  0.0508668 |   8.44628 |
|    199 |    0.404987 |    0.49271 |   121.661 |
|    203 |     0.79559 |   0.105298 |   13.2353 |
|    204 |    0.101074 |   0.019955 |    19.743 |
|    207 |     6.56012 |   0.468184 |   7.13683 |
|    208 |     3.20135 |   0.349065 |   10.9037 |
|    209 |     0.78797 |   0.141833 |   17.9998 |
|    210 |    0.571084 |  0.0650242 |   11.3861 |
|    211 |     3.38362 |   0.110959 |    3.2793 |
|    212 |     4.54297 |   0.190982 |   4.20389 |
|    213 |     4.63417 |   0.506259 |   10.9245 |
|    214 |     8.39299 |   0.467779 |   5.57345 |
|    215 |   0.0521331 |  0.0802041 |   153.845 |
|    216 |     0.66763 |  0.0773952 |   11.5925 |
|    218 |     30.7332 |    2.56227 |   8.33713 |
|    219 |    0.403487 |  0.0707834 |   17.5429 |
|    222 |   0.0898964 |  0.0201874 |   22.4563 |
|    223 |     11.3835 |   0.318286 |   2.79603 |
|    224 |    0.465393 |    0.17042 |   36.6184 |
|    231 |    0.930879 |   0.110524 |   11.8731 |
|    232 | 0.000300861 |  0.0524098 |   17419.9 |
|    233 |     4.20433 |    0.28694 |   6.82485 |
|    234 |   0.0192938 | 0.00886986 |   45.9727 |
|    237 |    0.356911 |   0.227127 |   63.6368 |
|    239 |     0.16309 |  0.0146806 |   9.00151 |
|    240 |   0.0723574 | 0.00594069 |    8.2102 |
|    243 |     1.36437 |   0.199452 |   14.6186 |
|    245 |    0.188843 |  0.0451201 |   23.8929 |
|    248 |     8.81223 |   0.406155 |   4.60899 |
|    249 |     1.42356 |   0.132901 |   9.33582 |
|    251 |   0.0292431 |  0.0137256 |   46.9361 |
|    254 |    0.581071 |  0.0951835 |   16.3807 |
|    255 |     1.05098 |   0.115429 |   10.9829 |
|    257 | 7.83737e-05 |  0.0120324 |   15352.6 |
|    258 | 0.000377353 |   0.060194 |   15951.6 |
|    GIS |     476.153 |    44.6966 |   9.38702 |

*** Results (Mouginot 2019 Region)
#+BEGIN_SRC python :results raw drawer :session discharge :display text/org
from uncertainties import unumpy
import pandas as pd
import numpy as np

df = pd.read_csv("./tmp/dat.csv")

err_sector = pd.DataFrame(columns=['D','E', 'E%'])
err_sector.index.name = 'Sector'

sectors = np.unique(df['regions@Mouginot_2019'].values)
for s in sectors:
   sub = df[df['regions@Mouginot_2019'] == s]
   thick = sub['thickness@BedMachine']
   vel = np.abs(sub['vx_baseline@ENVEO'])*sub['gates_x@gates_150_10000'] + np.abs(sub['vy_baseline@ENVEO'])*sub['gates_y@gates_150_10000']
   D = 200  * thick * vel * 917 / 1E12
   err_thick = np.abs(sub['errbed@BedMachine'].values)
   # err_thick[np.where(err_thick < 50)] = 50  # IS THIS REASONABLE? IMPORTANT?
   e_th = 200 * err_thick * vel * 917 / 1E12
   err_sector.loc[s] = [np.sum(D), np.sum(e_th), np.round(np.sum(e_th),10)/np.round(np.sum(D),10)*100]

err_sector.loc['GIS'] = np.sum(err_sector, axis=0)
err_sector.loc['GIS']['E%'] = err_sector.loc['GIS']['E']/err_sector.loc['GIS']['D']*100

err_sector.to_csv('./tmp/err_region_mouginot.csv')

err_sector.rename(columns = {'D':'D [Gt]', 
                         'E':'Error [Gt]',
                         'E%':'Error [%]'}, inplace=True)

err_sector
#+END_SRC

#+RESULTS:
| Sector |    D [Gt] | Error [Gt] | Error [%] |
|--------+-----------+------------+-----------|
|      1 | 0.0732849 | 0.00470999 |   6.42696 |
|      2 | 0.0823817 | 0.00651088 |    7.9033 |
|      3 |  0.210029 |  0.0190811 |   9.08501 |
|      4 |  0.370091 |  0.0407197 |   11.0026 |
|      5 | 0.0546231 | 0.00890458 |   16.3018 |
|      6 |  0.214758 |  0.0164815 |   7.67446 |
|      7 |  0.316332 |  0.0236688 |   7.48227 |
|    GIS |    1.3215 |   0.120077 |   9.08639 |

*** Results (Gate)                                                 :noexport:
#+BEGIN_SRC python :results raw drawer :session discharge :display text/org
from uncertainties import unumpy
import pandas as pd
import numpy as np

df = pd.read_csv("./tmp/dat.csv")

err_gate = pd.DataFrame(columns=['D','E', 'E%'])
err_gate.index.name = 'Gate'

gates = np.unique(df['gates_gateID@gates_150_10000'].values)
for g in gates:
    sub = df[df['gates_gateID@gates_150_10000'] == g]
    thick = sub['thickness@BedMachine']
    vel = np.abs(sub['vx_baseline@ENVEO'])*sub['gates_x@gates_150_10000'] + np.abs(sub['vy_baseline@ENVEO'])*sub['gates_y@gates_150_10000']
    D = 200  * thick * vel * 917 / 1E12
    err_thick = np.abs(sub['errbed@BedMachine'].values)
    # err_thick[np.where(err_thick < 50)] = 50  # IS THIS REASONABLE? IMPORTANT?
    e_th = 200 * err_thick * vel * 917 / 1E12
    err_gate.loc[g] = [np.sum(D), np.sum(e_th), np.sum(e_th)/np.sum(D)*100]

err_gate.loc['GIS'] = np.sum(err_gate, axis=0)
err_gate.loc['GIS']['E%'] = err_gate.loc['GIS']['E']/err_gate.loc['GIS']['D']*100

gate_meta = pd.read_csv("./out/gate_meta.csv")
err_gate['name'] = ''
for g in err_gate.index.values:
    if (g == 'GIS'): continue
    if (sum(gate_meta.gate == g) == 0): continue
    err_gate.loc[g,'name'] = gate_meta[gate_meta.gate == g].Mouginot_2019.values[0]

err_gate.to_csv('./tmp/err_gate.csv')
err_gate.rename(columns = {'D':'D [Gt]', 
                           'E':'Error [Gt]',
                           'E%':'Error [%]'}, inplace=True),

err_gate
#+END_SRC



** Raw data to discharge product
:PROPERTIES:
:header-args:python+: :tangle raw2discharge.py :session raw2discharge
:END:
*** Load data

+ What columns are in the file?
+ Don't show all the "vel_eff_YYYY_MM_DD" and "err_eff_YYYY_MM_DD" columns.
#+BEGIN_SRC bash :results verbatim :tangle no
head -n1 ./tmp/dat.csv | tr ',' '\n' | grep -v "vel_eff_*" | grep -v "err_eff_*" | grep -v "dh_*" | sort | uniq | tr '\n' '\t'
echo "also: dh_YYYY@elev, vel_eff_YYYY_MM_DD@various, etc."
#+END_SRC

#+RESULTS:
: bed@BedMachine	err_2D	err_baseline@ENVEO	errbed@BedMachine	gates_gateID@gates_150_10000	gates_x@gates_150_10000	gates_y@gates_150_10000	lat	lon	regions@Mouginot_2019	sectors@Mouginot_2019	sectors@Zwally_2012	surface@BedMachine	thickness@BedMachine	vel_baseline@ENVEO	vel_err_baseline@ENVEO	vx_baseline@ENVEO	vy_baseline@ENVEO	x	y	org_babel_sh_prompt> also: dh_YYYY@elev, vel_eff_YYYY_MM_DD@various, etc.

#+NAME: load_data
#+BEGIN_SRC python :exports none :results raw drawer
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import datetime as dt

# pd.options.display.notebook_repr_html = False

###
### Load metadata
### 
meta_cols = ["x", "y", "err_2D", 
             "regions@Mouginot_2019", "sectors@Zwally_2012", "gates_gateID@gates_150_10000"]
meta = pd.read_csv("./tmp/dat.csv", usecols=meta_cols)
# rename columns
meta.rename(inplace=True, columns={'regions@Mouginot_2019':'regions', 
                                   'sectors@Zwally_2012':'sectors',
                                   'gates_gateID@gates_150_10000':'gates'})
regions = {1:'NO', 2:'NE', 3:'CE', 4:'SE', 5:'SW', 6:'CW', 7:'NW'}
meta['regions'] = meta['regions'].map(regions.get) # Convert sector numbers to meaningful names
meta['ones'] = 1

R = pd.read_csv('./out/gate_meta.csv')
meta['name'] = ''

for g in meta['gates'].unique(): meta.loc[meta['gates'] == g, 'name'] = R[R['gate'] == g]['Mouginot_2019'].values[0]

###
### Load BASELINE velocity
###
vel_baseline = pd.read_csv("./tmp/dat.csv", usecols=['vel_baseline@ENVEO'])
vel_baseline.rename(inplace=True, columns={'vel_baseline@ENVEO':'vel'})

###
### Load all velocity
###
vel = pd.read_csv("./tmp/dat.csv", usecols=(lambda c: (('vel_eff' in c) & ('ENVEO' in c))))

#vel.rename(columns=lambda c: pd.to_datetime(int(c[8:12]), int(c[13:15]), int(c[16:18])), inplace=True)


# Convert column names to datetime
def convert_to_datetime(col_name):
    try:
        year = int(col_name[8:12])
        month = int(col_name[13:15])
        day = int(col_name[16:18])
        return pd.to_datetime(f"{year}-{month:02d}-{day:02d}")
    except Exception as e:
        print(f"Error converting column '{col_name}': {e}")
        return col_name  # Return original column name if conversion fails

vel.rename(columns=lambda c: convert_to_datetime(c), inplace=True)


# vel.drop(columns=pd.datetime(1999, 7, 1), inplace=True) # bad year?
vel.replace(0, np.nan, inplace=True)
# vel = vel.loc[:,vel.columns.year < 2018] # drop 2018
# vel = vel.loc[:,vel.columns.year >= 1985] # drop early years
vel.sort_index(axis='columns', inplace=True)

####################
# Filter Velocity: Rolling Windows
##################
def filter_bad_v(v):
    WINDOW=30
    SIGMA=2
    vel_rolling = v.T.rolling(window=WINDOW, center=True, min_periods=1).mean().T
    vel_residual = v - vel_rolling
    vel_std = vel_residual.T.rolling(window=WINDOW, center=True, min_periods=1).std().T
    vel_outlier = (v > vel_rolling+SIGMA*vel_std) | ( v < vel_rolling-SIGMA*vel_std)
    v[vel_outlier] = np.nan
    return v
####################
# vel = filter_bad_v(vel)
# vel = filter_bad_v(vel)
# vel = filter_bad_v(vel)


vel = vel.interpolate(method='time', axis=1, limit_area='inside')
vel.fillna(method='ffill', axis=1, inplace=True)
vel.fillna(method='bfill', axis=1, inplace=True)


# vel[meta.name == TESTNAME].T.sort_index().head()
# fill[meta.name == TESTNAME].T.sort_index().head()

# vel.sum(axis='rows').resample('1D').mean().interpolate(method='time', limit_area='inside').resample('A').mean()/1E6

###
### Load all velocity ERROR
###
err = pd.read_csv("./tmp/dat.csv", usecols=(lambda c: ('err_eff' in c)))
#err.rename(columns=lambda c: pd.to_datetime(int(c[8:12]), int(c[13:15]), int(c[16:18])), inplace=True)
err.rename(columns=lambda c: convert_to_datetime(c), inplace=True)

err.replace(0, np.nan, inplace=True)
# err = err.loc[:,err.columns.year > 1985] # drop early years
err.sort_index(axis='columns', inplace=True)
# err.interpolate(method='time', limit_area='inside', axis=1 inplace=True)
err.fillna(method='ffill', axis=1, inplace=True)
err.fillna(method='backfill', axis=1, inplace=True)

for c in err.columns[err.columns.duplicated()]:
    err.drop(columns=c, inplace=True)

# make sure we have error (even if 0) for each velocity, and no err w/o vel
for c in vel.columns:
    if c not in err.columns:
        err[c] = np.nan

for c in err.columns:
    if c not in vel.columns:
        err.drop(columns=c, inplace=True)
    
err.sort_index(axis='columns', inplace=True)

# tmp = np.array([c if c not in err.columns else None for c in vel.columns]); print(tmp[tmp != None])


###
### Thickness
###
th = pd.read_csv("./tmp/dat.csv", usecols=["thickness@BedMachine",
                                           "surface@BedMachine",
                                           "bed@BedMachine",
                                           "errbed@BedMachine",
                                           # "bed_0@Millan_2018",
                                           # "thickness_0@Millan_2018",
                                           "gates_gateID@gates_150_10000"])
th.rename(inplace=True, columns={'thickness@BedMachine':'thick',
                                 # 'bed_0@Millan_2018':'bed@Millan_2018',
                                 # 'thickness_0@Millan_2018':'thickness@Millan_2018',
                                 'errbed@BedMachine': 'err',
                                 'gates_gateID@gates_150_10000':'gates'})
# th_GIMP = pd.read_csv("./tmp/dat.csv", usecols=(lambda c: ('@GIMP.0715' in c)))
# th_GIMP['day'] = [dt.datetime(2000,1,1) + dt.timedelta(days=np.int(_)) for _ in th_GIMP['day@GIMP.0715']]
# for _ in th_GIMP.columns: th[_] = th_GIMP[_]
# del(th_GIMP)


###
### dh/dt
###
dhdt = pd.read_csv("./tmp/dat.csv", usecols=(lambda c: ('dh' in c)))
mv = {}
for c in dhdt.columns: mv[c] = int(c.split('@')[0].split('_')[1])
dhdt.rename(inplace=True, columns=mv)

# assume linear trend average of adjacent 3 years for missing years
# dhdt[2018] = dhdt.loc[:,2015:2017].mean(axis='columns')
# dhdt[2019] = dhdt.loc[:,2015:2017].mean(axis='columns')
# dhdt[2018] = 0
# dhdt[2019] = 0

# for y in np.arange(1985,1994+1): dhdt[y] = dhdt.loc[:,1995:1997].mean(axis='columns')
# dhdt.sort_index(axis='columns', inplace=True)

# what is the unadjusted discharge using BedMachine thickness?
D = (vel).apply(lambda c: c * (200 * th['thick'] * meta['err_2D'].values), axis=0) * 917 / 1E12
D.sum(axis='rows').resample('1D').mean().interpolate(method='time', limit_area='inside').resample('A').mean()
#+END_SRC

#+RESULTS: load_data
:results:
2014-12-31    456.282507
2015-12-31    464.653458
2016-12-31    468.636893
2017-12-31    482.607014
2018-12-31    480.612162
2019-12-31    483.706338
2020-12-31    491.265153
2021-12-31    493.829257
2022-12-31    463.412435
Freq: A-DEC, dtype: float64
:end:



*** Adjust thickness 
**** Adjust "bad" thickness
Here we perform a few thickness adjustments:

First, patch in Millan (2018) where it exists.

+ 300 :: All ice <= 20 m thick is assumed bad and set to the minimum
         "good" thickness in a gate if good exists, or 300 m if it
         does not exist
+ 400 :: All ice <= 50 m thick is set to 400 m thick
+ fit :: All ice <= 20 m thick is fit to the log10(thickness) v.
         log10(velocity) relationship, even though it is not a good
         fit.

For testing, gate clumps 9 (all bad) and 546 (some bad)

#+CALL: load_data[:results none]()

#+NAME: adjust_thickness
#+BEGIN_SRC python :exports none :results raw drawer :display text/org

th['bad'] = th['thick'] <= 20

th['thick_adj_300'] = th['thick']
th['thick_adj_300_err'] = th['err']
for g in th[th['bad']]['gates'].unique(): # only work on gates with some (or all) bad thickness
    if all(th[th['gates'] == g]['bad']): # If all bad, set to 300
        th.loc[th['gates'] == g, 'thick_adj_300'] = 300
        th.loc[th['gates'] == g, 'thick_adj_300_err'] = 300/2.

    elif any(th[th['gates'] == g]['bad']): # If any bad, set to minimum of good.
        th.loc[(th['gates'] == g) & (th['bad']), 'thick_adj_300'] = \
        (th.loc[(th['gates'] == g) & (~th['bad']), 'thick']).min()
        th.loc[(th['gates'] == g) & (th['bad']), 'thick_adj_300_err'] = 300/2.

# aggressive: Anything <= 50 gets 400 m thickness
th['thick_adj_400'] = [400 if T <= 50 else T for T in th['thick']]
th['thick_adj_400_err'] = [400/2. if T[0] <= 50 else T[1] for T in zip(th['thick'],th['err'])]
#+END_SRC

#+RESULTS: adjust_thickness
:results:
None
:end:

#+BEGIN_SRC python :exports none :results raw drawer :display text/org :session discharge :tangle no
<<load_data>>
<<adjust_thickness>>

print(th.describe())
#+END_SRC

#+RESULTS:
:results:
None
:end:

#+BEGIN_SRC python :exports none :results raw drawer :display text/org :session discharge
D0 = (vel).apply(lambda c: c * (200 * th['thick'] * meta['err_2D'].values), axis=0) * 917 / 1E12
D1 = (vel).apply(lambda c: c * (200 * th['thick_adj_300'] * meta['err_2D'].values), axis=0) * 917 / 1E12
D0 = D0.sum(axis='rows').resample('1D').mean().interpolate(method='time', limit_area='inside',).resample('A').mean()
D1 = D1.sum(axis='rows').resample('1D').mean().interpolate(method='time', limit_area='inside').resample('A').mean()
pd.concat([D0,D1, D1-D0], axis='columns', keys=['BedMachine','300','diff'])
#+END_SRC

#+RESULTS:
:results:
            BedMachine         300      diff
2014-12-31  456.282507  458.687555  2.405048
2015-12-31  464.653458  466.991554  2.338096
2016-12-31  468.636893  470.987356  2.350462
2017-12-31  482.607014  485.346826  2.739812
2018-12-31  480.612162  483.466418  2.854256
2019-12-31  483.706338  486.552572  2.846234
2020-12-31  491.265153  494.185315  2.920162
2021-12-31  493.829257  496.632609  2.803352
2022-12-31  463.412435  466.088584  2.676149
:end:


**** Adjust thickness w thickness v. velocity fit.

#+NAME: adjust_thickness_fit
#+BEGIN_SRC python :exports none :results raw drawer :display text/plain
CUTOFF = 20
df = vel_baseline.join(th['thick'])
max_vel = df.loc[df['thick'] <= CUTOFF, 'vel'].max() # limit fit to velocities where data is missing
# df = df[(df['thick'] > CUTOFF) & (df['vel'] <= max_vel)]
df = df[df['thick'] > CUTOFF]
# df = df[df['vel'] <= max_vel]

import statsmodels.api as sm
y = (df['thick'])
X = np.log10(df['vel'])
X = sm.add_constant(X)
model = sm.OLS(y, X)
fits = model.fit()
# print(fits.summary())
predictions = fits.predict(X)

from statsmodels.sandbox.regression.predstd import wls_prediction_std
XX = np.linspace(X['vel'].min(), X['vel'].max(), 50)
XX = sm.add_constant(XX)
yy = fits.predict(XX)
sdev, lower, upper = wls_prediction_std(fits, exog=XX, alpha=0.05)

fig = plt.figure(1, figsize=(4,4)) # w,h
# get_current_fig_manager().window.move(0,0)
fig.clf()
# fig.set_tight_layout(True)

ax = fig.add_subplot(111)
im = ax.scatter(X['vel'], y, alpha=0.1, color='k')
xl, yl = ax.get_xlim(), ax.get_ylim()
ax.set_ylabel('Thickness [m]')
ax.set_xlabel('Velocity [m yr$^{-1}$]')
ax.plot(XX[:,1], yy, 'r--')
ax.fill_between(XX[:,1], lower, upper, color='#888888', alpha=0.4)
ax.fill_between(XX[:,1], lower, upper, color='#888888', alpha=0.1)
# ax.set_xlim(50,xl[1])
ax.set_ylim(0,yl[1])
plt.savefig('./tmp/vel_thick_fit.png', transparent=True, bbox_inches='tight', dpi=300)
plt.savefig('./tmp/vel_thick_fit.pdf', transparent=True, bbox_inches='tight', dpi=300)
            
th['fit'] = th['thick']
vel_where_thick_bad = vel_baseline.loc[th['bad'] == True, 'vel']
th.loc[th['bad'] == True, 'fit'] = fits.predict(sm.add_constant(np.log10(vel_where_thick_bad)))
# set err to thickness where fit
th['fit_err'] = th['err']
th.loc[th['bad'] == True, 'fit_err'] = th.loc[th['bad'] == True, 'fit'] /2.


fits.summary()


D0 = (vel).apply(lambda c: c * (200 * th['thick_adj_300'] * meta['err_2D'].values), axis=0) * 917 / 1E12
D1 = (vel).apply(lambda c: c * (200 * th['fit'] * meta['err_2D'].values), axis=0) * 917 / 1E12
D0 = D0.sum(axis='rows').resample('1D').mean().interpolate(method='time', limit_area='inside').resample('A').mean()
D1 = D1.sum(axis='rows').resample('1D').mean().interpolate(method='time', limit_area='inside').resample('A').mean()
pd.concat([D0,D1, D1-D0], axis='columns', keys=['300','fit','diff'])

#+END_SRC

#+RESULTS: adjust_thickness_fit
:results:
                   300         fit      diff
2014-12-31  458.687555  460.269696  1.582140
2015-12-31  466.991554  468.518664  1.527110
2016-12-31  470.987356  472.496464  1.509109
2017-12-31  485.346826  487.156504  1.809678
2018-12-31  483.466418  485.386054  1.919636
2019-12-31  486.552572  488.463479  1.910907
2020-12-31  494.185315  496.117607  1.932291
2021-12-31  496.632609  498.515189  1.882580
2022-12-31  466.088584  467.894327  1.805743
:end:

**** Table of thickness adjustments
:PROPERTIES:
:ID:       62f5d28c-c704-422d-9e9b-c0771d5b86ee
:END:

#+BEGIN_SRC python :exports none :results raw drawer :display text/org
th[['thick','thick_adj_300','thick_adj_400','fit']].describe()
#+END_SRC

#+RESULTS:
:results:
             thick  thick_adj_300  thick_adj_400          fit
count  7102.000000    7102.000000    7102.000000  7102.000000
mean    501.602235     512.570731     523.574630   518.553613
std     272.125691     257.363524     246.170636   253.563481
min       0.004272      20.147034      50.133362    20.147034
25%     323.352068     323.352068     373.302622   355.869805
50%     502.713985     502.713985     502.713985   505.693165
75%     672.482665     672.482665     672.482665   672.482665
max    1715.087400    1715.087400    1715.087400  1715.087400
:end:


**** Baseline discharge values for various thickness adjustments
Here we calculate:
+ D_baseline_th_noadj :: Discharge with no thickness adjustment
+ D_baseline_th_300 :: The baseline discharge
+ D_baseline_th_400 :: The discharge assuming the aggressive thickness adjustment
+ D_baseline_th_fit :: The discharge assuming the fitted thickness adjustment
+ D_baseline :: The baseline discharge - picked from our favorite of the above. TBD

#+NAME: discharge_th
#+BEGIN_SRC python :exports none :results raw drawer
D_th = pd.DataFrame(index=th.index,
                    columns=['NoAdj','NoAdj_err','300','300_err','400','400_err','fit','fit_err'])

# + D_baseline_th_noadj :: Discharge with no thickness adjustment
D_th['NoAdj'] = vel_baseline.apply(lambda c: c * (th['thick'].values * 200 * meta['err_2D'].values), axis=0) * 917 / 1E12

# should match HeatMap
D_th['NoMillan'] = vel_baseline.apply(lambda c: c * ((th['surface@BedMachine']-th['bed@BedMachine']).values * 200), axis=0) * 917 / 1E12

# D_baseline_th_noadj_err ::
D_th['NoAdj_err'] = vel_baseline.apply(lambda c: c * (th['err'].values * 200 * meta['err_2D'].values), axis=0) * 917 / 1E12

D_th['300'] = vel_baseline.apply(lambda c: c * (th['thick_adj_300'].values * 200 * meta['err_2D'].values), axis=0) * 917 / 1E12
D_th['300_err'] = vel_baseline.apply(lambda c: c * (th['thick_adj_300_err'].values  * 200 * meta['err_2D'].values), axis=0) * 917 / 1E12

D_th['400'] = vel_baseline.apply(lambda c: c * (th['thick_adj_400'].values * 200 * meta['err_2D'].values), axis=0) * 917 / 1E12
D_th['400_err'] = vel_baseline.apply(lambda c: c * (th['thick_adj_400_err'].values * 200 * meta['err_2D'].values), axis=0) * 917 / 1E12

D_th['fit'] = vel_baseline.apply(lambda c: c * (th['fit'].values * 200 * meta['err_2D'].values), axis=0) * 917 / 1E12
D_th['fit_err'] = vel_baseline.apply(lambda c: c * (th['fit_err'].values* 200 * meta['err_2D'].values), axis=0) * 917 / 1E12

D_th.sum(axis='rows')
#+END_SRC

#+RESULTS: discharge_th
:results:
NoAdj        475.515487
NoAdj_err     37.887958
300          478.776608
300_err       39.152362
400          482.307862
400_err       40.677359
fit          480.854010
fit_err       40.096038
NoMillan     475.807067
dtype: float64
:end:


**** Temporal changes in thickness
+ Assume BedMachine surface date is nominally 2007
+ Adjust thickness forward and backward through time using SEC.
#+BEGIN_SRC python :exports none :results raw drawer
th_ts = dhdt.copy(deep=True)
th_ts[2007] = th['fit']

th_ts[2008] = th_ts[2007] + dhdt[2008]
for i in np.arange(2009,2019+1):
    th_ts[i] = th_ts[i-1] + dhdt[i]
th_ts[2020] = th_ts[2019] + dhdt[2019]
th_ts[2021] = th_ts[2019] + dhdt[2019]*2
th_ts[2022] = th_ts[2019] + dhdt[2019]*3
th_ts[2023] = th_ts[2019] + dhdt[2019]*4

th_ts.columns = [pd.to_datetime(_, format='%Y') for _ in th_ts.columns]
th_ts = th_ts.T.resample('1D').interpolate().T

th_ts = th_ts[vel.columns]

# Re-adjust th_ts where thickness < 20 m.
bad = th_ts.min(axis=1) < 20 # Pixels with bad thickness somewhere in the time series
for px in bad[bad == True].index:
    th_ts.loc[px] = fits.predict(np.log10([1,vel_baseline.iloc[px].vel]))
#+END_SRC

#+RESULTS:
:results:
None
:end:

*** Discharge

And more importantly and long-term, we calculate the following time series discharge products, using our preferred method (fill w/ 300 m):
+ D :: Discharge at gate scale
+ D_err :: The discharge error at gate scale
+ D_fill :: The fill percentage for each gate at each point in time
+ D_sector :: Same, but at Mouginot 2019 sector scale
+ D_sector_err ::
+ D_sector_fill :: 
+ D_region :: Same, but at Mouginot 2019 region scale
+ D_region_err ::
+ D_region_fill ::
+ D_all :: Same, but all GIS
+ D_all_err ::
+ D_all_fill ::

#+BEGIN_SRC python :display text/plain :session test :tangle no
import pandas as pd
import numpy as np
filled_D = pd.DataFrame(index=['A','B'], columns=['t1','t3','t4'], data=[[8,9,7],[4,2,1]])
fill = filled_D/filled_D
fill.loc['B','t3'] = np.nan

no_filled_D = filled_D * fill
# filled_weighted_D = filled_D / filled_D.sum()
no_filled_weighted_D = no_filled_D / filled_D.sum()

r = ((filled_D*fill)/filled_D.sum()).sum()
r.round(2)                        
#+END_SRC

#+RESULTS:
: t1    1.00
: t3    0.82
: t4    1.00
: dtype: float64

#+NAME: discharge
#+BEGIN_SRC python :exports none :results raw drawer
# D :: Discharge at pixel scale
# D_err :: The discharge error at pixel scale
# D_fill :: The fill percentage for each pixel at each point in time
D = (vel*th_ts).apply(lambda c: c * (200 * meta['err_2D'].values), axis=0) * 917 / 1E12
# SHL: I will set fill to 1 - because it is not calculated as in the main code 
fill = D/D
# Don't adjust thickness over time
# D = (vel).apply(lambda c: c * (200 * meta['err_2D'].values * th['thick'].values), axis=0) * 917 / 1E12

D_err = vel.apply(lambda c: c * (th['fit_err'] * 200 * meta['err_2D'].values), axis=0) * 917 / 1E12

[DD,DD_err] = [_.copy() for _ in [D,D_err]]

DD[['gates','sectors','regions','ones','name']] = meta[['gates','sectors','regions','ones','name']]
DD_err[['gates','sectors','regions','ones','name']] = meta[['gates','sectors','regions','ones','name']]

# D_gate :: Same, but at the gate scale
# D_gate_err ::
# D_gate_fill ::
D_gates = DD.groupby('gates').sum().drop(['ones','sectors','regions','name'], axis=1)
D_gates_err = DD_err.groupby('gates').sum().drop(['ones','sectors','regions','name'], axis=1)
D_gates_fill_weight = pd.DataFrame().reindex_like(D_gates)
for g in D_gates.index:
    g_idx = (DD['gates'] == g)
    D_gates_fill_weight.loc[g] = ((D[g_idx]*fill[g_idx])/D[g_idx].sum()).sum()

D_gates.columns = D_gates.columns.astype(str).astype('datetime64[ns]')

D_gates_err.columns = D_gates_err.columns.astype(str).astype('datetime64[ns]')
D_gates_fill_weight.columns = D_gates_fill_weight.columns.astype(str).astype('datetime64[ns]')
D_gates_fill_weight.clip(lower=0, upper=1, inplace=True)



# D_sector :: Same, but at Mouginot sector scale
# D_sector_err ::
# D_sector_fill ::
D_sectors = DD.groupby('sectors').sum().drop(['ones','gates','regions','name'], axis=1)
D_sectors_err = DD_err.groupby('sectors').sum().drop(['ones','gates','regions','name'], axis=1)
D_sectors_fill_weight = pd.DataFrame().reindex_like(D_sectors)
for s in D_sectors.index:
    s_idx = (DD['sectors'] == s)
    D_sectors_fill_weight.loc[s] = ((D[s_idx]*fill[s_idx])/D[s_idx].sum()).sum()

# no gates is 1.4
D_sectors.index = [1.1, 1.2, 1.3, 2.1, 2.2, 3.1, 3.2, 3.3, 4.1, 4.2, 4.3, 5.0, 6.1, 6.2, 7.1, 7.2, 8.1, 8.2]
D_sectors_err.index = D_sectors.index
D_sectors_fill_weight.index = D_sectors.index

D_sectors.columns = D_sectors.columns.astype(str).astype('datetime64[ns]')
D_sectors_err.columns = D_sectors_err.columns.astype(str).astype('datetime64[ns]')
D_sectors_fill_weight.columns = D_sectors_fill_weight.columns.astype(str).astype('datetime64[ns]')
D_sectors_fill_weight.clip(lower=0, upper=1, inplace=True)


# D_region :: Same, but at Mouginot region scale
# D_region_err ::
# D_region_fill ::
D_regions = DD.groupby('regions').sum().drop(['ones','sectors','gates','name'], axis=1)
D_regions_err = DD_err.groupby('regions').sum().drop(['ones','sectors','gates','name'], axis=1)
D_regions_fill_weight = pd.DataFrame().reindex_like(D_regions)
for r in D_regions.index:
    r_idx = DD['regions'] == r
    D_regions_fill_weight.loc[r] = ((D[r_idx]*fill[r_idx])/D[r_idx].sum()).sum()
    
    # # or, broken apart into simple steps.
    # # Whether any given pixel is filled (1) or not (0).
    # r_fill = fill[DD['regions'] == r].fillna(value=0)
    # # Discharge for each pixel in this region, using filling
    # r_filled_D = DD[DD['regions'] == r].drop(['sectors','regions','ones'], axis=1)
    # # weighted filling for this region
    # r_fill_weight = ((r_filled_D*r_fill)/r_filled_D.sum()).sum()
    # D_regions_fill_weight.loc[r] = r_fill_weight
    
D_regions.columns = D_regions.columns.astype(str).astype('datetime64[ns]')
D_regions_err.columns = D_regions_err.columns.astype(str).astype('datetime64[ns]')
D_regions_fill_weight.columns = D_regions_fill_weight.columns.astype(str).astype('datetime64[ns]')
D_regions_fill_weight.clip(lower=0, upper=1, inplace=True)


# D_all :: Same, but all GIS
# D_all_err ::
# D_all_fill ::
D_all = DD.drop(['regions','sectors','ones','name','gates'], axis=1).sum()
D_all_err = DD_err.drop(['regions','sectors','ones','name','gates'], axis=1).sum()
D_all_fill_weight = pd.Series().reindex_like(D_all)
for c in D.columns:
    D_all_fill_weight.loc[c] = (fill[c] * (D[c] / D[c].sum())).sum()
#+END_SRC

#+RESULTS: discharge
:results:
None
:end:



*** SAVE & RESTORE STATE

#+BEGIN_SRC python :results raw drawer :tangle no
%store D
%store D_err
%store fill
%store D_gates
%store D_gates_err
%store D_gates_fill_weight
%store D_sectors
%store D_sectors_err
%store D_sectors_fill_weight
%store D_regions
%store D_regions_err
%store D_regions_fill_weight
%store D_all
%store D_all_err
%store D_all_fill_weight
%store meta
#+END_SRC

#+RESULTS:
:results:
# Out[796]:
# output
Stored 'D' (DataFrame)
Stored 'D_err' (DataFrame)
Stored 'fill' (DataFrame)
Stored 'D_gates' (DataFrame)
Stored 'D_gates_err' (DataFrame)
Stored 'D_gates_fill_weight' (DataFrame)
Stored 'D_sectors' (DataFrame)
Stored 'D_sectors_err' (DataFrame)
Stored 'D_sectors_fill_weight' (DataFrame)
Stored 'D_regions' (DataFrame)
Stored 'D_regions_err' (DataFrame)
Stored 'D_regions_fill_weight' (DataFrame)
Stored 'D_all' (Series)
Stored 'D_all_err' (Series)
Stored 'D_all_fill_weight' (Series)
Stored 'meta' (DataFrame)

:end:

#+BEGIN_SRC python :results raw drawer :tangle no
%store -r

D = D.T['2000':].T
D_err = D_err.T['2000':].T
fill = fill.T['2000':].T
D_gates = D_gates.T['2000':].T
D_gates_err = D_gates_err.T['2000':].T
D_gates_fill_weight = D_gates_fill_weight.T['2000':].T
D_sectors = D_sectors.T['2000':].T
D_sectors_err = D_sectors_err.T['2000':].T
D_sectors_fill_weight = D_sectors_fill_weight.T['2000':].T
D_regions = D_regions.T['2000':].T
D_regions_err = D_regions_err.T['2000':].T
D_regions_fill_weight = D_regions_fill_weight.T['2000':].T
D_all = D_all.T['2000':].T
D_all_err = D_all_err.T['2000':].T
D_all_fill_weight = D_all_fill_weight.T['2000':].T
#+END_SRC

#+RESULTS:
:results:
# Out[278]:
:end:


*** Export Data
**** Crop time series
#+BEGIN_SRC python :exports both :results raw drawer

STARTDATE=pd.to_datetime('2014-10-01')
D_all = D_all.T[STARTDATE:].T
D_all_err = D_all_err.T[STARTDATE:].T
D_all_fill_weight = D_all_fill_weight.T[STARTDATE:].T
D_gates = D_gates.T[STARTDATE:].T
D_gates_err = D_gates_err.T[STARTDATE:].T
D_gates_fill_weight = D_gates_fill_weight.T[STARTDATE:].T
D_sectors = D_sectors.T[STARTDATE:].T
D_sectors_err = D_sectors_err.T[STARTDATE:].T
D_sectors_fill_weight = D_sectors_fill_weight.T[STARTDATE:].T
D_regions = D_regions.T[STARTDATE:].T
D_regions_err = D_regions_err.T[STARTDATE:].T
D_regions_fill_weight = D_regions_fill_weight.T[STARTDATE:].T
D_all = D_all.T[STARTDATE:].T
D_all_err = D_all_err.T[STARTDATE:].T
D_all_fill_weight = D_all_fill_weight.T[STARTDATE:].T

#+END_SRC

#+RESULTS:
:results:
None
:end:

**** README

#+BEGIN_SRC org :tangle ./out/README.txt :mkdirp ./out
README for "Greenland Ice Sheet solid ice discharge from 1986 through 2018"

Paper Citation: TODO

Original Paper: doi:10.5194/essd-11-769-2019

Data Citation: TODO

Original Data Citations: doi:10.22008/promice/data/ice_discharge

Source: https://github.com/mankoff/ice_discharge

,* Usage instructions:

When using any of the following data, you are required to cite the paper and the data set.

,* Data Descriptions

Data sets released as part of this work include:
+ Discharge data
+ Gates
+ Surface Elevation Change
+ Code

Each are described briefly below.

,** Discharge Data

This data set is made up of the following files

| Filename            | Description                                           |
|---------------------+-------------------------------------------------------|
| GIS_D.csv           | Greenland Ice Sheet cumulative discharge by timestamp |
| GIS_err.csv         | Errors for GIS_D.csv                                  |
| GIS_coverage.csv    | Coverage for GIS_D.csv                                |
| region_D.csv        | Regional discharge                                    |
| region_err.csv      | Errors for region_D.csv                               |
| region_coverage.csv | Coverage for region_D.csv                             |
| sector_D.csv        | Sector discharge                                      |
| sector_err.csv      | Errors for sector_D.csv                               |
| sector_coverage.csv | Coverage for sector_D.csv                             |
| gate_D.csv          | Gate discharge                                        |
| gate_err.csv        | Errors for gate_D.csv                                 |
| gate_coverage.csv   | Coverage for gate_D.csv                               |
|---------------------+-------------------------------------------------------|
| gate_meta.csv       | Metadata for each gate                                |


D and err data have units [Gt yr-1].
Coverage is in range [0, 1]

,** Gates

| Filename   | Description                                   |
|------------+-----------------------------------------------|
| gates.kml  | KML file of gate location and metadata        |
| gates.gpkg | GeoPackage file of gate location and metadata |

,** Surface Elevation Change

The "surface_elevation_change" file set contains the surface elevation change data used in this work (DOI 10.22008/promice/data/DTU/surface_elevation_change/v1.0.0)

,** Code

The "code" file set (DOI 10.22008/promice/data/ice_discharge/code/v0.0.1) contains the digital workbook that produced the data, the ESSD document text and figures, this README, and everything else associated with this work.
#+END_SRC

**** Gates
***** D, err, coverage
#+BEGIN_SRC python :exports both :results raw drawer
D_gatesT = D_gates.T
D_gates_errT = D_gates_err.T
D_gates_fill_weightT = D_gates_fill_weight.T

D_gatesT.index.name = "Date"
D_gates_errT.index.name = "Date"
D_gates_fill_weightT.index.name = "Date"

D_gatesT = D_gatesT.replace(to_replace=0, value=np.nan).dropna(axis='rows', how='all')
D_gates_errT = D_gates_errT.loc[D_gatesT.index]
D_gates_fill_weightT = D_gates_fill_weightT.loc[D_gatesT.index]

D_gatesT.to_csv('./out/gate_D.csv')
D_gates_errT.to_csv('./out/gate_err.csv')
D_gates_fill_weightT.to_csv('./out/gate_coverage.csv')
#+END_SRC

#+RESULTS:

**** Sectors
#+BEGIN_SRC python :exports both :results raw drawer :display text/org
# meta_sector = pd.DataFrame(index=meta.groupby('sectors').first().index)
# meta_sector['mean x'] = meta.groupby('sectors').mean()['x'].round().astype(np.int)
# meta_sector['mean y'] = meta.groupby('sectors').mean()['y'].round().astype(np.int)
# meta_sector['n gates'] = meta.groupby('sectors').count()['gates'].round().astype(np.int)
# meta_sector['region'] = meta.groupby('sectors').first()['regions']

D_sectorsT = D_sectors.T
D_sectors_errT = D_sectors_err.T
D_sectors_fill_weightT = D_sectors_fill_weight.T

D_sectorsT.index.name = "Date"
D_sectors_errT.index.name = "Date"
D_sectors_fill_weightT.index.name = "Date"

D_sectorsT = D_sectorsT.replace(to_replace=0, value=np.nan).dropna(axis='rows', how='all')
D_sectors_errT = D_sectors_errT.loc[D_sectorsT.index]
D_sectors_fill_weightT = D_sectors_fill_weightT.loc[D_sectorsT.index]

# meta_sector.to_csv('./out/sector_meta.csv')
D_sectorsT.to_csv('./out/sector_D.csv')
D_sectors_errT.to_csv('./out/sector_err.csv')
D_sectors_fill_weightT.to_csv('./out/sector_coverage.csv')

# meta_sector.head(10)
#+END_SRC

#+RESULTS:

**** Regions
#+BEGIN_SRC python :exports both :results raw drawer :display text/org
# meta_region = pd.DataFrame(index=meta.groupby('regions').first().index)
# meta_region['n gates'] = meta.groupby('regions').count()['gates'].round().astype(np.int)

D_regionsT = D_regions.T
D_regions_errT = D_regions_err.T
D_regions_fill_weightT = D_regions_fill_weight.T
D_regionsT.index.name = "Date"
D_regions_errT.index.name = "Date"
D_regions_fill_weightT.index.name = "Date"

D_regionsT = D_regionsT.replace(to_replace=0, value=np.nan).dropna(axis='rows', how='all')
D_regions_errT = D_regions_errT.loc[D_regionsT.index]
D_regions_fill_weightT = D_regions_fill_weightT.loc[D_regionsT.index]

# meta_region.to_csv('./out/region_meta.csv')
D_regionsT.to_csv('./out/region_D.csv')
D_regions_errT.to_csv('./out/region_err.csv')
D_regions_fill_weightT.to_csv('./out/region_coverage.csv')

# meta_region.head(10)
#+END_SRC

#+RESULTS:


**** GIS
#+BEGIN_SRC python :exports both :results raw drawer
D_all.index.name = "Date"
D_all_err.index.name = "Date"
D_all_fill_weight.index.name = "Date"

D_all = D_all.replace(to_replace=0, value=np.nan).dropna(axis='rows', how='all')
D_all_err = D_all_err[D_all.index]
D_all_fill_weight = D_all_fill_weight[D_all.index]

D_all.to_csv('./out/GIS_D.csv', float_format='%.5f', header=["Discharge [Gt yr-1]"])
D_all_err.to_csv('./out/GIS_err.csv', float_format='%.5f', header=["Discharge Error [Gt yr-1]"])
D_all_fill_weight.to_csv('./out/GIS_coverage.csv', float_format='%.5f', header=["Coverage [unit]"])
#+END_SRC

#+RESULTS:

**** Gates
#+BEGIN_SRC bash :results verbatim :tangle gate_export.sh
<<MSGS_pretty_print>>
<<GRASS_config>>
g.mapset gates_150_10000

v.out.ogr input=gates_final output=./out/gates.kml format=KML --o
v.out.ogr input=gates_final output=./out/gates.gpkg format=GPKG --o
#+END_SRC
#+RESULTS:

**** Elevation change

Done manually. See DOI

**** TODO Code

Make sure this Org file is tidy enough...

**** TODO Distribute
#+BEGIN_SRC bash :results verbatim :tangle no
(cd out; zip -e /media/kdm/promicedata/ice_discharge/gates/gates.zip gates*)
(cd out; zip -e /media/kdm/promicedata/ice_discharge/d/D.zip D*csv)
cp ./out/README.txt /media/kdm/promicedata/ice_discharge/

zip -e /media/kdm/promicedata/ice_discharge/code/mankoff_et_al.zip ice_discharge.org

cp ${DATADIR}/Khan_2016/dhdt_1995-2015_GrIS.txt /media/kdm/promicedata/ice_discharge/surface_elevation_change

#+END_SRC
#+RESULTS:


** Figures
:PROPERTIES:
:header-args:python+: :tangle figures.py
:header-args:python+: :session sob_figures
:END:
*** Discharge Time Series - GIS
#+NAME: fig:discharge_ts
#+BEGIN_SRC python :results raw drawer :display text/org
import matplotlib.gridspec as gridspec
import numpy as np
import pandas as pd
from adjust_spines import adjust_spines as adj
import matplotlib.pyplot as plt
import datetime as dt

# plt.close(1)

fig = plt.figure(1, figsize=(9,5)) # w,h
fig.clf()

ax_D = fig.add_subplot(111)

adj(ax_D, ['left','bottom'])

D = pd.read_csv("./out/GIS_D.csv", index_col=0, parse_dates=True)
err = pd.read_csv("./out/GIS_err.csv", index_col=0, parse_dates=True)
coverage = pd.read_csv("./out/GIS_coverage.csv", index_col=0, parse_dates=True)

ROOT="/home/shl@geus.dk/OneDrive/projects/promice/solid_ice_discharge/dataverse_data"
D_M2019 = pd.read_csv(ROOT+"/GIS_D.csv", index_col=0, parse_dates=True)
err_M2019 = pd.read_csv(ROOT+"/GIS_err.csv", index_col=0, parse_dates=True)

D_M2019 = D_M2019[(D_M2019.index > D.index[0]) & (D_M2019.index <= D.index[-1])]
err_M2019 = err_M2019[(err_M2019.index > err.index[0]) & (err_M2019.index <= err.index[-1])]

# | Color       |   R |   G |   B | hex     |
# |-------------+-----+-----+-----+---------|
# | light blue  | 166 | 206 | 227 | #a6cee3 |
# | dark blue   |  31 | 120 | 180 | #1f78b4 |
# | light green | 178 | 223 | 138 | #b2df8a |
# | dark green  |  51 | 160 |  44 | #33a02c |
# | pink        | 251 | 154 | 153 | #fb9a99 |
# | red         | 227 |  26 |  28 | #e31a1c |
# | pale orange | 253 | 191 | 111 | #fdbf6f |
# | orange      | 255 | 127 |   0 | #ff7f00 |
C1="#e31a1c" # red
C2="#1f78b4" # dark blue

MS=4

D_M2019.plot(ax=ax_D, marker='.', color=C2, label='')
D.plot(ax=ax_D, drawstyle='steps', color=C1, label='')

ax_D.fill_between(err.index, 
                  (D.values-err.values).flatten(), 
                  (D.values+err.values).flatten(), 
                  color=C1, alpha=0.25, label='')

ax_D.fill_between(err_M2019.index, 
                  (D_M2019.values-err_M2019.values).flatten(), 
                  (D_M2019.values+err_M2019.values).flatten(), 
                  color=C2, alpha=0.25, label='')

ax_D.legend(["Mankoff (2019)", "GEUS CCI"], framealpha=0)
ax_D.set_xlabel('Time [Years]')
ax_D.set_ylabel('Discharge [Gt yr$^{-1}$]')

import matplotlib.dates as mdates
ax_D.xaxis.set_major_locator(mdates.YearLocator())
ax_D.minorticks_off()
# ax_D.xaxis.set_tick_params(rotation=-90) #, ha="left", rotation_mode="anchor")
# for tick in ax_D.xaxis.get_majorticklabels():
#     tick.set_horizontalalignment("left")

plt.savefig('./figs/discharge_ts.png', transparent=False, bbox_inches='tight', dpi=300)
# plt.savefig('./figs/discharge_ts.pdf', box_inches='tight', dpi=300)

# disp = pd.DataFrame(data = {'D':D_day_year.values.flatten(), 'err':err_day_year.values.flatten()},
#                     index = D_day_year.index.year)
# disp.index.name = 'Year'
# disp
#+END_SRC

#+RESULTS: fig:discharge_ts
:results:
None
:end:

*** COMMENT Discharge Time Series - Regions
#+NAME: fig:discharge_ts_regions
#+BEGIN_SRC python :results raw drawer 
import matplotlib.gridspec as gridspec
import numpy as np
import pandas as pd
from adjust_spines import adjust_spines as adj
import datetime as dt

# plt.close(1)

fig = plt.figure(1, figsize=(9,7)) # w,h
fig.clf()
# fig.set_tight_layout(True)
grid = plt.GridSpec(2, 1, height_ratios=[1,6], hspace=0.1) # h, w

ax_D = fig.add_subplot(111)

from adjust_spines import adjust_spines as adj
adj(ax_D, ['left','bottom'])

D = pd.read_csv("./out/region_D.csv", index_col=0, parse_dates=True)
err = pd.read_csv("./out/region_err.csv", index_col=0, parse_dates=True)

ROOT="/home/kdm/projects/ice_discharge/out"
D_M2019 = pd.read_csv(ROOT+"/region_D.csv", index_col=0, parse_dates=True)
err_M2019 = pd.read_csv(ROOT+"/region_err.csv", index_col=0, parse_dates=True)

D_M2019 = D_M2019[(D_M2019.index > D.index[0]) & (D_M2019.index <= D.index[-1])]
err_M2019 = err_M2019[(err_M2019.index > err.index[0]) & (err_M2019.index <= err.index[-1])]

D = D.loc[D.index[:-3]]
err = err.loc[err.index[:-3]]

# | Color       |   R |   G |   B | hex     |
# |-------------+-----+-----+-----+---------|
# | light blue  | 166 | 206 | 227 | #a6cee3 |
# | dark blue   |  31 | 120 | 180 | #1f78b4 |
# | light green | 178 | 223 | 138 | #b2df8a |
# | dark green  |  51 | 160 |  44 | #33a02c |
# | pink        | 251 | 154 | 153 | #fb9a99 |
# | red         | 227 |  26 |  28 | #e31a1c |
# | pale orange | 253 | 191 | 111 | #fdbf6f |
# | orange      | 255 | 127 |   0 | #ff7f00 |
C1="#e31a1c" # red
C2="#1f78b4" # dark blue



MS=4
Z=99
for r in D.columns:
    e = ax_D.errorbar(D[r].index, D[r].values, fmt='o', mfc='none', ms=MS)
    C = e.lines[0].get_color()
    D[r].plot(drawstyle='steps', linewidth=2, ax=ax_D,
              color=C,
              # color='orange'
              alpha=0.75, zorder=Z)
    ax_D.fill_between(D.index, 
                      (D[r]-err[r]), 
                      (D[r]+err[r]),
                      color=C,
                      #hatch="\\",
                      alpha=0.25)

    ax_D.fill_between(D_M2019.index,
                      (D_M2019[r]-err_M2019[r]), 
                      (D_M2019[r]+err_M2019[r]),
                      color=C,
                      # hatch="/",
                      alpha=0.1)

    tx = D.iloc[-1].name + dt.timedelta(days=50)
    ty = D.iloc[-1][r]
    if r in ['CE', 'SW']: ty=ty-4
    if r == 'NE': ty=ty+4
    if r == 'NO': ty=ty-2
    ax_D.text(tx, ty, r, verticalalignment='center')

ax_coverage.set_ylabel('Coverage [%]')
ax_coverage.set_ylim([0,100])
    
import matplotlib.dates as mdates
ax_D.xaxis.set_major_locator(mdates.YearLocator())

ax_D.legend("", framealpha=0)
ax_D.set_xlabel('Time [Years]')
ax_D.set_ylabel('Discharge [Gt yr$^{-1}$]')
# ax_D.set_yscale('log')

# ax_D.xaxis.set_tick_params(rotation=-90)
# for tick in ax_D.xaxis.get_majorticklabels():
#     tick.set_horizontalalignment("left")

plt.savefig('./figs/discharge_ts_regions.png', transparent=False, bbox_inches='tight', dpi=300)
# plt.savefig('./figs/discharge_ts_regions.pdf', transparent=True, bbox_inches='tight', dpi=300)

# Err_pct = (err_day_year.values/D_day_year.values*100).round().astype(np.int).astype(np.str)
# tbl = (D_day_year.round().astype(np.int).astype(np.str) + ' ('+Err_pct+')')
# tbl.index = tbl.index.year.astype(np.str)
# tbl.columns = [_ + ' (Err %)' for _ in tbl.columns]
# tbl
#+END_SRC

#+RESULTS: fig:discharge_ts_regions


*** Discharge Time Series - Sectors
#+BEGIN_SRC python :results raw drawer :display text/org :kernel ice_discharge :session CCI
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# plt.close(1)

fig = plt.figure(1, figsize=(9,5)) # w,h
fig.clf()
# fig.set_tight_layout(True)


ax_D = fig.add_subplot(111)

from adjust_spines import adjust_spines as adj
adj(ax_D, ['left','bottom'])

D = pd.read_csv("./out/sector_D.csv", index_col=0, parse_dates=True)
err = pd.read_csv("./out/sector_err.csv", index_col=0, parse_dates=True)

### Take annual average from daily interpolated rather than the existing samples.
# D_day_year = D.resample('1D',axis='rows').mean().interpolate(method='time',limit_area='inside').resample('A',axis='rows').mean()
# err_day_year=err.resample('1D',axis='rows').mean().interpolate(method='time',limit_area='inside').resample('A',axis='rows').mean()

# D_day_year.plot(ax=ax_D, alpha=0.5)
# D_day_year.sum(axis='columns').plot(ax=ax_D, alpha=0.5)
D[['8.1','7.1']].plot(ax=ax_D, linewidth=3)
ax_D.fill_between(D.index,
                  D['8.1']-err['8.1'],
                  D['8.1']+err['8.1'], alpha=0.25)

ax_D.fill_between(D.index,
                  D['7.1']-err['7.1'],
                  D['7.1']+err['7.1'], alpha=0.25)

ax_D.set_ylim([0,120])
ax_D.set_ylabel("Discharge [Gt yr$^{-1}$]")
ax_D.set_xlabel("Date")
# # largest average for last year
# D_sort = D.resample('Y', axis='rows')\
#           .mean()\
#           .iloc[-1]\
#           .sort_values(ascending=False)

# LABELS={}
# # for k in D_sort.head(8).index: LABELS[k] = k
# # Use the last       ^ glaciers

# # Make legend pretty
# LABELS['JAKOBSHAVN_ISBRAE'] = 'Sermeq Kujalleq (Jakobshavn Isbræ)'
# LABELS['HELHEIMGLETSCHER'] = 'Helheim Gletsjer'
# LABELS['KANGERLUSSUAQ'] = 'Kangerlussuaq Gletsjer'
# LABELS['KOGE_BUGT_C'] = '(Køge Bugt C)'
# LABELS['ZACHARIAE_ISSTROM'] = 'Zachariae Isstrøm'
# LABELS['RINK_ISBRAE'] = 'Kangilliup Sermia (Rink Isbræ)'
# LABELS['NIOGHALVFJERDSFJORDEN'] = '(Nioghalvfjerdsbrae)'
# LABELS['PETERMANN_GLETSCHER'] ='Petermann Gletsjer'

# SYMBOLS={}
# SYMBOLS['JAKOBSHAVN_ISBRAE'] = 'o'
# SYMBOLS['HELHEIMGLETSCHER'] = 's'
# SYMBOLS['KANGERLUSSUAQ'] = 'v'
# SYMBOLS['KOGE_BUGT_C'] = '^'
# SYMBOLS['NIOGHALVFJERDSFJORDEN'] = 'v'
# SYMBOLS['RINK_ISBRAE'] = 's'
# SYMBOLS['ZACHARIAE_ISSTROM'] = 'o'
# SYMBOLS['PETERMANN_GLETSCHER'] ='^'

# MS=4
# Z=99
# for g in LABELS.keys(): # for each glacier
#     e = ax_D.errorbar(D.loc[:,g].index,
#                       D.loc[:,g].values,
#                       label=LABELS[g],
#                       fmt=SYMBOLS[g],
#                       mfc='none',
#                       ms=MS)
#     C = e.lines[0].get_color()
#     D_day_year.loc[:,g].plot(drawstyle='steps', linewidth=2,
#                              label='',
#                              ax=ax_D,
#                              alpha=0.75, color=C, zorder=Z)

#     for i,idx in enumerate(D.loc[:,g].index):
#         ax_D.errorbar(D.loc[:,g].index[i],
#                       D.loc[:,g].values[i],
#                       yerr=err.loc[:,g].values[i],
#                       alpha=coverage.loc[:,g].values[i],
#                       label='',
#                       ecolor='grey',
#                       mfc=C, mec=C,
#                       marker='o', ms=MS)


#     if g in ['NIOGHALVFJERDSFJORDEN', 'KANGERLUSSUAQ']: #, 'JAKOBSHAVN_ISBRAE']:
#         ax_coverage.plot(D.loc[:,g].index,
#                          coverage.loc[:,g].values*100,
#                          drawstyle='steps',
#                          # alpha=0.5,
#                          color=C)

# # yl = ax_D.get_ylim()

# ax_D.legend(fontsize=8, ncol=2, loc=(0.0, 0.82), fancybox=False, frameon=False)
# ax_D.set_xlabel('Time [Years]')
# ax_D.set_ylabel('Discharge [Gt yr$^{-1}$]')

# import matplotlib.dates as mdates
# ax_D.xaxis.set_major_locator(mdates.YearLocator())
# ax_D.xaxis.set_tick_params(rotation=-90)
# for tick in ax_D.xaxis.get_majorticklabels():
#     tick.set_horizontalalignment("left")

# ax_coverage.set_ylabel('Coverage [%]')
# ax_coverage.set_ylim([0,100])


#plt.savefig('./figs/discharge_ts_topfew.svg', transparent=True, bbox_inches='tight', dpi=300)
plt.savefig('./figs/discharge_ts_sectors.png', transparent=False, bbox_inches='tight', dpi=300)
# plt.savefig('./figs/discharge_ts_topfew.pdf', transparent=True, bbox_inches='tight', dpi=300)

# Err_pct = (err_day_year / D_day_year*100).round().astype(np.int).astype(np.str)
# Err_pct = Err_pct[list(LABELS.keys())]
# tbl = D_day_year[list(LABELS.keys())].round().astype(np.int).astype(np.str) + ' (' + Err_pct+')'
# tbl.index = tbl.index.year.astype(np.str)
# tbl.columns = [_ + ' (%)' for _ in tbl.columns]
# tbl
#+END_SRC

#+RESULTS:
:results:
None
:end:


*** This v. Mankoff (2019)
#+NAME: name
#+BEGIN_SRC python :session compare :exports results :results raw drawer
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

CCI = pd.read_csv("./out/GIS_D.csv", index_col=0, parse_dates=True)\
        .rename({'Discharge [Gt yr-1]':'CCI'}, axis='columns')
ID = pd.read_csv("/home/shl@geus.dk/OneDrive/projects/promice/solid_ice_discharge/dataverse_data", index_col=0, parse_dates=True)\
       .rename({'Discharge [Gt yr-1]':'Mankoff (2019)'}, axis='columns')

df = pd.merge(CCI,ID,how='outer', left_index=True, right_index=True).dropna()
# df['diff'] = df['Mankoff (2019)'] - df['CCI']
df.plot()

plt.savefig("./figs/this_v_M2019.png", dpi=300)
#+END_SRC

#+RESULTS: name
:results:
:end:

** Distribution for CCI

Example: http://products.esa-icesheets-cci.org/products/details/greenland_iv_50m_s2_20170501_20170914_petermann_v1_1.zip/

It is the optical IV generated by S&T. I believe it follows all the
guidelines listed below.

*GUIDELINES*

1. The *name of the zip file and the name of the top-level folder inside
the zip* file should follow the logic of old products. Please download
the previous version of your product from the CCI website to understand
what this means. For new products, try to follow the structure of the
filename of the example provided in this email.

2. A *quicklook image in .png or .jpg format*. Size can *not exceed*
 1200x1200. This should be contained in the above zip file.

3. A short text file called *description.txt with a brief description of
the product*. The description *can not exceed 100 characters. *This
should also be contained in the above zip file.

4. *A SINGLE text file called README or comments.txt*,  with comments on
the preparation and content of the product . You are encouraged to include
paragraphs "Citable as:" and "References:" if this applies to your
product. This should also be contained in the above zip file.

5. *File permissions.* Inside the zip, files should be 644 (writable to
the owner, readable to everyone, not executable, represented as
"-rw-r--r--"), and directory permissions should be 755 (writable to the
owner, readable and executable to everyone, represented as "drwxr-xr-x").
On a Unix/MacOS/Linux system you list permissions with the command "ls -l",
and correct them with "chmod 644 {filename}" or "chmod 755 {directory}

6. There should not be any spare or hidden files or directories included
in the zip (like e.g. the hidden __MACOS folder you often get when creating
a zipped folder on MacOS).

#+NAME: dist_for_CCI
#+BEGIN_SRC bash :results verbatim
mkdir -p MFID
#+END_SRC

#+RESULTS: dist_for_CCI

#+BEGIN_SRC org :tangle ./MFID/description.txt :mkdirp ./MFID :tangle-mode (identity #o644)
Mass flow rate ice discharge (MFID) for Greenland from CCI IV, CCI SEC, and BedMachine
#+END_SRC

#+BEGIN_SRC org :tangle ./MFID/README.txt :mkdirp ./MFID :tangle-mode (identity #o644)
Mass flow rate ice discharge (MFID) for Greenland ice sheet sectors.

This data set is part of the ESA Greenland Ice sheet CCI project. 
It provides the following CSV files.
1. Mass flow rate ice discharge. Units are Gt yr^{-1}.
2. Mass flow rate ice discharge uncertainty. Units are Gt yr^{-1}.
3. Coverage for each sector at each timestamp. Unitless [0 to 1].

Ice discharge is calculated from the CCI Ice Velocity (IV) product, the CCI Surface Elevation Change (SEC) product (where it overlaps with the ice discharge gates), and ice thickness from BedMachine. Ice discharge gates are placed 10 km upstream from all marine terminating glacier termini that have baseline velocities of more than 150 m/yr. Results are summed by Zwally et al. (2012) sectors.

The methods, including description of "coverage", are described in Mankoff /et al/. (2020; DOI: 10.5194/essd-12-1367-2020)
#+END_SRC

#+BEGIN_SRC python :session MFID :exports results :results raw drawer :kernel ice_discharge
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt

from matplotlib import rc
rc('font', size=12)
rc('text', usetex=False)
# matplotlib.pyplot.xkcd()

# plt.close(1)
fig = plt.figure(1, figsize=(5,4)) # w,h
fig.clf()
fig.set_tight_layout(True)
ax = fig.add_subplot(111)

# Reformat data for CCI
df = pd.read_csv("./out/sector_D.csv", index_col=0, parse_dates=True)\
       .resample('MS')\
       .mean()\
       .to_csv("./MFID/MFID.csv", float_format='%.3f')

df = pd.read_csv("./out/sector_err.csv", index_col=0, parse_dates=True)\
       .resample('MS')\
       .mean()\
       .to_csv("./MFID/MFID_err.csv", float_format='%.3f')

df = pd.read_csv("./out/sector_coverage.csv", index_col=0, parse_dates=True)\
       .resample('MS')\
       .mean()\
       .to_csv("./MFID/coverage.csv", float_format='%.3f')

# Graphic
df = pd.read_csv("./out/sector_D.csv", index_col=0, parse_dates=True)\
       .resample('MS')\
       .mean()\

err = pd.read_csv("./out/sector_err.csv", index_col=0, parse_dates=True)\
        .resample('MS')\
        .mean()\

dsum = df.sum(axis='columns')
errsum = err.sum(axis='columns')
dsum.plot(ax=ax, color='k')
ax.fill_between(dsum.index, dsum-errsum, dsum+errsum, color='grey', alpha=0.25)
ax.set_ylabel("Discharge [Gt yr$^{-1}$]")

plt.savefig('./MFID/MFID.png', transparent=False, bbox_inches='tight')
#+END_SRC

#+RESULTS:

#+NAME: post_dist
#+BEGIN_SRC bash :results verbatim
cp gates_and_zwally.png ./MFID
(cd MFID; chmod og-w *)
zip -r MFID.zip MFID
cp MFID.zip ~/Dropbox/out/
dbsl ~/Dropbox/out/MFID.zip
#+END_SRC

#+RESULTS: post_dist
: 
: $ updating: MFID/ (stored 0%)
: )
: )
: )
: )
: )
: )
: )

*** WWW

The mass flow rate and ice discharge (MFID) product generated in the Greenland Ice Sheet CCI are derived from the CCI ice velocity (IV) product, the CCI surface elevation change (SEC) product (where it overlaps with the gates), and ice thickness from BedMachine (v3). Ice discharge gates are placed 10 km upstream from all marine terminating glacier termini that have baseline velocities of more than 150 m/yr. Results are summed by Zwally et al. (2012) sectors. Full details of the methods are provided in the Algorithm Theorotical Basis Document (ATBD) or in Mankoff et al. (2019). 

The following figure shows the sectors and gate locations within each sector.

<Greenland image here>

MFID is provided as a time series CSV file where each column represents one sector from with units in Gt/yr. Additional files provide error estimates and coverage (a measure of gap-filling).

<discharge figure here>

The product is generated by GEUS.

* References                                              :ignore:

# #+LaTeX: \bibliographystyle{copernicus}
# # #+LaTeX: \bibliography{/home/kdm/Documents/Papers/library,local}{}
# # #+LaTeX: \bibliography{local}{}
# #+LaTeX: \bibliography{ice_discharge}{}

* Meta                                                  :noexport:
:PROPERTIES:
:header-args: :tangle no
:END:

This document probably uses code - python, octave, and/or R. Below I provide the version of the software(s) used to create this document in order to support the goal of reproduciblity. 
*** Emacs
#+BEGIN_SRC elisp
(emacs-version)
#+END_SRC
#+RESULTS:
: GNU Emacs 25.2.2 (x86_64-pc-linux-gnu, GTK+ Version 3.22.21)
:  of 2017-09-22, modified by Debian
*** Org Mode
#+BEGIN_SRC elisp
(org-version nil t)
#+END_SRC
#+RESULTS:
: Org mode version 9.2.3 (9.2.3-7-g222408-elpaplus @ /home/kdm/.emacs.d/elpa/org-plus-contrib-20190415/)

*** Python
#+BEGIN_SRC bash :cmdline -i :results verbatim
. /home/kdm/local/anaconda/etc/profile.d/conda.sh
conda env export --name sci
#+END_SRC
#+RESULTS:
#+begin_example
name: sci
channels:
  - https://repo.anaconda.com/pkgs/free
  - conda-forge
  - defaults
dependencies:
  - affine=2.2.1=py_0
  - asn1crypto=0.24.0=py36_1003
  - attrs=18.2.0=py_0
  - backcall=0.1.0=py_0
  - blas=1.0=mkl
  - bokeh=1.0.1=py36_1000
  - boost-cpp=1.68.0=h3a22d5f_0
  - boto3=1.9.58=py_0
  - botocore=1.12.58=py_0
  - bottleneck=1.2.1=py36h7eb728f_1
  - bzip2=1.0.6=h470a237_2
  - ca-certificates=2019.3.9=hecc5488_0
  - cairo=1.14.12=he6fea26_5
  - certifi=2019.3.9=py36_0
  - cffi=1.11.5=py36h5e8e0c9_1
  - cftime=1.0.2.1=py36h7eb728f_0
  - click=7.0=py_0
  - click-plugins=1.0.4=py_0
  - cligj=0.5.0=py_0
  - cloudpickle=0.6.1=py_0
  - cryptography=2.6.1=py36h72c5cf5_0
  - cryptography-vectors=2.3.1=py36_1000
  - curl=7.64.1=hf8cf82a_0
  - cycler=0.10.0=py_1
  - cytoolz=0.9.0.1=py36h470a237_1
  - dask=0.20.0=py_0
  - dask-core=0.20.0=py_0
  - dbus=1.13.0=h3a4f0e9_0
  - decorator=4.3.0=py_0
  - descartes=1.1.0=py_2
  - dill=0.2.8.2=py36_1000
  - distributed=1.24.0=py36_1000
  - docutils=0.14=py36_1001
  - entrypoints=0.2.3=py36_1002
  - expat=2.2.5=hfc679d8_2
  - fontconfig=2.13.1=h65d0f4c_0
  - freetype=2.9.1=h6debe1e_4
  - freexl=1.0.5=h470a237_2
  - geos=3.6.2=hfc679d8_4
  - geotiff=1.4.2=h700e5ad_5
  - gettext=0.19.8.1=h5e8e0c9_1
  - giflib=5.1.4=h470a237_1
  - glib=2.55.0=h464dc38_2
  - gmp=6.1.2=hfc679d8_0
  - gst-plugins-base=1.12.5=hde13a9d_0
  - gstreamer=1.12.5=h61a6719_0
  - h5netcdf=0.6.2=py_0
  - h5py=2.8.0=py36h470a237_0
  - hdf4=4.2.13=h951d187_2
  - hdf5=1.10.1=2
  - heapdict=1.0.0=py36_1000
  - icu=58.2=hfc679d8_0
  - idna=2.8=py36_1000
  - intel-openmp=2019.0=118
  - ipykernel=5.1.0=pyh24bf2e0_0
  - ipython=7.1.1=py36h24bf2e0_1000
  - ipython_genutils=0.2.0=py_1
  - ipywidgets=7.4.2=py_0
  - jedi=0.13.1=py36_1000
  - jinja2=2.10=py_1
  - jmespath=0.9.3=py_1
  - jpeg=9c=h470a237_1
  - json-c=0.12.1=h470a237_1
  - jsonschema=3.0.0a3=py36_1000
  - jupyter=1.0.0=py_1
  - jupyter_client=5.2.3=py_1
  - jupyter_console=6.0.0=py_0
  - jupyter_core=4.4.0=py_0
  - kealib=1.4.8=hfc679d8_0
  - kiwisolver=1.0.1=py36h2d50403_2
  - krb5=1.16.3=h05b26f9_1001
  - libcurl=7.64.1=hda55be3_0
  - libdap4=3.19.1=h8fe5423_1
  - libedit=3.1.20170329=haf1bffa_1
  - libffi=3.2.1=hfc679d8_5
  - libgcc-ng=8.2.0=hdf63c60_1
  - libgfortran=3.0.0=1
  - libgfortran-ng=7.2.0=hdf63c60_3
  - libiconv=1.15=h470a237_3
  - libkml=1.3.0=he469717_9
  - libnetcdf=4.4.1.1=10
  - libpng=1.6.35=ha92aebf_2
  - libpq=11.2=h4770945_0
  - libsodium=1.0.16=h470a237_1
  - libspatialindex=1.8.5=hfc679d8_3
  - libspatialite=4.3.0a=hdfcc80b_23
  - libssh2=1.8.2=h22169c7_2
  - libstdcxx-ng=7.3.0=hdf63c60_0
  - libtiff=4.0.9=he6b73bb_2
  - libuuid=2.32.1=h470a237_2
  - libxcb=1.13=h470a237_2
  - libxml2=2.9.8=h422b904_5
  - locket=0.2.0=py_2
  - markupsafe=1.0=py36h470a237_1
  - matplotlib=3.0.3=py36_0
  - matplotlib-base=3.0.3=py36h167e16e_0
  - mistune=0.8.4=py36h470a237_0
  - mkl=2018.0.3=1
  - mkl_fft=1.0.6=py36_0
  - mkl_random=1.0.1=py36_0
  - msgpack-python=0.5.6=py36h2d50403_3
  - munch=2.3.2=py_0
  - nbconvert=5.3.1=py_1
  - nbformat=4.4.0=py_1
  - ncurses=6.1=hfc679d8_1
  - netcdf4=1.3.1=py36_1
  - notebook=5.7.0=py36_1000
  - numpy=1.14.2=py36hdbf6ddf_0
  - numpy-base=1.15.3=py36h81de0dd_0
  - olefile=0.46=py_0
  - openblas=0.3.3=ha44fe06_1
  - openjpeg=2.3.0=h0e734dc_3
  - openssl=1.1.1b=h14c3975_1
  - packaging=18.0=py_0
  - pandoc=2.3.1=0
  - pandocfilters=1.4.2=py_1
  - parso=0.3.1=py_0
  - partd=0.3.9=py_0
  - patsy=0.5.1=py_0
  - pcre=8.41=hfc679d8_3
  - pexpect=4.6.0=py36_1000
  - pickleshare=0.7.5=py36_1000
  - pillow=5.3.0=py36hc736899_0
  - pint=0.8.1=py_1
  - pip=18.1=py36_1000
  - pixman=0.34.0=h470a237_3
  - poppler=0.61.1=h4d7e492_4
  - poppler-data=0.4.9=0
  - postgresql=11.2=h61314c7_0
  - proj4=4.9.3=h470a237_8
  - prometheus_client=0.4.2=py_0
  - prompt_toolkit=2.0.7=py_0
  - psutil=5.4.8=py36h470a237_0
  - psycopg2=2.8.1=py36h72c5cf5_0
  - pthread-stubs=0.4=h470a237_1
  - ptyprocess=0.6.0=py36_1000
  - pycparser=2.19=py_0
  - pygments=2.2.0=py_1
  - pyopenssl=18.0.0=py36_1000
  - pyparsing=2.3.0=py_0
  - pyproj=1.9.5.1=py36h508ed2a_6
  - pyqt=4.11.4=py36_3
  - pyrsistent=0.14.5=py36h470a237_1
  - pysal=1.14.4.post2=py36_1001
  - pyshp=1.2.12=py_2
  - pysocks=1.6.8=py36_1002
  - python=3.6.7=h0371630_0
  - python-dateutil=2.7.5=py_0
  - pytz=2018.7=py_0
  - pyyaml=3.13=py36h470a237_1
  - pyzmq=17.1.2=py36hae99301_1
  - qt=4.8.7=2
  - qtconsole=4.4.2=py_1
  - readline=7.0=haf1bffa_1
  - rtree=0.8.3=py36_1000
  - s3transfer=0.1.13=py36_1001
  - scipy=1.1.0=py36hc49cb51_0
  - send2trash=1.5.0=py_0
  - setuptools=40.5.0=py36_0
  - shapely=1.6.4=py36h164cb2d_1
  - simplejson=3.16.1=py36h470a237_0
  - simplekml=1.3.0=py_1
  - sip=4.18=py36_1
  - six=1.11.0=py36_1001
  - snuggs=1.4.1=py_1
  - sortedcontainers=2.0.5=py_0
  - sqlalchemy=1.2.15=py36h470a237_0
  - sqlite=3.25.2=hb1c47c0_0
  - statsmodels=0.9.0=py36h7eb728f_0
  - tabulate=0.8.2=py_0
  - tblib=1.3.2=py_1
  - terminado=0.8.1=py36_1001
  - testpath=0.4.2=py36_1000
  - tk=8.6.9=h84994c4_1001
  - toolz=0.9.0=py_1
  - tornado=5.1.1=py36h470a237_0
  - traitlets=4.3.2=py36_1000
  - tzcode=2018g=h14c3975_1001
  - uncertainties=3.0.3=py36_1000
  - urllib3=1.24.1=py36_1000
  - wcwidth=0.1.7=py_1
  - wheel=0.32.2=py36_0
  - widgetsnbextension=3.4.2=py36_1000
  - xarray=0.11.0=py36_1000
  - xerces-c=3.2.0=h5d6a6da_2
  - xorg-kbproto=1.0.7=h470a237_2
  - xorg-libice=1.0.9=h470a237_4
  - xorg-libsm=1.2.3=h8c8a85c_0
  - xorg-libx11=1.6.6=h470a237_0
  - xorg-libxau=1.0.8=h470a237_6
  - xorg-libxdmcp=1.1.2=h470a237_7
  - xorg-libxext=1.3.3=h470a237_4
  - xorg-libxrender=0.9.10=h470a237_2
  - xorg-renderproto=0.11.1=h470a237_2
  - xorg-xextproto=7.3.0=h470a237_2
  - xorg-xproto=7.0.31=h470a237_7
  - xz=5.2.4=h470a237_1
  - yaml=0.1.7=h470a237_1
  - zeromq=4.2.5=hfc679d8_6
  - zict=0.1.3=py_0
  - zlib=1.2.11=h470a237_3
  - pip:
    - atomicwrites==1.3.0
    - bleach==3.0.2
    - chardet==3.0.4
    - csvs-to-sqlite==1.0
    - dateparser==0.7.1
    - fastkml==0.11
    - future==0.17.1
    - grass-session==0.1
    - ical2orgpy==0.2.0
    - icalendar==4.0.3
    - importlib-metadata==0.18
    - more-itertools==7.2.0
    - mpmath==1.1.0
    - pandas==0.25.1
    - pluggy==0.12.0
    - py==1.8.0
    - py-lru-cache==0.1.4
    - pycwt==0.3.0a22
    - pygeoif==0.7
    - pytest==5.0.1
    - q==2.6
    - regex==2019.8.19
    - seaborn==0.9.0
    - sty==1.0.0b9
    - sympy==1.3
    - tqdm==4.28.1
    - tzlocal==1.5.1
    - webencodings==0.5.1
    - xlrd==1.2.0
    - zipp==0.5.2
prefix: /home/kdm/local/anaconda/envs/sci

#+end_example

*** LaTeX
#+BEGIN_SRC bash :cmdline "-i" :results verbatim
pdflatex --version
#+END_SRC
#+RESULTS:
#+begin_example
pdfTeX 3.14159265-2.6-1.40.18 (TeX Live 2017/Debian)
kpathsea version 6.2.3
Copyright 2017 Han The Thanh (pdfTeX) et al.
There is NO warranty.  Redistribution of this software is
covered by the terms of both the pdfTeX copyright and
the Lesser GNU General Public License.
For more information about these matters, see the file
named COPYING and the pdfTeX source.
Primary author of pdfTeX: Han The Thanh (pdfTeX) et al.
Compiled with libpng 1.6.34; using libpng 1.6.34
Compiled with zlib 1.2.11; using zlib 1.2.11
Compiled with poppler version 0.62.0
#+end_example

* LaTeX Header                                            :ignore:
#+LaTeX_CLASS_OPTIONS: [article,letterpaper,times,12pt]
** References                                             :ignore:

#+LATEX_HEADER_EXTRA:%\usepackage[bibstyle=authoryear,firstinits=true,maxbibnames=99]{biblatex}
#+LATEX_HEADER_EXTRA: \usepackage[hyperref=true,
#+LATEX_HEADER_EXTRA:             %sorting=none, 
#+LATEX_HEADER_EXTRA:             sorting=nyt,
#+LATEX_HEADER_EXTRA:             %style=numeric, 
#+LATEX_HEADER_EXTRA:             date=year,
#+LATEX_HEADER_EXTRA:             style=authoryear,
#+LATEX_HEADER_EXTRA:             %defernumbers=true, 
#+LATEX_HEADER_EXTRA:             firstinits=true, 
#+LATEX_HEADER_EXTRA:             uniquename=false,
#+LATEX_HEADER_EXTRA:             uniquelist=false,
#+LATEX_HEADER_EXTRA:             %uniquelist=minyear,
#+LATEX_HEADER_EXTRA:             maxnames=99, 
#+LATEX_HEADER_EXTRA:             maxcitenames=1]{biblatex}
# # #+LATEX_HEADER_EXTRA:\addbibresource{library.bib,/home/kdm/Documents/Papers/library.bib}
# #+LATEX_HEADER_EXTRA:\addbibresource{library.bib}
#+LATEX_HEADER_EXTRA:\addbibresource{/home/kdm/Documents/Papers/library.bib}
#+LATEX_HEADER_EXTRA: \renewbibmacro{in:}{}

# biber <texfile><.NOEXT> --output_format bibtex

# http://tex.stackexchange.com/a/5779/360
#+LATEX_HEADER_EXTRA: % Don't print URL if DOI field exists
#+LATEX_HEADER_EXTRA: \DeclareFieldFormat{url}{%
#+LATEX_HEADER_EXTRA:   \iffieldundef{doi}{%
#+LATEX_HEADER_EXTRA:     \mkbibacro{URL}\addcolon\space\url{#1}%
#+LATEX_HEADER_EXTRA:   }{%
#+LATEX_HEADER_EXTRA:   }%
#+LATEX_HEADER_EXTRA: }
#+LATEX_HEADER_EXTRA: % Don't print URL if DOI field exists
#+LATEX_HEADER_EXTRA: \DeclareFieldFormat{urldate}{%
#+LATEX_HEADER_EXTRA:   \iffieldundef{doi}{%
#+LATEX_HEADER_EXTRA:     \mkbibparens{\bibstring{urlseen}\space#1}%
#+LATEX_HEADER_EXTRA:   }{%
#+LATEX_HEADER_EXTRA:   }%
#+LATEX_HEADER_EXTRA: }

#+LATEX_HEADER_EXTRA: \renewbibmacro*{journal+issuetitle}{%
#+LATEX_HEADER_EXTRA: \usebibmacro{journal}%
#+LATEX_HEADER_EXTRA: \setunit*{\addspace}%
#+LATEX_HEADER_EXTRA: \iffieldundef{series}
#+LATEX_HEADER_EXTRA: {}
#+LATEX_HEADER_EXTRA: {\newunit
#+LATEX_HEADER_EXTRA: \printfield{series}%
#+LATEX_HEADER_EXTRA: \setunit{\addspace}}%
#+LATEX_HEADER_EXTRA: \usebibmacro{issue+date}%
#+LATEX_HEADER_EXTRA: \setunit{\addcomma\space}%
#+LATEX_HEADER_EXTRA: \usebibmacro{volume+number+eid}%
#+LATEX_HEADER_EXTRA: \setunit{\addcolon\space}%
#+LATEX_HEADER_EXTRA: \usebibmacro{issue}%
#+LATEX_HEADER_EXTRA: \newunit}

#+LATEX_HEADER_EXTRA: \newbibmacro*{issue+date}{%
#+LATEX_HEADER_EXTRA: \iffieldundef{issue}
#+LATEX_HEADER_EXTRA: {. \usebibmacro{date}}
#+LATEX_HEADER_EXTRA: {\printfield{issue}%
#+LATEX_HEADER_EXTRA: \setunit*{\addspace}%
#+LATEX_HEADER_EXTRA: \usebibmacro{date}}%
#+LATEX_HEADER_EXTRA: \newunit}

#+LATEX_HEADER_EXTRA: \renewbibmacro*{volume+number+eid}{%
#+LATEX_HEADER_EXTRA: \printfield{volume}%
#+LATEX_HEADER_EXTRA: \setunit*{\addnbspace}% NEW (optional); there's also #+LATEX_HEADER_EXTRA: \addnbthinspace
#+LATEX_HEADER_EXTRA: \printfield{number}%
#+LATEX_HEADER_EXTRA: \setunit{\addcomma\space}%
#+LATEX_HEADER_EXTRA: \printfield{eid}}
#+LATEX_HEADER_EXTRA: \DeclareFieldFormat[article]{number}{\mkbibparens{#1}}

#+LATEX_HEADER_EXTRA: \DeclareFieldFormat{pages}{#1}

** Page and Fonts                                         :ignore:

#+LATEX_HEADER_EXTRA: \pdfpagewidth 8.5in
#+LATEX_HEADER_EXTRA: \pdfpageheight 11in
#+LATEX_HEADER_EXTRA:  \usepackage{setspace}
#+LATEX_HEADER_EXTRA:  \usepackage{hyperref} % links (citations, references, URLs, etc.)
#+LATEX_HEADER_EXTRA:  \usepackage{fixltx2e} % fix some bugs. Require proper coding of equations...
#+LATEX_HEADER_EXTRA:  \usepackage{enumitem}\setlist{nosep} % shrink space between bullets
#+LATEX_HEADER_EXTRA:  \usepackage{lmodern}  % better i18n Postscript version of Knuth's cm fonts
#+LATEX_HEADER_EXTRA:  \usepackage[final,protrusion=true,expansion=true]{microtype} % nice font tweaks
#+LATEX_HEADER_EXTRA:  \usepackage[small,compact, sf]{titlesec} % reduce space
#+LATEX_HEADER_EXTRA:  \usepackage[margin=1in]{geometry} % set page margins automatically 
#+LATEX_HEADER_EXTRA:  \usepackage[parfill]{parskip}  % paragraphs have vert space not indent
#+LATEX_HEADER_EXTRA:  %\usepackage{paralist} %\begin{compactitem} http://www.howtotex.com/packages/compact-lists-with-paralist
#+LATEX_HEADER_EXTRA:  \usepackage[T1]{fontenc}
#+LATEX_HEADER_EXTRA:  \usepackage[sc]{mathpazo} % Palatino font
#+LATEX_HEADER_EXTRA:  \usepackage{fancyref} % \fref{fig:foo} makes everything pretty...
#+LATEX_HEADER_EXTRA:  \usepackage{flafter} % make sure figures do not appear before their text:    
#+LATEX_HEADER_EXTRA:  \usepackage[all]{hypcap} % links from go to top of table/image, not bottom.
#+LATEX_HEADER_EXTRA:  \usepackage[section]{placeins} % floats get placed in the section
#+LATEX_HEADER_EXTRA:  \usepackage{siunitx}
#+LATEX_HEADER_EXTRA:  \usepackage{commath} % \dif, \od, \pd, \md, etc.
#+LATEX_HEADER_EXTRA:  \usepackage{amsmath} % provides \eqref which adds []'s. 
#+LATEX_HEADER_EXTRA:  %\numberwithin{equation}{section} % reference equations as [3.42] rather than 42.
#+LATEX_HEADER_EXTRA:  \usepackage{amsfonts} % I hear these are also good to load
#+LATEX_HEADER_EXTRA:  \usepackage{amssymb} % I hear these are also good to load
#+LATEX_HEADER_EXTRA:  \usepackage[all]{onlyamsmath} % don't allow $$, eqnarray, etc.
#+LATEX_HEADER_EXTRA:  %\usepackage{tocbibind} % add bib to toc

** Code                                                   :ignore:
# #+LATEX_HEADER_EXTRA:  \usepackage[gobble=auto]{pythontex}
# #+LATEX_HEADER_EXTRA:  \setpythontexworkingdir{./}
# #+LATEX_HEADER_EXTRA:  \usepackage{minted}
# #+LATEX_HEADER_EXTRA:  \usemintedstyle{emacs}
# #+LATEX_HEADER_EXTRA:  \newminted{common-lisp}{fontsize=\footnotesize}
#+LATEX_HEADER_EXTRA: \BeforeBeginEnvironment{minted}{\begin{mdframed}}
#+LATEX_HEADER_EXTRA: \AfterEndEnvironment{minted}{\end{mdframed}}
** Hyperref                                               :ignore:
#+LATEX_HEADER_EXTRA:  %\usepackage{datetime}\renewcommand{\dateseparator}{-}
#+LATEX_HEADER_EXTRA:  \usepackage{xspace} % smart spaces
#+LATEX_HEADER_EXTRA:  \hypersetup{
#+LATEX_HEADER_EXTRA:    colorlinks=true,       % links are colored
#+LATEX_HEADER_EXTRA:    urlcolor=blue,    % color of external links
#+LATEX_HEADER_EXTRA:    linkcolor=blue,   % color of internal links
#+LATEX_HEADER_EXTRA:    citecolor=blue,   % color of links to bibliography
#+LATEX_HEADER_EXTRA:    draft=false, % link even in draft mode
#+LATEX_HEADER_EXTRA:    bookmarksopen=true, % ?
#+LATEX_HEADER_EXTRA:    pdfdisplaydoctitle=true}
#+LATEX_HEADER_EXTRA:  \renewcommand{\textfraction}{0.05}
#+LATEX_HEADER_EXTRA:  \renewcommand{\topfraction}{0.8}
#+LATEX_HEADER_EXTRA:  \renewcommand{\bottomfraction}{0.8}
#+LATEX_HEADER_EXTRA:  \renewcommand{\floatpagefraction}{0.75}

** Figures                                                :ignore:
#+LATEX_HEADER_EXTRA:  \usepackage{pdfpages}
#+LATEX_HEADER_EXTRA:  \usepackage[final]{graphicx} % [final] means show figs in draft mode
#+LATEX_HEADER_EXTRA:  \setkeys{Gin}{draft=false}
#+LATEX_HEADER_EXTRA:  %\usepackage{wrapfig}
#+LATEX_HEADER_EXTRA:  %\usepackage[Export]{adjustbox} % http://latex-alive.tumblr.com/post/81481408449
#+LATEX_HEADER_EXTRA:  %\adjustboxset{max size={\textwidth}{0.7\textheight}}
#+LATEX_HEADER_EXTRA:  \usepackage{mdframed}

** Draft Mode                                             :ignore:
# DRAFT
#+LATEX_HEADER_EXTRA:  \usepackage{ifdraft} % used for conditional stuff
#+LATEX_HEADER_EXTRA:  % \ifdraft{
#+LATEX_HEADER_EXTRA:  %   \usepackage{draftwatermark}
#+LATEX_HEADER_EXTRA:  %   \SetWatermarkText{DRAFT}
#+LATEX_HEADER_EXTRA:  %   \SetWatermarkLightness{0.95}
#+LATEX_HEADER_EXTRA:  %   \SetWatermarkScale{2}}{}
#+LATEX_HEADER_EXTRA:  \ifdraft{\usepackage{lineno}\linenumbers\modulolinenumbers[5]}{}
#+LATEX_HEADER_EXTRA:  \ifdraft{\doublespacing}{}
#+LATEX_HEADER_EXTRA:  %\ifdraft{\usepackage{showlabels}}{}

** Header/Footer                                          :ignore:
# Header/footer
#+LATEX_HEADER_EXTRA:  \usepackage{lastpage} % used in the footer of fancyheader
#+LATEX_HEADER_EXTRA:  \usepackage{fancyhdr}
#+LATEX_HEADER_EXTRA:  \pagestyle{fancyplain}
#+LATEX_HEADER_EXTRA:  \lhead{}\chead{}\rhead{}
#+LATEX_HEADER_EXTRA:  \lfoot{}\cfoot{}\rfoot{}
#+LATEX_HEADER_EXTRA:  \lfoot{K. D. Mankoff} 
#+LATEX_HEADER_EXTRA:  \rfoot{p. \thepage\ of \pageref*{LastPage}} % * means no link
#+LATEX_HEADER_EXTRA:  \ifdraft{\chead{DRAFT -- DO NOT DISTRIBUTE}}{}
#+LATEX_HEADER_EXTRA:  \renewcommand{\headrulewidth}{0.0pt} % no bars but thanks anyway.
#+LATEX_HEADER_EXTRA:  \renewcommand{\footrulewidth}{0.0pt} 
** GitInfo                                                :ignore:
# GitInfo
#+LATEX_HEADER_EXTRA: \usepackage[mark,missing={master}]{gitinfo2}
#+LATEX_HEADER_EXTRA: \renewcommand{\gitMark}{\gitBranch\,@\,\gitAbbrevHash{}\gitDirty\,[\gitAuthorDate]}

** Embedded file                                          :ignore:
# #+LATEX_HEADER_EXTRA: \usepackage{embedfile}
# #+LATEX_HEADER_EXTRA: \embedfile{\jobname.org}

* TODO QC                                               :noexport:

(langtool-check)
(langtool-correct-buffer)
(langtool-check-done)

Export as ASCII, then,

#+BEGIN_SRC elisp :results none :eval no-export
(setq org-ascii-text-width 80)
(org-ascii-export-to-ascii)
#+END_SRC

#+BEGIN_SRC bash :cmdline "-i" :results output :eval no-export :exports none
this='ice_discharge.txt'
# aspell list < $this | sort | uniq
echo "\n"

declare -a cmds=("style" "diction -s")
for cmd in "${cmds[@]}"; do
    echo "###\n### $cmd\n###"
    #echo $cmd $this
    ${cmd} ${this}
    echo "\n"
done
#+END_SRC
#+RESULTS:

* LaTeXdiff                                             :noexport:
#+BEGIN_SRC bash :results verbatim :results none :eval no-export

OLD=ice_discharge.2537c3a.tex
NEW=ice_discharge.tex
latexdiff --disable-citation-markup --append-safecmd="textcite,autocite" --config="PICTUREENV=(?:picture|DIFnomarkup|tabular)[\w\d*@]*" $OLD $NEW > diff.tex

# NOTE: Stil requires some manual editing of diff.tex, particularly
# when \DIFDEL and \DIFADD are inside CITE commands.

# latexmk diff.tex
#+END_SRC
#+RESULTS:

* Release                                               :noexport:
** Share w/ Coauthors
#+BEGIN_SRC bash :results verbatim
bibexport -o ice_discharge.bib ice_discharge.aux
pandoc -f latex -i ice_discharge.tex -t DOCX -o ice_discharge.docx --bibliography ./ice_discharge.bib

zip -r ice_discharge.zip ice_discharge.pdf ice_discharge.docx ice_discharge.tex ice_discharge.org
mv ice_discharge.zip ~/Dropbox/out/ice_discharge.zip

alias pbcopy='xsel --clipboard --input'
alias pbpaste='xsel --clipboard --output'
dropbox sharelink ~/Dropbox/out/ice_discharge.zip | pbcopy; pbpaste
#+END_SRC
#+RESULTS:
: This is BibTeX, Version 0.99d (TeX Live 2017/Debian)
: The top-level auxiliary file: bibexp.1548456057.aux
: The style file: export.bst
: Database file #1: /home/kdm/Documents/Papers/library.bib
:   adding: ice_discharge.pdf (deflated 11%)
:   adding: ice_discharge.docx (deflated 0%)
: https://www.dropbox.com/s/opxvww4sty3sv5v/ice_discharge.zip?dl=0
* Doc
** Pandoc

#+NAME: pandoc
#+BEGIN_SRC bash :results verbatim
fn=ATBD_kdm
fn=E3UB_kdm
fn=SSD_kdm

# open tex file
# (reftex-create-bibtex-file)

# rm ${fn}.bib
# bibexport -o ${fn}.bib ${fn}.aux
# biber --output_format=bibtex --output_resolve ${fn}.bcf
# pandoc -f latex -i ${fn}.tex -t DOCX -o ${fn}.docx --bibliography ./${fn}.bib

parallel -j1 "pandoc -f latex -i {}.tex -t DOCX -o {}.docx --bibliography ./{}.bib" ::: ATBD_kdm E3UB_kdm SSD_kdm
o ${fn}.docx
#+END_SRC

** Introduction

+ From [[mu4e:msgid:2472981.BbhlL0Da9A@enveo-26.enveo.hq][[GIS CCI+] ATBD and E3UB]]:

#+BEGIN_QUOTE
Dear GIS CCI+ Team,

Please find attached the template documents for the GIS CCI+ ATBD and E3UB (also on the GDrive). The documents have chapters and sub-chapters for each ECV. If possible please provide your input back to me before next telecon 17th December. As a guideline the old documents (ATBD & CECR) are on the GDrive as well, I think max 10 pages/5 pages for the ATBD & E3UB respectively (including figures) for each ECV should be sufficient. Let me know if you have any questions.

Best regards,

Jan
#+END_QUOTE

With link to
+ [[./ST-DTU-ESA-GISCCI+-ATBD-001_v0.6.docx]]
+ [[./ST-DTU-ESA-GISCCI+-E3UB-001-v0.6.docx]]


** ATBD
:PROPERTIES:
:EXPORT_FILE_NAME: ATBD_kdm
:END:

*** Mass Flow Rate and Ice Discharge

Here we present the mass flow rate and ice discharge (MFID). This work is based on the published data, algorithm, and code from citet:mankoff_2019_ice but with the following changes:

+ We only use CCI Ice Velocity (IV) data.
+ The baseline velocity, used to place the discharge gates, is the average 2018 velocity.
+ Surface elevation change (from citet:simonsen_2017_implications, citet:sorensen_2015_envisat, citet:khvorostovsky_2012_merging, and citet:CCI_SEC_data) is only applied in a few cases where the two data overlap.
+ Gates are 10 km upstream from the baseline termini, rather than 5 km as in citet:mankoff_2019_ice.
+ Cutoff velocity is 150 m yr^{-1} rather than 100 m yr^{-1} as citet:mankoff_2019_ice.

*Note* that much of the text below is from citet:mankoff_2019_ice and is reproduced here either verbatim, or with minor changes to reflect minor changes in the work presented here.

**** Introduction

The mass of the Greenland ice sheet is decreasing (e.g. citet:fettweis_2017_reconstructions, citet:van-den-broeke_2017_greenland, citet:wiese_2016_jpl, and citet:khan_2016_geodetic). Most ice sheet mass loss -- as iceberg discharge, submarine melting, and meltwater runoff -- enters the fjords and coastal seas, and therefore ice sheet mass loss directly contributes to sea-level rise citep:wcrp_2018,moon_2018_rising,nerem_2018_climate,chen_2017_increasing. Greenland's total ice loss can be estimated through a variety of independent methods, for example 'direct' mass change estimates from GRACE citep:wiese_2016_jpl or by using satellite altimetry to estimate surface elevation change, which is then converted into mass change (using a firn model, e.g. citet:khan_2016_geodetic). However, partitioning the mass loss between ice discharge (D) and surface mass balance (SMB) remains challenging (c.f. citet:rignot_2008_mass and citet:enderlin_2014_improved). Correctly assessing mass loss, as well as the attribution of this loss (SMB or D) is critical to understanding the process-level response of the Greenland ice sheet to climate change, and thus improving models of future ice-sheet changes and associated sea-level rise citep:moon_2018_rising.

**** Review of scientific background

From citet:mankoff_2019_ice,

The total mass of an ice-sheet, or a drainage basin, changes if the mass gain (SMB inputs, primarily snowfall) is not balanced by the mass loss (D and SMB outputs, the latter generally meltwater runoff). This change is typically termed ice-sheet mass balance (MB) and the formal expression for this rate of change in mass is (e.g. citet:cuffey_2010_the-physics),

#+NAME: eq:dMdt
\begin{equation}
\frac{\mathrm{d}M}{\mathrm{d}t} = \rho \int_A b \, \mathrm{d}A - \int_g Q \, \mathrm{d}g,
\end{equation}

where \(\rho\) is the average density of ice, \(b\) is an area mass balance, and \(Q\) is the discharge flux. The left hand side of the equation is the rate of change of mass, the first term on the right hand side is the area \(A\) integrated surface mass balance (SMB), and the second term is the discharge \(D\) mass flow rate that drains through gate \(g\). Equation [[eq:dMdt]] is often simplified to

#+NAME: eq:MB
\begin{equation}
MB = SMB - D
\end{equation}

where \(MB\) is the mass balance, and referred to as the "input-output" method (e.g. citet:khan_2015_greenland). Virtually all studies agree on the trend of Greenland mass balance, but large discrepancies persist in both the magnitude and attribution. Magnitude discrepancies include, for example, citet:kjeldsen_2015_spatial reporting a mass imbalance of -250 \(\pm\) 21 Gt yr^{-1} during 2003 to 2010, citet:ewert_2012_volume reporting -181 \(\pm\) 28 Gt yr^{-1} during 2003 to 2008, and citet:rignot_2008_mass reporting a mass imbalance of -265 \(\pm\) 19 Gt yr^{-1} during 2004 to 2008. Some of these differences may be due to different ice sheet area masks used in the studies. Attribution discrepancies include, for example, citet:enderlin_2014_improved attributing the majority (64 %) of mass loss to changes in SMB during the 2005 to 2009 period but citet:rignot_2008_mass attributing the majority (85 %) of mass loss to changes in D during the 2004 to 2008 period.

Discharge may be calculated through several methods, including mass flow rate through gates (e.g. citet:enderlin_2014_improved, citet:king_2018_seasonal, and citet:mouginot_2019_forty), or solving as a residual from independent mass balance terms (e.g. citet:kjaer_2012_aerial,kjeldsen_2015_spatial). The gate method that we use in this study incorporates ice thickness and an estimated vertical profile from the observed surface velocity to calculate the discharge. A typical formulation of discharge across a gate \(D_g\) is,

#+NAME: eq:Q
\begin{equation}
D_g = \rho \, V \, H \, w,
\end{equation}

where \(\rho\) is the average density of ice, \(V\) is depth-average gate-perpendicular velocity, \(H\) is the ice thickness, and \(w\) is the gate width. Uncertainties in \(V\) and \(H\) naturally influence the estimated discharge. At fast-flowing outlet glaciers, \(V\) is typically assumed to be equal at all ice depths, and observed surface velocities can be directly translated into depth-averaged velocities (as in citet:enderlin_2014_improved, and citet:king_2018_seasonal). To minimize uncertainty from SMB or basal mass balance corrections downstream of a flux gate, the gate should be at the grounding line of the outlet glacier. Unfortunately, uncertainty in bed elevation (translating to ice thickness uncertainty) increases toward the grounding line. In order to minimize downstream SMB effects, we put gates as close as possible to the grounding line.

**** Algorithms
***** Terminology 

We use the following terminology:
+ "Pixels" are individual 200 m x 200 m raster discharge grid cells. We use the nearest neighbor when combining data sets that have different grid properties.
+ "Gates" are contiguous (including diagonal) clusters of pixels.
+ "Sectors" are spatial areas that have 0, 1, or > 1 gate(s) plus any upstream source of ice that flows through the gate(s), and come from citet:zwally_2012_sectors.
+ The "baseline" period is the average 2018 velocity from all available 2018 CCI IV data.
+ "Fast-flowing ice" is defined as ice that flows more than 150 m yr^{-1}.
+ Names are reported using the official Greenlandic names from citet:bjork_2015_brief if a nearby name exists, then citet:mouginot_2019_glacier in parentheses.

Although we refer to solid ice discharge, and it is in the solid phase when it passes the gates and eventually reaches the termini, submarine melting does occur at the termini and some of the discharge enters the fjord as liquid water citep:enderlin_2013_submarine.

***** Gate location

Gates are algorithmically generated for fast-flowing ice (greater than 150 m yr^{-1}) close to the ice sheet terminus determined by the baseline-period data. We apply a 2D inclusive mask to the baseline data for all ice flowing faster than 150 m yr^{-1}. We then select the mask edge where it is near the BedMachine ice mask (not including ice shelves), which effectively provides grounding line termini. We buffer the termini 10 km in all directions creating ovals around the termini and once again down-select to fast-flowing ice pixels. This procedure results in gates 10 km upstream from the baseline terminus that bisect the baseline fast-flowing ice. We manually mask some land- or lake-terminating glaciers which are initially selected by the algorithm due to fast flow and mask issues. 

We select a 150 m yr^{-1} speed cutoff because slower ice, taking longer to reach the terminus, is more influenced by SMB. The choice of a 10 km buffer follows from the fact that it is near-terminus and thus avoids the need for (minor) SMB corrections downstream, yet is not too close to the terminus where discharge results are sensitive to the choice of distance-to-terminus value citep:mankoff_2019_ice, which may be indicative of bed (ice thickness) errors.

***** Thickness

We derive thickness from the BedMachine surface and bed elevation. We adjust the surface through time by linearly interpolating the SEC product and adding it to the BedMachine surface, where the SEC product exists. Finally, from the fixed bed and temporally varying surface, we calculate the time-dependent ice thickness at each gate pixel.

***** Missing or invalid data

The baseline data provides velocity at all gate locations by definition, but individual non-baseline velocity maps often have missing or invalid data. Also, thickness provided by BedMachine is clearly incorrect in some places (e.g. fast-flowing ice that is 10 m thick, Fig. [[fig:h_v_histogram]]). We define invalid data and fill in missing data as described below.

****** Missing IV

We generate an ice speed time series by assigning the IV product to the middle of their reported time span. Velocities are sampled only where there are gate pixels. Missing pixel velocities are linearly interpolated in time, except for missing data at the beginning of the time series which are back- and forward-filled with the temporally-nearest value for that pixel. 

****** Missing SEC

Where SEC is missing, we use the provided BedMachine ice thickness.

****** Invalid thickness

The thickness data appear to be incorrect in some locations. For example, many locations have fast-flowing ice, but report ice thickness as 10 m or less. We accept all ice thickness greater than 20 m and construct from this a thickness versus log_{10} speed relationship. For all ice thickness less than or equal to 20 m thick we adjust thickness based this relationship. We selected the 20 m thickness cutoff after visually inspecting the velocity distribution. This thickness adjustment adds 20 Gt yr^{-1} to our baseline-period discharge estimate with no adjustment.

***** Discharge

We calculate discharge per pixel using density (917 kg m^{-3}), Filled ice velocity, projection-corrected pixel width, and adjusted ice thickness derived from time-varying surface elevation and a fixed bed elevation (Eq. [[eq:Q]]). We assume that any change in surface elevation corresponds to a change in ice thickness and thereby neglect basal uplift, erosion, and melt, which combined are orders of magnitude less than surface melting (e.g. citet:cowton_2012_rapid, citet:khan_2007_elastic). We also assume depth-averaged ice velocity is equal to the surface velocity.

We calculate discharge using the gate-orthogonal velocity at each pixel and at each timestamp -- all velocity estimates are gate-orthogonal at all times, regardless of gate position, orientation, or changing glacier velocity direction over time.

# Annual averages are calculated by linearly interpolating to daily, then estimating annual. The difference between this method and averaging only the observed samples is ~3 % median (5 % average, and a maximum of 10 % when examining the entire ice sheet and all years in our data). It is occasionally larger at individual glaciers when a year has few widely-space samples of highly variable velocity.

***** COMMENT Discharge Uncertainty
\label{sec:D_uncertainty}

Here we describe how we estimate the uncertainty related to the ice discharge following a simplistic approach. This yields an uncertainty of the total ice discharge of approximately 10 % throughout the time series. 

At each pixel we estimate the maximum discharge, \(D_{\mathrm{max}}\), from 

#+NAME: eq:D_err_max
\begin{equation}
D_{\mathrm{max}} = \rho \, (V + \sigma_V) \, (H + \sigma_H) \, W,
\end{equation}

and minimum discharge, \(D_{\mathrm{min}}\), from

#+NAME: eq:D_err_min
\begin{equation}
D_{\mathrm{min}} = \rho \, (V - \sigma_V) \, (H - \sigma_H) \, W,
\end{equation}

where \(\rho\) is ice density, \(V\) is baseline velocity, \(\sigma_V\) is baseline velocity error, \(H\) is ice thickness, \(\sigma_H\) is ice thickness error, and \(W\) is the width at each pixel. Included in the thickness term is surface elevation change through time (\(\mathrm{d}H/\mathrm{d}t\)). When data sets do not come with error estimates we treat the error as 0.

We use \(\rho = 917\) kg m^{-3} because the gates are near the terminus in the ablation zone and ice thickness estimates should not include snow or firn, although regionally ice density may be < 917 kg m^{-3} due to crevasses. We ignore the velocity error \(\sigma_V\) because the proportional thickness error (\(\sigma_H/H\)) is an order of magnitude larger than the proportional velocity error (\(\sigma_V/V\)) yet both contribute linearly to the discharge. \(W\) is location-dependent due to the errors between our working map projection (EPSG 3413) and a more accurate spheroid model of the earth surface. We adjust linear gate width by up to ~4% in the north and ~-2.5% in the south of Greenland (area errors are up to 8%). On a pixel by pixel basis we used the provided thickness uncertainty except where we modified the thickness (H < 20 m) we prescribe an uncertainty of 0.5 times the adjusted thickness. Subsequently, the uncertainty on individual glacier-, sector-, region-, or ice sheet scale is obtained by summing, but not reducing by the square of the sums, the uncertainty related to each pixel. We are conservative with our thickness error estimates, by assuming the uncertainty range is from \(D_{\mathrm{min}}\) to \(D_{\mathrm{max}}\) and not reducing by the sum-of-squares of sectors or regions. 

**** Input data and algorithm output
***** Input Data

The discharge gates in this study are generated using only surface speed and an ice mask. We use CCI ice velocity (IV) and the BedMachine v3 citep:morlighem_2017_bedmachine,NSIDC_BedMachine_GL ice mask, and BedMachine for initial ice thickness, supplemented with the SEC product from this project. Official glacier names come from citet:bjork_2015_brief. Other glacier names come from citet:mouginot_2019_glacier. 

#+LATEX_ATTR: :placement [!h]
#+CAPTION: Summary of data sources used in this work.
#+NAME: tab:data
| Property                 | Name used in this paper  | Reference                                           |
|--------------------------+--------------------------+-----------------------------------------------------|
| Basal Topography         | BedMachine               | citet:morlighem_2017_bedmachine,NSIDC_BedMachine_GL |
| Surface Elevation        | BedMachine               | citet:morlighem_2017_bedmachine,NSIDC_BedMachine_GL |
| Surface Elevation Change | Surface Elevation Change | CCI+ SEC                                            |
| Baseline Velocity        | Baseline                 | CCI+ IV 2018 average                                |
| Velocity                 | CCI IV                   | CCI+ IV                                             |
| Sectors & Regions        | Sectors & Regions        | citet:mouginot_2019_glacier                         |
| Names                    |                          | citet:bjork_2015_brief,mouginot_2019_glacier        |


***** Output

The output of the algorithm is a set of CSV files with time (quarterly) and discharge (by region from citet:zwally_2012_sectors). Table [[tab:output]] shows the algorithm output.


#+BEGIN_SRC python :session D_val_text :exports none :results raw drawer :eval no-export :kernel ice_discharge
import pandas as pd
import numpy as np

df = pd.read_csv("./MFID/MFID.csv", parse_dates=True, index_col=0)
df.index = df.index.astype(np.str) # drop "00:00:00" timestamp
df['Total'] = df.sum(axis='columns')
df
#+END_SRC

#+RESULTS:
|       Date |    1.1 |   1.2 |   1.3 |    2.1 |   2.2 |    3.1 |    3.2 |    3.3 |    4.1 |    4.2 |    4.3 |    5.0 |   6.1 |   6.2 |    7.1 |    7.2 |     8.1 |   8.2 |   Total |
|------------+--------+-------+-------+--------+-------+--------+--------+--------+--------+--------+--------+--------+-------+-------+--------+--------+---------+-------+---------|
| 2014-10-31 | 16.684 | 5.859 | 1.753 | 26.178 | 0.146 | 17.607 |  8.894 | 42.631 | 32.315 | 49.442 | 29.983 | 23.696 | 6.465 | 3.162 | 46.212 | 44.539 |   94.67 | 7.965 | 458.201 |
| 2014-11-30 |  16.68 | 5.859 | 1.753 | 26.171 | 0.146 | 17.608 |  8.894 | 42.631 | 32.315 | 49.443 | 29.983 | 23.696 | 6.464 | 3.162 | 46.131 | 44.433 |  94.731 | 7.964 | 458.064 |
| 2014-12-31 | 16.676 | 5.859 | 1.753 | 26.165 | 0.146 | 17.608 |  8.894 | 42.631 | 32.315 | 49.444 | 29.983 | 23.696 | 6.464 | 3.161 | 45.915 |  45.35 |   94.91 | 7.963 | 458.933 |
| 2015-01-31 | 16.673 | 5.859 | 1.753 | 26.158 | 0.146 | 17.608 |  8.895 | 42.631 | 32.315 | 49.444 | 29.982 | 23.695 | 6.464 | 3.167 | 45.829 | 45.852 |  95.098 | 7.962 | 459.531 |
| 2015-02-28 | 17.048 | 5.978 | 1.779 | 26.146 | 0.151 | 17.415 |  8.909 | 42.521 | 31.716 | 48.981 | 30.314 |  23.54 | 6.575 | 3.169 | 45.361 | 45.802 |  94.773 | 7.987 | 458.165 |
| 2015-03-31 | 16.951 | 6.033 | 1.864 |  26.43 | 0.145 | 17.819 |  9.085 | 43.032 | 32.866 | 49.624 |  31.75 |  24.12 | 6.821 | 3.383 | 45.375 | 45.705 |  95.265 | 7.946 | 464.214 |
| 2015-04-30 | 16.843 | 6.094 | 1.834 | 26.744 | 0.138 | 18.265 |   9.28 | 43.597 | 34.139 | 50.337 |  33.34 | 24.761 | 7.093 | 3.614 | 45.412 | 45.867 |  96.251 | 7.901 |  471.51 |
| 2015-05-31 | 16.739 | 6.153 | 1.806 | 27.048 | 0.132 | 18.698 |  9.469 | 44.144 | 35.371 | 51.026 | 34.878 | 25.382 | 7.357 | 3.842 | 45.885 | 47.328 |  98.097 | 7.858 | 481.213 |
| 2015-06-30 | 17.584 | 6.533 | 1.777 | 27.362 | 0.167 | 19.144 |  9.665 | 43.293 | 34.834 | 50.898 | 35.216 | 24.968 | 7.359 | 3.896 | 45.697 | 48.222 |  99.342 | 8.584 | 484.541 |
| 2015-07-31 | 19.069 | 7.306 | 1.748 | 28.401 |   0.2 | 18.415 |  9.514 | 43.164 | 33.753 | 50.992 | 34.302 |  24.28 | 7.145 |  3.43 | 46.131 | 45.221 |  94.813 | 8.467 | 476.351 |
| 2015-08-31 |  16.72 | 5.555 | 1.424 | 26.282 | 0.156 | 17.538 |  8.498 | 42.575 | 33.934 | 51.209 |  34.33 | 24.319 | 7.292 | 3.548 | 46.316 | 46.009 |  93.654 |  7.26 | 466.619 |
| 2015-09-30 | 16.272 | 5.649 | 1.042 | 25.581 | 0.151 | 17.619 |  8.596 | 42.925 | 33.935 | 50.457 | 33.522 | 23.519 | 7.009 | 3.298 | 46.124 | 46.668 |  94.184 | 7.389 |  463.94 |
| 2015-10-31 | 16.153 | 5.789 | 1.194 | 25.465 | 0.148 | 17.933 |  8.772 | 42.975 | 33.951 | 48.368 | 32.645 | 22.576 | 7.075 | 3.012 | 45.793 | 47.026 |  93.957 | 7.598 |  460.43 |
| 2015-11-30 | 16.258 | 5.807 |  1.26 | 25.602 | 0.149 |     18 |  8.867 | 42.605 |  34.03 | 47.484 | 32.778 |  23.08 | 7.109 | 3.216 | 45.682 | 47.899 |  97.402 | 7.686 | 464.914 |
| 2015-12-31 | 16.442 | 5.829 | 1.247 | 25.802 | 0.152 | 17.672 |  9.028 | 41.252 | 33.206 | 47.147 | 29.953 | 23.081 | 7.143 | 3.249 |  45.47 | 47.981 |  97.315 | 7.751 |  459.72 |
| 2016-01-31 | 16.532 | 5.821 | 1.278 | 26.126 | 0.152 | 17.757 |  8.987 | 41.419 | 32.663 | 46.527 | 29.176 | 22.797 | 6.972 | 3.111 | 45.553 | 48.188 |  97.519 | 7.845 | 458.423 |
| 2016-02-29 | 16.738 | 5.928 | 1.283 | 26.448 | 0.151 | 17.918 |  8.979 | 41.447 | 32.231 | 46.334 | 28.915 | 23.022 | 7.014 | 3.107 | 44.978 | 46.824 |  97.972 | 7.789 | 457.078 |
| 2016-03-31 | 16.662 | 5.937 |  1.26 | 26.505 | 0.151 | 17.906 |  9.017 | 41.554 | 32.519 | 46.399 | 28.637 | 22.805 | 6.935 | 3.159 | 44.774 | 46.514 |  98.086 | 7.847 | 456.667 |
| 2016-04-30 | 16.811 | 6.003 | 1.316 | 26.435 | 0.153 | 18.063 |  9.107 | 42.724 | 33.181 | 46.997 | 30.372 | 23.788 |  7.12 | 3.338 | 46.236 | 49.205 | 101.686 | 7.783 | 470.318 |
| 2016-05-31 |  17.06 | 6.032 | 1.313 | 26.587 | 0.152 | 18.559 |  9.152 | 43.106 | 33.518 | 48.124 | 33.281 | 24.604 | 7.395 | 3.702 | 45.897 | 49.225 | 100.546 | 8.063 | 476.316 |
| 2016-06-30 | 18.076 | 6.513 | 1.547 | 27.084 | 0.172 | 18.825 |  9.418 | 43.257 |   33.5 | 48.598 | 33.891 | 24.728 | 7.224 | 3.633 | 46.557 |  49.96 | 100.979 |  8.33 | 482.292 |
| 2016-07-31 | 20.748 | 6.895 | 1.759 | 28.584 | 0.206 | 18.369 |  8.583 |  41.77 |  33.41 |  50.64 | 34.783 | 24.043 | 6.507 | 2.969 | 46.834 |  46.51 | 103.224 | 8.319 | 484.153 |
| 2016-08-31 | 18.397 | 5.572 | 1.252 | 27.341 | 0.148 |  17.85 |  8.068 | 41.415 | 33.393 | 50.966 | 34.389 | 23.768 | 5.976 | 2.586 | 45.991 | 45.224 |  98.794 |  7.42 |  468.55 |
| 2016-09-30 | 17.178 | 5.834 | 1.153 | 26.192 | 0.139 | 17.879 |   8.17 | 41.718 | 34.818 | 49.484 | 34.481 |   23.4 | 6.014 | 2.656 | 45.482 | 45.158 |  96.119 | 7.637 | 463.512 |
| 2016-10-31 | 17.315 | 5.871 | 1.157 | 26.029 | 0.141 | 18.314 |  8.547 | 42.747 | 36.142 | 49.681 | 35.327 | 24.315 | 6.374 | 2.916 | 46.707 | 46.669 | 100.504 | 7.965 | 476.721 |
| 2016-11-30 | 17.479 | 5.945 | 1.144 | 26.315 | 0.147 | 18.404 |  8.675 | 42.557 | 36.464 | 49.793 |  35.67 | 24.944 | 6.302 | 2.955 |  44.18 | 46.815 | 101.658 |  7.95 | 477.397 |
| 2016-12-31 | 17.539 | 5.921 | 1.145 | 26.531 | 0.148 | 18.234 |   8.81 |  43.94 | 36.138 | 50.196 | 35.113 | 24.938 |  6.47 | 3.194 | 41.257 | 47.719 | 102.007 | 8.192 | 477.492 |
| 2017-01-31 | 17.598 | 5.948 | 1.147 |  26.47 |  0.15 | 17.867 |  8.906 | 44.214 | 34.603 | 48.553 | 33.087 |  25.52 | 6.521 | 3.222 | 37.007 | 47.284 | 101.044 | 8.267 | 467.408 |
| 2017-02-28 |  17.73 | 6.014 | 1.169 | 26.617 | 0.148 | 18.496 |  8.919 | 45.018 | 34.483 |  50.23 | 35.075 | 25.867 | 6.498 |  3.12 | 33.712 | 46.502 | 101.259 |  8.27 | 469.127 |
| 2017-03-31 | 17.789 | 6.096 | 1.163 | 26.751 |  0.15 | 18.484 |  9.173 | 45.766 | 34.776 | 49.605 | 34.831 |  25.85 | 6.672 | 3.229 | 36.631 | 48.387 | 101.589 | 8.195 | 475.137 |
| 2017-04-30 | 17.856 | 6.127 | 1.185 | 26.974 | 0.151 | 18.378 |  9.186 | 45.951 | 36.785 | 49.737 | 34.832 | 26.182 | 6.676 |  3.27 | 36.721 | 48.948 | 103.357 | 8.381 | 480.697 |
| 2017-05-31 | 18.204 | 6.162 | 1.199 | 26.974 | 0.147 | 18.806 |  9.466 | 47.462 | 39.126 | 52.173 | 38.146 | 27.237 |   7.1 | 3.577 | 38.007 | 49.425 | 105.512 | 8.436 | 497.159 |
| 2017-06-30 | 18.374 | 6.226 | 1.737 | 28.006 | 0.171 | 19.365 |  9.994 | 47.214 | 39.908 | 52.266 |  37.76 | 26.907 |  7.38 | 3.754 | 38.139 | 49.812 | 103.642 | 8.641 | 499.296 |
| 2017-07-31 | 20.656 | 7.024 | 2.416 | 30.017 | 0.216 | 19.075 |   9.62 |  47.57 | 39.555 | 53.175 | 38.171 | 27.375 | 7.137 |   3.6 | 40.062 | 48.525 | 108.064 | 8.867 | 511.125 |
| 2017-08-31 | 19.387 | 6.411 | 1.609 | 28.476 | 0.151 | 18.368 |  8.825 | 46.554 |   40.2 | 52.609 | 37.991 | 26.183 | 6.853 | 2.961 | 39.556 |  45.35 | 105.933 | 7.754 | 495.171 |
| 2017-09-30 | 17.759 | 6.107 | 1.374 | 27.436 | 0.148 | 18.296 |  8.938 | 46.745 | 40.122 | 51.762 |  37.47 | 25.122 | 6.688 | 3.038 | 39.781 | 46.169 | 100.308 | 7.746 | 485.009 |
| 2017-10-31 | 17.755 | 6.334 | 1.425 | 27.617 | 0.148 | 18.585 |  8.803 | 46.393 | 39.498 | 51.548 | 37.994 | 25.074 | 6.721 | 3.111 | 38.109 | 46.157 | 103.355 |  8.03 | 486.657 |
| 2017-11-30 | 17.867 | 6.342 | 1.373 | 27.604 | 0.149 | 18.651 |  9.042 | 46.709 | 38.439 | 51.178 | 37.062 |  24.65 | 6.921 | 3.225 | 36.858 | 46.625 | 105.217 | 8.248 |  486.16 |
| 2017-12-31 | 18.068 | 6.353 |  1.38 | 27.736 |  0.15 | 18.556 |   9.25 | 46.673 | 37.517 | 51.447 |  35.94 | 25.179 | 6.962 | 3.335 | 35.009 | 46.783 | 104.957 | 8.358 | 483.653 |
| 2018-01-31 | 18.188 | 6.352 |  1.42 |  27.62 |  0.15 | 18.547 |  9.235 | 47.296 | 35.192 | 50.471 | 33.143 | 25.259 | 7.026 | 3.406 | 33.665 |  46.74 | 103.274 | 8.541 | 475.525 |
| 2018-02-28 | 18.244 | 6.303 | 1.415 | 27.673 | 0.152 |  18.62 |  9.421 | 47.206 | 35.329 | 50.476 | 33.514 | 25.813 | 7.041 | 3.379 | 31.998 | 46.512 | 103.801 | 8.594 | 475.491 |
| 2018-03-31 | 18.356 | 6.345 | 1.434 | 27.834 | 0.153 | 18.661 |  9.544 | 47.258 | 36.947 | 51.345 | 35.153 | 25.642 |  6.96 | 3.329 | 31.664 |  46.47 | 103.835 | 8.666 | 479.596 |
| 2018-04-30 |  18.38 | 6.403 |  1.44 | 27.713 | 0.153 | 18.572 |  9.527 | 48.222 | 36.918 | 50.781 | 35.633 | 26.101 | 6.971 | 3.411 | 31.736 | 46.541 | 104.278 | 8.631 | 481.411 |
| 2018-05-31 | 18.715 | 6.397 | 1.476 | 28.364 | 0.153 | 18.747 |  9.534 | 49.341 | 38.185 | 51.042 | 36.984 | 26.577 | 7.004 | 3.444 | 32.348 |  46.75 |  106.23 | 8.739 |  490.03 |
| 2018-06-30 | 18.858 | 6.431 |  1.59 | 28.282 | 0.156 | 19.041 |  9.927 | 49.024 | 38.547 |  52.88 | 38.941 | 27.405 | 7.429 | 3.827 | 33.634 | 48.184 | 105.048 | 8.963 | 498.167 |
| 2018-07-31 | 20.811 | 7.017 | 2.545 | 29.071 | 0.193 | 18.817 | 10.203 |  49.08 | 38.193 | 53.302 | 38.714 |   27.5 | 7.254 | 3.649 | 33.154 | 46.756 | 106.456 | 9.209 | 501.924 |
| 2018-08-31 | 20.065 | 6.815 | 2.532 | 28.454 | 0.186 | 18.244 |  9.094 | 47.449 | 37.815 | 53.466 |  37.41 | 25.627 | 6.183 | 3.106 | 35.678 | 44.973 | 105.265 | 8.692 | 491.054 |
| 2018-09-30 | 18.646 | 6.413 | 2.076 | 28.159 | 0.165 |  18.31 |  8.659 | 46.625 | 37.929 | 52.266 | 36.507 | 25.197 | 6.064 | 3.128 | 36.304 | 45.009 | 100.754 | 8.703 | 480.914 |
| 2018-10-31 |  18.67 | 6.448 | 2.116 | 28.028 | 0.179 | 18.579 |  8.957 | 46.663 | 35.962 | 51.499 | 36.637 | 25.181 | 6.402 | 3.178 | 34.213 | 45.483 | 103.089 | 8.919 | 480.203 |
| 2018-11-30 | 18.622 | 6.529 | 2.089 | 28.091 | 0.167 |  18.74 |  9.355 | 47.399 | 37.313 | 51.969 | 36.794 | 25.197 | 6.481 | 3.155 | 33.189 |  45.64 | 102.847 | 8.864 | 482.441 |
| 2018-12-31 | 18.768 | 6.498 | 2.168 | 28.302 | 0.165 | 18.803 |  9.234 |  48.16 |  36.48 | 50.847 |  34.19 |  25.58 | 6.582 |  3.34 | 32.267 | 46.066 | 102.318 | 8.717 | 478.485 |
| 2019-01-31 | 18.783 | 6.481 |  2.19 | 28.154 | 0.165 |  18.72 |  9.338 | 47.898 | 36.235 | 50.835 | 33.061 | 25.682 | 6.732 | 3.499 | 32.089 |  46.04 | 102.176 | 8.969 | 477.047 |
| 2019-02-28 | 18.828 | 6.548 | 2.208 | 28.084 | 0.164 | 18.787 |  9.428 | 47.191 | 37.158 | 52.763 | 35.486 | 25.987 | 6.707 | 3.164 | 31.302 | 45.968 | 102.732 | 9.043 | 481.548 |
| 2019-03-31 | 18.908 | 6.542 | 2.245 | 28.154 | 0.166 | 18.795 |  9.522 | 46.701 | 38.335 | 53.132 | 36.068 | 26.208 | 6.742 | 3.276 | 30.245 | 45.965 | 102.418 | 9.025 | 482.447 |
| 2019-04-30 | 18.959 | 6.493 | 2.328 | 28.067 | 0.166 | 18.821 |  9.387 | 48.323 | 40.307 | 52.971 | 37.034 | 26.707 | 6.787 | 3.445 |  31.39 | 45.969 | 105.079 | 8.882 | 491.115 |
| 2019-05-31 | 19.095 | 6.521 |  2.37 | 28.051 | 0.159 | 18.956 |  9.542 | 47.481 | 40.479 | 53.811 |  38.75 | 27.727 | 7.243 | 3.815 | 33.554 | 46.906 | 103.968 | 9.075 | 497.503 |
| 2019-06-30 | 20.692 | 7.169 | 2.966 | 29.067 | 0.211 |  19.33 | 10.165 | 47.636 | 41.718 | 53.963 | 40.034 | 28.711 | 7.676 | 3.754 | 37.964 |  47.13 | 105.358 | 9.583 | 513.127 |
| 2019-07-31 | 22.091 | 6.445 | 3.089 | 30.276 | 0.203 | 18.372 |  9.106 | 46.803 | 41.784 | 54.101 | 39.096 | 27.069 | 7.161 | 3.418 | 39.584 | 46.485 | 102.269 | 8.467 | 505.819 |

**** Accuracy and performance
***** Accuracy

The algorithm and data product introduced here are closely related to the algorithm and data product introduced by citet:mankoff_2019_ice.  When comparing annual average over all of Greenland, the this product and the product released by citet:mankoff_2019_ice agree well. 

#+NAME: D_compare_ann
#+BEGIN_SRC python :session D_val_text :exports results :results raw drawer :eval no-export :kernel ice_discharge
this = pd.read_csv('./MFID/MFID.csv', index_col=0, parse_dates=True)
this_err = pd.read_csv('./MFID/MFID_err.csv', index_col=0, parse_dates=True)

D = pd.DataFrame(index = this.index)
D['this'] = this.sum(axis='columns')
D['this_err'] = this_err.sum(axis='columns')
D.resample("AS").mean()

# root = "/home/kdm/data/Mankoff_2019/d/version_01/"
root = "/home/kdm/projects/ice_discharge/out/"
m2019 = pd.read_csv(root+'region_D.csv', index_col=0, parse_dates=True)\
          .resample("M")\
          .mean()\
          .sum(axis='columns')
m2019_err = pd.read_csv(root+'region_err.csv', index_col=0, parse_dates=True)\
              .resample("M")\
              .mean()\
              .sum(axis='columns')
m2019.name = "m2019"
m2019_err.name = "m2019_err"

D = D.merge(m2019, left_index=True, right_index=True)
D = D.merge(m2019_err, left_index=True, right_index=True)

D['diff'] = D['this'] - D['m2019']
D['diff %'] = D['diff'] / D['this'] * 100

D.index = D.index.astype(np.str)
D
#+END_SRC

#+CAPTION: Comparison between this product ("this") and citet:mankoff_2019_ice ("m2019")
#+RESULTS: D_compare_ann
|       Date |    this | this_err |   m2019 | m2019_err |     diff |    diff % |
|------------+---------+----------+---------+-----------+----------+-----------|
| 2014-10-31 | 458.201 |   41.714 | 493.947 |    50.835 |  -35.746 |  -7.80138 |
| 2014-11-30 | 458.064 |   41.684 | 499.001 |    51.361 |  -40.937 |  -8.93696 |
| 2014-12-31 | 458.933 |   41.739 | 499.686 |   51.4215 |  -40.753 |  -8.87995 |
| 2015-01-31 | 459.531 |   41.785 | 498.548 |   51.1195 | -39.0165 |   -8.4905 |
| 2015-02-28 | 458.165 |   41.595 | 498.392 |    50.959 | -40.2265 |  -8.77992 |
| 2015-03-31 | 464.214 |   42.119 | 500.767 |    51.545 |  -36.553 |  -7.87417 |
| 2015-04-30 |  471.51 |   42.758 |       0 |         0 |   471.51 |       100 |
| 2015-05-31 | 481.213 |   43.613 |  498.79 |    51.057 |  -17.577 |  -3.65264 |
| 2015-06-30 | 484.541 |   43.863 |       0 |         0 |  484.541 |       100 |
| 2015-07-31 | 476.351 |   42.776 | 515.999 |   52.9005 | -39.6485 |  -8.32338 |
| 2015-08-31 | 466.619 |    42.14 | 498.024 |   50.9895 | -31.4055 |  -6.73044 |
| 2015-09-30 |  463.94 |   41.987 | 500.495 |    51.367 |  -36.555 |  -7.87925 |
| 2015-10-31 |  460.43 |   41.725 | 498.883 |   51.1755 | -38.4535 |  -8.35165 |
| 2015-11-30 | 464.914 |   42.103 |       0 |         0 |  464.914 |       100 |
| 2015-12-31 |  459.72 |    41.69 | 499.037 |    51.197 |  -39.317 |  -8.55238 |
| 2016-01-31 | 458.423 |   41.547 | 493.502 |   50.6585 |  -35.079 |   -7.6521 |
| 2016-02-29 | 457.078 |   41.436 |       0 |         0 |  457.078 |       100 |
| 2016-03-31 | 456.667 |   41.487 | 492.947 |    50.691 |   -36.28 |  -7.94452 |
| 2016-04-30 | 470.318 |   42.652 |       0 |         0 |  470.318 |       100 |
| 2016-05-31 | 476.316 |   43.147 | 498.546 |    51.527 |   -22.23 |  -4.66707 |
| 2016-06-30 | 482.292 |   43.864 |       0 |         0 |  482.292 |       100 |
| 2016-07-31 | 484.153 |   43.746 | 504.007 |    51.724 | -19.8545 |  -4.10087 |
| 2016-08-31 |  468.55 |    42.54 | 493.635 |   50.6935 | -25.0855 |  -5.35386 |
| 2016-09-30 | 463.512 |    42.22 | 495.268 |    50.779 |  -31.756 |  -6.85117 |
| 2016-10-31 | 476.721 |    43.55 | 495.857 |   50.8837 | -19.1362 |  -4.01412 |
| 2016-11-30 | 477.397 |   43.765 | 497.649 |    50.985 | -20.2517 |   -4.2421 |
| 2016-12-31 | 477.492 |   43.789 | 497.671 |   50.9589 | -20.1786 |  -4.22595 |
| 2017-01-31 | 467.408 |   43.152 | 500.478 |   51.1046 | -33.0698 |  -7.07515 |
| 2017-02-28 | 469.127 |   43.734 | 500.683 |   51.1568 | -31.5556 |  -6.72645 |
| 2017-03-31 | 475.137 |   44.192 | 500.946 |   51.1526 | -25.8091 |  -5.43194 |
| 2017-04-30 | 480.697 |   44.753 | 507.796 |   52.3664 |  -27.099 |  -5.63744 |
| 2017-05-31 | 497.159 |   46.091 | 508.157 |    52.198 | -10.9977 |  -2.21211 |
| 2017-06-30 | 499.296 |   46.247 | 507.599 |   51.4868 |   -8.303 |  -1.66294 |
| 2017-07-31 | 511.125 |    47.02 | 516.857 |    52.238 |  -5.7322 |  -1.12149 |
| 2017-08-31 | 495.171 |   45.175 |  507.64 |   51.0631 | -12.4689 |  -2.51809 |
| 2017-09-30 | 485.009 |   44.618 | 503.394 |   50.9327 | -18.3853 |  -3.79072 |
| 2017-10-31 | 486.657 |   44.754 | 506.185 |   51.4474 | -19.5276 |  -4.01261 |
| 2017-11-30 |  486.16 |   44.813 | 500.558 |    50.628 | -14.3983 |  -2.96163 |
| 2017-12-31 | 483.653 |   44.649 | 501.124 |   50.7968 | -17.4707 |  -3.61225 |
| 2018-01-31 | 475.525 |   43.983 | 501.139 |    51.101 |  -25.614 |  -5.38647 |
| 2018-02-28 | 475.491 |   43.971 | 499.779 |   50.9015 | -24.2877 |  -5.10793 |
| 2018-03-31 | 479.596 |   44.512 | 497.692 |   50.5494 |  -18.096 |  -3.77318 |
| 2018-04-30 | 481.411 |   44.726 | 495.004 |   50.1655 | -13.5925 |  -2.82347 |
| 2018-05-31 |  490.03 |   45.563 | 501.054 |   51.0822 |  -11.024 |  -2.24966 |
| 2018-06-30 | 498.167 |   46.298 | 496.822 |   50.7725 |    1.345 |   0.26999 |
| 2018-07-31 | 501.924 |   46.577 | 500.902 |   50.9227 |  1.02167 |   0.20355 |
| 2018-08-31 | 491.054 |   44.961 | 497.571 |    50.385 |  -6.5175 |  -1.32725 |
| 2018-09-30 | 480.914 |    44.18 | 487.941 |   49.4873 |   -7.027 |  -1.46118 |
| 2018-10-31 | 480.203 |   44.399 | 499.935 |    51.104 | -19.7322 |  -4.10915 |
| 2018-11-30 | 482.441 |   44.774 | 498.129 |    50.659 |  -15.688 |   -3.2518 |
| 2018-12-31 | 478.485 |   44.463 | 496.089 |    50.685 | -17.6043 |  -3.67916 |
| 2019-01-31 | 477.047 |    44.43 |  498.34 |    51.198 |  -21.293 |   -4.4635 |
| 2019-02-28 | 481.548 |   44.936 | 497.903 |    51.034 | -16.3545 |  -3.39623 |
| 2019-03-31 | 482.447 |   45.126 | 495.642 |   50.5323 | -13.1953 |  -2.73508 |
| 2019-04-30 | 491.115 |   45.852 | 499.428 |   51.1327 |   -8.313 |  -1.69268 |
| 2019-05-31 | 497.503 |   46.409 | 502.146 |    51.749 |   -4.643 | -0.933261 |
| 2019-06-30 | 513.127 |   48.037 | 507.756 |    52.096 |  5.37067 |   1.04665 |
| 2019-07-31 | 505.819 |   46.779 |  505.35 |    51.441 |    0.469 | 0.0927209 |

Comparing by regions is difficult because this product is binned on the citet:zwally_2012_sectors and citet:mankoff_2019_ice is on the citet:mouginot_2019_glacier regions and sectors.

***** Performance

The code takes ~1 hour to run after the input data products have been downloaded and placed in the necessary location. Downloading input data and installing all required software is not automated, but once those dependencies are met, the algorithm is publicly available.

Repeated runs make some use of the static computational results of earlier runs, and take less time to calculate discharge for updated velocity products.

If surface elevation change or thickness products change, a full re-run is required.

**** Capabilities and known limitations

We note the following major limitations to the current implementation.

+ Discharge is only calculated where gates are placed. This means discharge less than the cutoff velocity is not considered, and that if a glacier does not currently have a gate surges in the future, that surge will not be captured in the discharge unless the gates are recalculated.

+ We use relatively raw products as-provided from 3rd parties. We do not apply smoothing filters to the velocity product, and only adjust the thickness product where it is clearly incorrect (fast-flowing ice < 20 m thick).

+ There is only partial treatment of surface elevation change, because the CCI SEC product does not provide data near the coast.

**** References

\printbibliography[heading=none]


** E3UB                                                 :noexport:
:PROPERTIES:
:EXPORT_FILE_NAME: E3UB_kdm
:END:

*** End-to-end Uncertainty Budget for MFID

Note that much of the text below is from citet:mankoff_2019_ice and is reproduced here either verbatim, or with minor changes to reflect minor changes in the work presented here.

**** COMMENT Introduction

Traditional and mathematically valid uncertainty treatments divide errors into two classes: systematic (bias) and random. The primary distinction is that systematic errors do not decrease with more samples, and random errors decrease as the number of samples or measurements increases. The question is then which errors are systematic and which are random. A common treatment is to decide that errors within a region of Greenland are systematic, and among regions are random. This approach has no physical basis - two glaciers a few 100 m apart but in different regions are assumed to have random errors, but two glaciers 1000s of km apart but within the same region are assumed to have systematic errors. It is more likely the case that all glaciers less wide than some width or more deep than some depth have systematic errors even if they are on opposite sides of the ice sheet, if ice thickness is estimated with the same method (i.e. the systematic error is likely caused by the sensor and airplane, not the location of the glacier).

The decision to have \(R\) random samples (where \(R\) is the number of regions, usually ~18 based on citet:zwally_2012_sectors) is also arbitrary. Mathematical treatment of random errors means that even if the error is 50 %, 18 measurements reduces it to only 11.79 %.

**** Sources of error

Error sources include the following:

+ Ice thickness
+ Change in ice thickness
+ Velocity
+ Errors due to map projection warping
+ Human error and software bugs

**** Methodology for determination of error and uncertainty

We determine error by using the upstream error provided by the input data products, considering the relative scale of those errors on the final product, considering whether or not errors are random or systematic, and whether or not our variables are truly independent.

**** Error and uncertainty documentation
***** Thickness

Thickness uncertainty is provided by the BedMachine data set citep:morlighem_2017_bedmachine,NSIDC_BedMachine_GL.

***** Velocity

Velocity standard deviation is provided by the CCI IV product

***** Discharge

Discharge is the combination of thickness and velocity. We assume ice thicknesses < 20 m are incorrect where ice speed is > 100 m yr^{-1}. We adjust these thickness using a poor fit (correlation coefficient: 0.3) of the log$_{10}$ of the ice speed to thickness where the relationship is known (thickness > 20 m). We set errors equal to one half the thickness (i.e. \(\sigma_H = \pm 0.5 \, H\)). We also test the sensitivity of this treatment to simpler treatments, and have the following five categories:

Here we describe how we estimate the uncertainty related to the ice discharge following a simplistic approach. This yields an uncertainty of the total ice discharge of approximately 10 % throughout the time series. 

At each pixel we estimate the maximum discharge, \(D_{\mathrm{max}}\), from 

#+NAME: eq:D_err_max
\begin{equation}
D_{\mathrm{max}} = \rho \, (V + \sigma_V) \, (H + \sigma_H) \, W,
\end{equation}

and minimum discharge, \(D_{\mathrm{min}}\), from

#+NAME: eq:D_err_min
\begin{equation}
D_{\mathrm{min}} = \rho \, (V - \sigma_V) \, (H - \sigma_H) \, W,
\end{equation}

where \(\rho\) is ice density, \(V\) is baseline velocity, \(\sigma_V\) is baseline velocity error, \(H\) is ice thickness, \(\sigma_H\) is ice thickness error, and \(W\) is the width at each pixel.

We use \(\rho = 917\) kg m^{-3} because the gates are near the terminus in the ablation zone and ice thickness estimates should not include snow or firn, although regionally ice density may be < 917 kg m^{-3} due to crevasses. We ignore the velocity error \(\sigma_V\) because the proportional thickness error (\(\sigma_H/H\)) is an order of magnitude larger than the proportional velocity error (\(\sigma_V/V\)) yet both contribute linearly to the discharge. \(W\) is location-dependent due to the errors between our working map projection (EPSG 3413) and a more accurate spheroid model of the earth surface. We adjust linear gate width by up to ~4% in the north and ~-2.5% in the south of Greenland (area errors are up to 8%). On a pixel by pixel basis we used the provided thickness uncertainty except where we modified the thickness (H < 20 m) we prescribe an uncertainty of 0.5 times the adjusted thickness. Subsequently, the uncertainty on individual glacier-, sector-, region-, or ice sheet scale is obtained by summing, but not reducing by the square of the sums, the uncertainty related to each pixel. We are conservative with our thickness error estimates, by assuming the uncertainty range is from \(D_{\mathrm{min}}\) to \(D_{\mathrm{max}}\) and not reducing by the sum-of-squares of sectors or regions. 

***** Map projection
#+LaTeX: \label{sec:uncertain_map}

Our work takes place in a projected coordinate system (EPSG 3413) and therefore errors are introduced between the "true" earth spheroid (which is itself an approximation) and our projected coordinates system. We address these by calculating the projection error due to EPSG 3413 which is approximately +8 % in Northern Greenland and -6 % in Southern Greenland, and multiplying variables by a scaling factor if the variables do not already take this into account. Velocities are not scaled, but the gate width is scaled.

**** Guideline for using the product

The primary source of uncertainty is the ice thickness uncertainty, and that is systematic and fixed in time. Therefore, aggregating discharge spatially or temporally will not reduce that uncertainty. Even so, other sources of errors which are random do exist and will be reduced when aggregating results over large areas or times. We therefore suggest using GIS-wide discharge or regional discharge, and using caution if examining individual glaciers. Similarly, annual or monthly averaged or summed results will have a higher signal-to-noise ratio than individual time steps.

**** References

\printbibliography[heading=none]

** SSD
:PROPERTIES:
:EXPORT_FILE_NAME: SSD_kdm
:END:

*** Mass Flow Rate and Ice Discharge (MFID)
**** System overview

The flow rate and ice discharge algorithms have two primary steps
+ Calculation of discharge gate locations.
+ Calculation of discharge through the gates.

Gate locations are calculated once using a baseline velocity product and then remain fixed in space and time. Discharge is then calculated for each and every time when a velocity map exists.

Note - some of the text below comes from citet:mankoff_2019_ice where this algorithm was first described.

Gates are algorithmically generated for fast-flowing ice (greater than 150 m yr^{-1}) close to the ice sheet terminus determined by the baseline-period data. We apply a 2D inclusive mask to the baseline data for all ice flowing faster than 150 m yr^{-1}. We then select the mask edge where it is near the BedMachine ice mask (not including ice shelves), which effectively provides grounding line termini. We buffer the termini 10 km in all directions creating ovals around the termini and once again down-select to fast-flowing ice pixels. This procedure results in gates 10 km upstream from the baseline terminus that bisect the baseline fast-flowing ice. We manually mask some land- or lake-terminating glaciers which are initially selected by the algorithm due to fast flow and mask issues. 

We select a 150 m yr^{-1} speed cutoff because slower ice, taking longer to reach the terminus, is more influenced by SMB. The choice of a 10 km buffer follows from the fact that it is near-terminus and thus avoids the need for (minor) SMB corrections downstream, yet is not too close to the terminus where discharge results are sensitive to the choice of distance-to-terminus value citep:mankoff_2019_ice, which may be indicative of bed (ice thickness) errors.

Discharge is calculated at each gate by multiplying the provided velocity by the thickness of the ice at the gate location. 

**** Operational scenarios

The operational scenario for this product is to generate an estimate of total Greenland ice discharge for every timestep when any velocity product exits. If a velocity product does not cover all gates or all portions of all gates, velocity is linearly interpolated from the surrounding times, or forward- or backward-filled for the last and first time, respectively.

***** Hardware

The development environment is a common laptop. It currently has 32 GB of RAM and 5 TB of internal storage, but can be run on a significantly smaller system. We suggest at least 8 GB of RAM and 1 TB of storage.

***** Operating system

We use the Linux operating system, specifically src_bash{lsb_release -d | cut -d":" -f2| head -n1} {{{results(=Ubuntu 18.04.3 LTS=)}}}, with the following CPU and architecture:

#+BEGIN_SRC bash :results verbatim :exports results
lscpu | grep -v Flags
#+END_SRC

#+RESULTS:
#+begin_example
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
CPU(s):              8
On-line CPU(s) list: 0-7
Thread(s) per core:  2
Core(s) per socket:  4
Socket(s):           1
NUMA node(s):        1
Vendor ID:           GenuineIntel
CPU family:          6
Model:               142
Model name:          Intel(R) Core(TM) i7-8650U CPU @ 1.90GHz
Stepping:            10
CPU MHz:             758.158
CPU max MHz:         4200.0000
CPU min MHz:         400.0000
BogoMIPS:            4224.00
Virtualization:      VT-x
L1d cache:           32K
L1i cache:           32K
L2 cache:            256K
L3 cache:            8192K
NUMA node0 CPU(s):   0-7
#+end_example

***** Tools and libraries
:PROPERTIES:
:header-args:bash+: :exports results
:header-args:elisp+: :exports results
:END:


We use the following tools for this workflow:

This work was performed using only open-source software, primarily =GRASS GIS= citep:neteler_2012_GRASS and =Python= citep:van-rossum_1995_python, in particular the =Jupyter= citep:kluyver_2016_jupyter, =pandas= citep:mckinney_2010_pandas, =numpy= citep:oliphant_2006_numpy, =statsmodel= citep:seabold_2010_statsmodels, =x-array= citep:hoyer_2017_xarray, and =Matplotlib= citep:hunter_2007_matplotlib packages. The entire work was performed in =Emacs= citep:stallman_1981_emacs using =Org Mode= citep:schulte_2012_a-multi-language. The =parallel= citep:tange_2011_parallel tool was used to speed up processing. We used =proj4= citep:proj4 to compute the errors in the EPSG 3413 projection. All code used in this work is available in the Supplemental Material.

****** Emacs
#+BEGIN_SRC elisp :eval no-export
(emacs-version)
#+END_SRC

#+RESULTS:
: GNU Emacs 26.3 (build 2, x86_64-pc-linux-gnu, GTK+ Version 3.22.30)
:  of 2019-09-16

****** Org Mode
#+BEGIN_SRC elisp :eval no-export
(org-version nil t)
#+END_SRC

#+RESULTS:
: Org mode version 9.3.1 (9.3.1-elpaplus @ /home/kdm/.emacs.d/elpa/org-plus-contrib-20191230/)

****** Bash
#+BEGIN_SRC bash :results verbatim :eval no-export
bash --version
#+END_SRC

#+RESULTS:
: GNU bash, version 4.4.20(1)-release (x86_64-pc-linux-gnu)
: Copyright (C) 2016 Free Software Foundation, Inc.
: This is free software; you are free to change and redistribute it.
: There is NO WARRANTY, to the extent permitted by law.

****** Parallel
#+BEGIN_SRC bash :results verbatim
parallel --version
#+END_SRC

#+RESULTS:
#+begin_example
GNU parallel 20161222
Copyright (C) 2007,2008,2009,2010,2011,2012,2013,2014,2015,2016
Ole Tange and Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
GNU parallel comes with no warranty.

Web site: http://www.gnu.org/software/parallel

When using programs that use GNU Parallel to process data for publication
please cite as described in 'parallel --citation'.
#+end_example

****** LaTeX                                            :noexport:
#+BEGIN_SRC bash :cmdline "-i" :results verbatim :eval no-export
pdflatex --version
#+END_SRC

#+RESULTS:
#+begin_example
pdfTeX 3.14159265-2.6-1.40.18 (TeX Live 2017/Debian)
kpathsea version 6.2.3
Copyright 2017 Han The Thanh (pdfTeX) et al.
There is NO warranty.  Redistribution of this software is
covered by the terms of both the pdfTeX copyright and
the Lesser GNU General Public License.
For more information about these matters, see the file
named COPYING and the pdfTeX source.
Primary author of pdfTeX: Han The Thanh (pdfTeX) et al.
Compiled with libpng 1.6.34; using libpng 1.6.34
Compiled with zlib 1.2.11; using zlib 1.2.11
Compiled with poppler version 0.62.0
#+end_example

****** Python
#+BEGIN_SRC bash :cmdline -i :results verbatim :eval no-export
. /home/kdm/local/anaconda/etc/profile.d/conda.sh
conda env export --name sci
#+END_SRC

#+RESULTS:
#+begin_example
name: sci
channels:
  - https://repo.anaconda.com/pkgs/free
  - conda-forge
  - defaults
dependencies:
  - affine=2.2.1=py_0
  - asn1crypto=0.24.0=py36_1003
  - attrs=18.2.0=py_0
  - backcall=0.1.0=py_0
  - basemap=1.2.0=py36h705c2d8_0
  - blas=1.0=mkl
  - bokeh=1.0.1=py36_1000
  - boost-cpp=1.68.0=h3a22d5f_0
  - boto3=1.9.58=py_0
  - botocore=1.12.58=py_0
  - bottleneck=1.2.1=py36h7eb728f_1
  - bzip2=1.0.6=h470a237_2
  - ca-certificates=2019.11.28=hecc5488_0
  - cairo=1.14.12=he6fea26_5
  - certifi=2019.11.28=py36_0
  - cffi=1.11.5=py36h5e8e0c9_1
  - cftime=1.0.2.1=py36h7eb728f_0
  - click=7.0=py_0
  - click-plugins=1.0.4=py_0
  - cligj=0.5.0=py_0
  - cloudpickle=0.6.1=py_0
  - cryptography=2.6.1=py36h72c5cf5_0
  - cryptography-vectors=2.3.1=py36_1000
  - curl=7.64.1=hf8cf82a_0
  - cycler=0.10.0=py_1
  - cytoolz=0.9.0.1=py36h470a237_1
  - dask=0.20.0=py_0
  - dask-core=0.20.0=py_0
  - dbus=1.13.0=h3a4f0e9_0
  - decorator=4.3.0=py_0
  - descartes=1.1.0=py_2
  - dill=0.2.8.2=py36_1000
  - distributed=1.24.0=py36_1000
  - docutils=0.14=py36_1001
  - entrypoints=0.2.3=py36_1002
  - expat=2.2.5=hfc679d8_2
  - fontconfig=2.13.1=h65d0f4c_0
  - freetype=2.9.1=h6debe1e_4
  - freexl=1.0.5=h470a237_2
  - geos=3.6.2=hfc679d8_4
  - geotiff=1.4.2=h700e5ad_5
  - gettext=0.19.8.1=h5e8e0c9_1
  - giflib=5.1.4=h470a237_1
  - glib=2.55.0=h464dc38_2
  - gmp=6.1.2=hfc679d8_0
  - gst-plugins-base=1.12.5=hde13a9d_0
  - gstreamer=1.12.5=h61a6719_0
  - h5netcdf=0.6.2=py_0
  - h5py=2.8.0=py36h470a237_0
  - hdf4=4.2.13=h951d187_2
  - hdf5=1.10.1=2
  - heapdict=1.0.0=py36_1000
  - icu=58.2=hfc679d8_0
  - idna=2.8=py36_1000
  - intel-openmp=2019.0=118
  - ipykernel=5.1.0=pyh24bf2e0_0
  - ipython=7.1.1=py36h24bf2e0_1000
  - ipython_genutils=0.2.0=py_1
  - ipywidgets=7.4.2=py_0
  - jedi=0.13.1=py36_1000
  - jinja2=2.10=py_1
  - jmespath=0.9.3=py_1
  - jpeg=9c=h470a237_1
  - json-c=0.12.1=h470a237_1
  - jsonschema=3.0.0a3=py36_1000
  - jupyter=1.0.0=py_1
  - jupyter_client=5.2.3=py_1
  - jupyter_console=6.0.0=py_0
  - jupyter_core=4.4.0=py_0
  - kealib=1.4.8=hfc679d8_0
  - kiwisolver=1.0.1=py36h2d50403_2
  - krb5=1.16.3=h05b26f9_1001
  - libblas=3.8.0=7_h6e990d7_netlib
  - libcblas=3.8.0=7_h6e990d7_netlib
  - libcurl=7.64.1=hda55be3_0
  - libdap4=3.19.1=h8fe5423_1
  - libedit=3.1.20170329=hf8c457e_1001
  - libffi=3.2.1=hfc679d8_5
  - libgcc-ng=8.2.0=hdf63c60_1
  - libgfortran=3.0.0=1
  - libgfortran-ng=7.2.0=hdf63c60_3
  - libiconv=1.15=h470a237_3
  - libkml=1.3.0=he469717_9
  - liblapack=3.8.0=7_h6e990d7_netlib
  - libnetcdf=4.4.1.1=10
  - libpng=1.6.35=ha92aebf_2
  - libpq=11.2=h4770945_0
  - libsodium=1.0.16=h470a237_1
  - libspatialindex=1.8.5=hfc679d8_3
  - libspatialite=4.3.0a=hdfcc80b_23
  - libssh2=1.8.2=h22169c7_2
  - libstdcxx-ng=7.3.0=hdf63c60_0
  - libtiff=4.0.9=he6b73bb_2
  - libuuid=2.32.1=h470a237_2
  - libxcb=1.13=h470a237_2
  - libxml2=2.9.8=h422b904_5
  - locket=0.2.0=py_2
  - markupsafe=1.0=py36h470a237_1
  - matplotlib=3.0.3=py36_0
  - matplotlib-base=3.0.3=py36h167e16e_0
  - mistune=0.8.4=py36h470a237_0
  - mkl=2018.0.3=1
  - mkl_fft=1.0.6=py36_0
  - mkl_random=1.0.1=py36_0
  - msgpack-python=0.5.6=py36h2d50403_3
  - munch=2.3.2=py_0
  - nbconvert=5.3.1=py_1
  - nbformat=4.4.0=py_1
  - ncurses=6.1=hfc679d8_1
  - netcdf4=1.3.1=py36_1
  - notebook=5.7.0=py36_1000
  - olefile=0.46=py_0
  - openblas=0.3.3=ha44fe06_1
  - openjpeg=2.3.0=h0e734dc_3
  - openssl=1.1.1d=h516909a_0
  - packaging=18.0=py_0
  - pandoc=2.3.1=0
  - pandocfilters=1.4.2=py_1
  - parso=0.3.1=py_0
  - partd=0.3.9=py_0
  - patsy=0.5.1=py_0
  - pcre=8.41=hfc679d8_3
  - pexpect=4.6.0=py36_1000
  - pickleshare=0.7.5=py36_1000
  - pillow=5.3.0=py36hc736899_0
  - pint=0.8.1=py_1
  - pip=18.1=py36_1000
  - pixman=0.34.0=h470a237_3
  - poppler=0.61.1=h4d7e492_4
  - poppler-data=0.4.9=0
  - postgresql=11.2=h61314c7_0
  - proj4=4.9.3=h470a237_8
  - prometheus_client=0.4.2=py_0
  - prompt_toolkit=2.0.7=py_0
  - psutil=5.4.8=py36h470a237_0
  - psycopg2=2.8.1=py36h72c5cf5_0
  - pthread-stubs=0.4=h470a237_1
  - ptyprocess=0.6.0=py36_1000
  - pycparser=2.19=py_0
  - pygments=2.2.0=py_1
  - pyopenssl=18.0.0=py36_1000
  - pyparsing=2.3.0=py_0
  - pyproj=1.9.5.1=py36h508ed2a_6
  - pyqt=4.11.4=py36_3
  - pyrsistent=0.14.5=py36h470a237_1
  - pysal=1.14.4.post2=py36_1001
  - pyshp=1.2.12=py_2
  - pysocks=1.6.8=py36_1002
  - python=3.6.7=h0371630_0
  - python-dateutil=2.7.5=py_0
  - pytz=2018.7=py_0
  - pyyaml=3.13=py36h470a237_1
  - pyzmq=17.1.2=py36hae99301_1
  - qt=4.8.7=2
  - qtconsole=4.4.2=py_1
  - readline=7.0=haf1bffa_1
  - rtree=0.8.3=py36_1000
  - s3transfer=0.1.13=py36_1001
  - scipy=1.1.0=py36hc49cb51_0
  - send2trash=1.5.0=py_0
  - setuptools=40.5.0=py36_0
  - shapely=1.6.4=py36h164cb2d_1
  - simplejson=3.16.1=py36h470a237_0
  - simplekml=1.3.0=py_1
  - sip=4.18=py36_1
  - six=1.11.0=py36_1001
  - snuggs=1.4.1=py_1
  - sortedcontainers=2.0.5=py_0
  - sqlalchemy=1.2.15=py36h470a237_0
  - sqlite=3.25.2=hb1c47c0_0
  - statsmodels=0.9.0=py36h7eb728f_0
  - tabulate=0.8.2=py_0
  - tblib=1.3.2=py_1
  - terminado=0.8.1=py36_1001
  - testpath=0.4.2=py36_1000
  - tk=8.6.9=h84994c4_1001
  - toolz=0.9.0=py_1
  - tornado=5.1.1=py36h470a237_0
  - traitlets=4.3.2=py36_1000
  - tzcode=2018g=h14c3975_1001
  - urllib3=1.24.1=py36_1000
  - wcwidth=0.1.7=py_1
  - wheel=0.32.2=py36_0
  - widgetsnbextension=3.4.2=py36_1000
  - xarray=0.14.1=py_0
  - xerces-c=3.2.0=h5d6a6da_2
  - xorg-kbproto=1.0.7=h470a237_2
  - xorg-libice=1.0.9=h470a237_4
  - xorg-libsm=1.2.3=h8c8a85c_0
  - xorg-libx11=1.6.6=h470a237_0
  - xorg-libxau=1.0.8=h470a237_6
  - xorg-libxdmcp=1.1.2=h470a237_7
  - xorg-libxext=1.3.3=h470a237_4
  - xorg-libxrender=0.9.10=h470a237_2
  - xorg-renderproto=0.11.1=h470a237_2
  - xorg-xextproto=7.3.0=h470a237_2
  - xorg-xproto=7.0.31=h470a237_7
  - xz=5.2.4=h470a237_1
  - yaml=0.1.7=h470a237_1
  - zeromq=4.2.5=hfc679d8_6
  - zict=0.1.3=py_0
  - zlib=1.2.11=h470a237_3
  - pip:
    - atomicwrites==1.3.0
    - bleach==3.0.2
    - cfchecker==4.0.0
    - cfunits==3.2.2
    - chardet==3.0.4
    - csvs-to-sqlite==1.0
    - dateparser==0.7.1
    - fastkml==0.11
    - fiona==1.8.11
    - future==0.17.1
    - geopandas==0.6.2
    - grass-session==0.1
    - ical2orgpy==0.2.0
    - icalendar==4.0.3
    - importlib-metadata==0.18
    - more-itertools==7.2.0
    - mpmath==1.1.0
    - numpy==1.17.4
    - pandas==0.25.1
    - pluggy==0.12.0
    - py==1.8.0
    - py-lru-cache==0.1.4
    - pycwt==0.3.0a22
    - pygeoif==0.7
    - pytest==5.0.1
    - q==2.6
    - rasterio==1.1.0
    - regex==2019.8.19
    - seaborn==0.9.0
    - sty==1.0.0b9
    - sympy==1.3
    - tqdm==4.28.1
    - tzlocal==1.5.1
    - uncertainties==3.1.2
    - webencodings==0.5.1
    - xlrd==1.2.0
    - zipp==0.5.2
prefix: /home/kdm/local/anaconda/envs/sci

#+end_example

**** Future concerns and developments

Development of this work is ongoing at http://github.com/mankoff/ice_discharge where we use additional IV products that support time series back to 1986, additional SEC products that cover the portions of the ice sheet where the gates are located, and other modifications.

Concerns for the future of this work are mitigated by the fact that the entire process is documented and the code is available for anyone to replicate and improve the product.

Concerns also include the quality of the ice thickness data, and the ability to generate SEC maps at regular frequency and with enough spatial coverage to cover the gate locations.

**** References

\printbibliography[heading=none]
** WWW
